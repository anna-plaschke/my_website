---
title: 'Smart Investment Decisions: Which house should I buy in London'
date: '2020-12-20T22:42:51-05:00'
description: London House Prices
draft: no
image: pic12.jpg
keywords: ''
slug: blog10
categories:
- ''
- ''
subtitle: Various analyses
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="abstract" class="section level1">
<h1>Abstract</h1>
<p>This report is about estimating housing prices in London with estimation engines to guide investment decisions. Transaction data from houses sold in London in 2019 as well as various information on these houses are used to create seven different estimation engines using linear regression, LASSO regression, knn, tree, random forest, gradient boosting, and stacking. The best model is used to select the most promising 200 houses out of 2,000 houses that are currently on sale. This will be done by calculating the deviation of the predicted price and asked price.</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>London house prices have risen substantially above the general inflation since 1995. Given this positive development of house prices, investing in properties in London seems very lucrative. However, house prices have crashed twice since 1990 and the current uncertainty in the British economy caused by Brexit and the global pandemic COVID-19 can have impact on its house prices. Recent governmental initiatives to lower property prices, are adding an additional factor of uncertainty. This may lead to lower house prices making investments in properties highly interesting if seen as a mid to long-term investment.
However, while some of the houses are overpriced, it is crucial to gather and evaluating more information on the properties when taking investment decisions.
Purpose of this project is to build an estimation engine to guide investment decisions in the London house market. This estimation engine predicts a price based on detailed information on the property for sale such as location, size, and energy efficiency which I will compare to the asking price. I will use publicly available data on transactions in 2019 in London data from Land Registry’s Price Paid Data, Energy Performance Certificate (EPC) data, and public transport information data to determine the effects of the various variables.
In this report, I explain how I got the data, which machine learning algorithms I used and how I tuned them. Finally, I will apply the estimation engine to recommend top 200 houses out of 2,000 houses on the market for sale at the moment.</p>
</div>
<div id="body" class="section level1">
<h1>Body</h1>
<div id="data-used" class="section level2">
<h2>Data Used</h2>
<p>For my project, I combine three datasets:
I use publicly available transaction data occurred in London in 2019 from Land Registry’s Price Paid Data that tracks the property sales in England and Wales and includes details on property types.
I merge this data with detailed information about each property from a publicly available data set with Energy Performance Certificate (EPC) data. From this, I retrieve data including size, number of bedrooms, and energy ratings.
Finally, I add public transport information such as nearest station, walking distance to station, and the number of lines for each property.
I clean the dataset, making sure that the correct data type is assigned to each variable and remove the variables with too many missing datapoints.</p>
<pre class="r"><code>#read in the data
library(data.table)
london_house_prices_2019_training&lt;-read.csv(&quot;data/training_data_assignment_with_prices.csv&quot;)
london_house_prices_2019_out_of_sample&lt;-read.csv(&quot;data/test_data_assignment.csv&quot;)

#fix dates
london_house_prices_2019_training &lt;- london_house_prices_2019_training %&gt;% mutate(date=as.Date(date))
london_house_prices_2019_out_of_sample&lt;-london_house_prices_2019_out_of_sample %&gt;% mutate(date=as.Date(date))
#change characters to factors
london_house_prices_2019_training &lt;- london_house_prices_2019_training %&gt;% mutate_if(is.character,as.factor)
london_house_prices_2019_out_of_sample&lt;-london_house_prices_2019_out_of_sample %&gt;% mutate_if(is.character,as.factor)
#remove address2 and town because of missingness
london_house_prices_2019_training &lt;- london_house_prices_2019_training %&gt;% select(-c(town, address2))
london_house_prices_2019_out_of_sample&lt;-london_house_prices_2019_out_of_sample %&gt;% select(-c(town, address2))

#make sure out of sample data and training data has the same levels for factors 
a&lt;-union(levels(london_house_prices_2019_training$postcode_short),levels(london_house_prices_2019_out_of_sample$postcode_short))
london_house_prices_2019_out_of_sample$postcode_short &lt;- factor(london_house_prices_2019_out_of_sample$postcode_short, levels = a)
london_house_prices_2019_training$postcode_short &lt;- factor(london_house_prices_2019_training$postcode_short, levels = a)</code></pre>
</div>
<div id="visualize-data" class="section level2">
<h2>Visualize data</h2>
<p>Before visualizing the data I calculate the average price total and average price per Sqrmtr</p>
<pre class="r"><code>london_house_prices_2019_training %&gt;% summarise(average_price =mean(price), average_price_sqmtr =mean(price/total_floor_area))</code></pre>
<pre><code>##   average_price average_price_sqmtr
## 1        593791                6343</code></pre>
<p>To get a good initial understanding on the structure of the data and the relationship between housing prices and the explanatory variables, I create a few visualizations:</p>
<p>First, I plot the distribution of the prices and detect that they are right skewed, with a medium price of 595,000 pounds.</p>
<pre class="r"><code>library(patchwork)
p1 &lt;- ggplot(london_house_prices_2019_training, aes(x=price, fill=(price &lt; 2000000)))+
  geom_histogram()+
  labs(y=&quot;Number of Properties&quot;, x=&quot;House Price&quot;, title=&quot;Distribution of House Prices in London&quot;)+
  theme_classic()+ #add theme
  scale_x_continuous(labels=scales::dollar_format())+
  theme(legend.position = &quot;none&quot;)+
  scale_fill_manual(values=c(&quot;dark grey&quot;, &quot;#5691B0&quot; ))+
  geom_vline(xintercept = 593790.9, color = &#39;red&#39;, linetype = &#39;dashed&#39;) +
  annotate(geom=&quot;text&quot;, x = 2000790.9,y = 8500, label=&#39;Average Price\n = ~595,000&#39;, color = &#39;red&#39;, size=3.5) +
  
  
  
  NULL
  
  p2 &lt;- ggplot(london_house_prices_2019_training, aes(x=price, fill=(price &lt; 2000000)))+
  geom_histogram()+
  labs(y=&quot;Number of Properties&quot;, x=&quot;House Price&quot;, title=&quot;Deep Dive:&quot;, subtitle= &quot;Distribution of House Prices (&lt; 2 Mio) in London&quot;)+
  theme_classic()+ #add theme
theme(legend.position = &quot;none&quot;)+
scale_x_continuous(labels=scales::dollar_format(), limits = c(0,2000000))+
scale_fill_manual(values=c(&quot;dark grey&quot;, &quot;#5691B0&quot; ))+
  NULL

  p1+p2</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Second, I plot the average price per property type as well as the frequency of each property type. While detached houses, the least frequent sold property type, are on average more expensive, Flats, the most frequent sold property type, are on average the cheapest properties to buy.</p>
<pre class="r"><code>p1 &lt;- london_house_prices_2019_training %&gt;% 
  group_by(property_type) %&gt;% 
  summarise(average_price=mean(price)) %&gt;% 
  ggplot(aes(y=average_price, x=reorder(property_type, -average_price), fill=property_type))+ 
  geom_col()+
  labs(y=&quot;Average Price&quot;, x=&quot;Property Type&quot;, title=&quot;Average Price per Property Type&quot;)+
  scale_x_discrete(labels = c(&#39;Detached&#39;,&#39;Terraced&#39;,  &#39;Semi- Detached&#39;,&quot;Flats/Maisonettes&quot;))+
  scale_fill_manual(values=c(&quot;#317395&quot;,&quot;#B5D7E9&quot;, &quot;#76B3D3&quot;, &quot;#5691B0&quot; ))+
  theme_classic()+ #add theme
  theme(legend.position = &quot;none&quot;)+
  scale_y_continuous(labels=scales::dollar_format())+
  NULL

p2&lt;- london_house_prices_2019_training %&gt;% 
   group_by(property_type) %&gt;% 
  summarise(count=n()) %&gt;% 
  ggplot(aes(x=reorder(property_type, -count), y=count, fill=property_type))+
    geom_col()+
  scale_x_discrete(labels = c(&quot;Flats/Maisonettes&quot;,&#39;Terraced&#39;,   &#39;Semi- Detached&#39;,&#39;Detached&#39;))+
  scale_fill_manual(values=c( &quot;#317395&quot;,&quot;#B5D7E9&quot;, &quot;#76B3D3&quot;, &quot;#5691B0&quot;))+
   theme(legend.position = &quot;none&quot;)+
  
 scale_y_continuous(label=comma)+
  labs(y=&quot;Number of Property Type&quot;, x=&quot;Property Type&quot;, title=&quot;Frequency of Property Types sold in 2019&quot;)+
  
  
  NULL

p1+p2</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize3-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>To understand the influence of a property’s size and zone I plot these variables and detect strong relationship between size and price, as well as london zones and prices.</p>
<pre class="r"><code>london_house_prices_2019_training %&gt;%
  mutate(london_zone2=as.factor(london_zone)) %&gt;% 

  ggplot(aes(y=price, x=total_floor_area, colour=london_zone2))+ 
 #geom_smooth()+
  geom_point(alpha=0.35)+
  labs(x=&quot;Size of Flat (in Sqmtr)&quot;, y=&quot;Price&quot;, title=&quot;Positive Relationship between Property&#39; Price and Size&quot;, colour=&quot;London Zone&quot;)+
  theme_classic()+ #add theme
  scale_y_continuous(labels=scales::dollar_format())+

  NULL</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize_londonzone-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Then, I visualized the positive relationship between average income and price.</p>
<pre class="r"><code>london_house_prices_2019_training %&gt;% 
  ggplot(aes(y=price, x=average_income))+ 
  geom_point(alpha=0.35)+
  geom_smooth()+
  labs(x=&quot;Average Income&quot;, y=&quot;Price&quot;, title=&quot;Relationship between Average Income and Price&quot;)+
  theme_classic()+ #add theme
  scale_y_continuous(labels=scales::dollar_format(), limits=c(0, 3000000))+
  scale_x_continuous(label=comma)+
  NULL</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualizeaverageincome-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>I look at the price/floor area by district.</p>
<pre class="r"><code>london_house_prices_2019_training %&gt;% 
  mutate(price_floor =price/total_floor_area) %&gt;%
  group_by(district) %&gt;% 
  summarise(average_price_floor=mean(price_floor)) %&gt;% 
  ggplot(aes(x=average_price_floor, y=reorder(district, average_price_floor)), by_row=TRUE)+ 
  geom_col()+
  labs(x=&quot;Average Price per squaremetre&quot;, y=&quot;&quot;, title=&quot;Average Price per District&quot;)+
  theme_classic()+ #add theme
  NULL</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualizedistrict-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Finally, I check if there are strong correlations between the variables. Some variables such as total floor area, number of habitable rooms, and current CO2 emissions are correlating strongly. Whilst it is important to keep such correlations in mind, they do not constitute a problem when creating models for prediction.</p>
<pre class="r"><code># produce a correlation table using GGally::ggcor()

library(&quot;GGally&quot;)
london_house_prices_2019_training %&gt;% 
  select(-ID) %&gt;% #keep Y variable last
  ggcorr(method = c(&quot;pairwise&quot;, &quot;pearson&quot;), layout.exp = 2,label_round=2, label = TRUE,label_size = 2,hjust = 1,nbreaks = 5,size = 2,angle = -20)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/correlation%20table-1.png" width="768" style="display: block; margin: auto;" />
## Tuning Model</p>
<p>Before creating models, I split the data into training and testing data. I use the training dataset to build my models and test them subsequently on the testing data. Having an outcome variable for the testing data, I can detect if my model overfits before using it for predictions on unlabeled data (houses with no transaction price).</p>
<pre class="r"><code>#let&#39;s do the initial split
set.seed(1)
library(rsample)
train_test_split &lt;- initial_split(london_house_prices_2019_training, prop = 0.75) #training set contains 75% of the data
train_data &lt;- training(train_test_split)
test_data &lt;- testing(train_test_split)</code></pre>
<p>As first step, I set seed and stabilize a cross-fold validation that I use for all my models. Cross-fold validation is a technique to test the predictive power of a model on a dataset that was not used to create the model, when having a limited number of observations. The seed instead makes it possible to replicate the model with exact the same results.</p>
<pre class="r"><code>#Define control variables
set.seed(1)#because I use cross-validation and want to be able to replicate the model
control &lt;- trainControl (
    method=&quot;cv&quot;, #cross-fold validation
    number=10,
    verboseIter=TRUE) #by setting this to true the model will report its progress after each estimation</code></pre>
<p>I tune all the models maximizing R² and minimizing RMSE. R² is the amount of variance in the data explained by the model. If my model has an R² of 80% for example, the model explains 80% of the different prices between the houses in my dataset. RMSE on the other side, stands for the root mean squared error and is the prediction error of the model.</p>
</div>
<div id="linear-regression" class="section level2">
<h2>Linear Regression</h2>
<p>The first model I create, is a linear regression. A linear regression looks for the line of best fit between all the variables. I use a stepwise regression when selecting the variables, meaning that I include all of them and subsequently remove unsignificant ones.
The only variables I exclude since the beginning are illogical variables such as latitude and longitude, variables with missing data, and variables that are missing in the dataset on which I will do the final predictions. Latitude and longitude are illogical for a linear regression because I assume prices to be higher in the centre if London, and a linear correlation between longitude/latitude and price would therefore be unlikely.</p>
<div id="linear-regression-1" class="section level3">
<h3>1 Linear Regression</h3>
<pre class="r"><code>#we are going to train the model and report the results using k-fold cross validation
model_lm_0&lt;-train(
    price ~ 

   num_tube_lines 
   +num_rail_lines
   +num_light_rail_lines
   +distance_to_station 
   #+nearest_station #not using it because of new station
   +type_of_closest_station
   
    +whether_old_or_new
    +freehold_or_leasehold
  

   +london_zone
   #+postcode_short #too many variables
    #+local_aut #not in out of sample data
    +average_income
  # +nearest_station #problems in out of sample
   
    +total_floor_area
    +number_habitable_rooms 
    +property_type
   +tenure
    
    +current_energy_rating
   +energy_consumption_potential
   +energy_consumption_current
    +windows_energy_eff
    +co2_emissions_potential
   +co2_emissions_current
    +water_company
    
    ,
    train_data,
   method = &quot;lm&quot;,
    trControl = control
   )

# summary of the results
model_lm_0$result</code></pre>
<p>After excluding all insignificant variables, I create interaction variables between variables that are very important (e.g., total floor area, number of habitable rooms, and London zone), as well as non-linear terms (e.g., (total floor area) ² ) .
Then, I replace the geographical categorical variable postcode short with London zones, because while many postcodes turn out to be insignificant, London zones seems to be a good indicator for geographical distribution of prices.</p>
</div>
<div id="linear-regression-2" class="section level3">
<h3>2 Linear Regression</h3>
<pre class="r"><code>#we are going to train the model and report the results using k-fold cross validation
model_lm&lt;-train(
    price ~ 
   num_tube_lines 

    +district:property_type
    +london_zone*poly(total_floor_area,2)*number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential
   +energy_consumption_current
   +current_energy_rating
    +windows_energy_eff
    +co2_emissions_potential
   +co2_emissions_current
    +water_company
    ,
    train_data,
   method = &quot;lm&quot;,
    trControl = control
   )</code></pre>
<pre><code>## + Fold01: intercept=TRUE 
## - Fold01: intercept=TRUE 
## + Fold02: intercept=TRUE 
## - Fold02: intercept=TRUE 
## + Fold03: intercept=TRUE 
## - Fold03: intercept=TRUE 
## + Fold04: intercept=TRUE 
## - Fold04: intercept=TRUE 
## + Fold05: intercept=TRUE 
## - Fold05: intercept=TRUE 
## + Fold06: intercept=TRUE 
## - Fold06: intercept=TRUE 
## + Fold07: intercept=TRUE 
## - Fold07: intercept=TRUE 
## + Fold08: intercept=TRUE 
## - Fold08: intercept=TRUE 
## + Fold09: intercept=TRUE 
## - Fold09: intercept=TRUE 
## + Fold10: intercept=TRUE 
## - Fold10: intercept=TRUE 
## Aggregating results
## Fitting final model on full training set</code></pre>
<pre class="r"><code># summary of the results
model_lm$result</code></pre>
<pre><code>##   intercept   RMSE Rsquared    MAE RMSESD RsquaredSD MAESD
## 1      TRUE 233128    0.804 117778  40439     0.0284  7436</code></pre>
<p>Then, I plot the results of the final model as well as the importance of each variable:</p>
<pre class="r"><code>model_lm$results</code></pre>
<pre><code>##   intercept   RMSE Rsquared    MAE RMSESD RsquaredSD MAESD
## 1      TRUE 233128    0.804 117778  40439     0.0284  7436</code></pre>
<pre class="r"><code># we can check variable importance as well
importance &lt;- varImp(model_lm, scale=TRUE)
plot(importance)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/varimportance-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="prediction-lm" class="section level3">
<h3>Prediction lm</h3>
<p>Below I use the predict function to test the performance of the model in testing data and summarize the performance of the linear regression model.</p>
<pre class="r"><code># We can predict the testing values

predictions_lm &lt;- predict(model_lm,test_data)

lm_results&lt;-data.frame(RMSE = RMSE(predictions_lm, test_data$price), #how much did qe predict wrong
                            Rsquare = R2(predictions_lm, test_data$price)) #how much does the model cover
lm_results                         </code></pre>
<pre><code>##     RMSE Rsquare
## 1 208392   0.835</code></pre>
<p>The performance of the model (in R²):
- Training 0.8102
- Testing 0.8358638</p>
</div>
</div>
<div id="lasso" class="section level2">
<h2>LASSO</h2>
<p>As second model, I performed a LASSO regression using the same variables as in the linear regression. LASSO regression is a type of linear regression that shirks the impact of the variables (regularization) and eliminates insignificant variables (parameter selection). To do so, I introduce artificially a bias (lambda) which adds a penalty to the coefficients for each variable. As consequence, all variables have a lower coefficient, and some go down to zero, resulting into a simpler model with less variance but a higher bias.
I optimize the model calculating the error of the model (RMSE – root mean standard error) as well as the explanatory power of my model (R²) for different biases (lambda). Finally, I select the model with the lowest RMSE and highest R².</p>
<pre class="r"><code>#split data into training &amp; testing -&gt; already done
#we need to optimize the lambda in this sequence
lambda_seq &lt;- seq(0, 1000, length =100)

#we use cross fold validation
set.seed(1)
control &lt;- trainControl(
  method=&quot;cv&quot;,
  number = 10,
  verboseIter = FALSE)

#LASSO regression to select the best lambda
set.seed(1)
lasso_fit &lt;- train(price ~
    #  distance_to_station #not significant
    num_tube_lines #not significant
    
    +whether_old_or_new #not significant
    +freehold_or_leasehold #not significant

    +distance_to_station
    +district:property_type
    +london_zone*poly(total_floor_area,2)*number_habitable_rooms 
 
    +average_income
    
    +energy_consumption_potential
    +energy_consumption_current #new
    +current_energy_rating #new
    +windows_energy_eff
    +co2_emissions_potential
    +co2_emissions_current #new
    +water_company,
    
        data=train_data,
        method=&quot;glmnet&quot;,
        preProc = c(&quot;center&quot;, &quot;scale&quot;), #This option standardizes the data before running the LASSO regression if alpha = 0 -&gt;RIDGE REG
  
   trControl = control,
  tuneGrid = expand.grid(alpha = 1, lambda = lambda_seq) #alpha=1 specifies to run a LASSO regression. If alpha=0 the model would run ridge regression.

)

coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)</code></pre>
<pre><code>## 166 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                                                       1
## (Intercept)                                                    594480.4
## num_tube_lines                                                  15627.7
## whether_old_or_newY                                               224.5
## freehold_or_leaseholdL                                         -16424.4
## distance_to_station                                             -2672.4
## london_zone                                                   -183472.0
## poly(total_floor_area, 2)1                                    1014162.8
## poly(total_floor_area, 2)2                                     321756.7
## number_habitable_rooms                                         -77333.0
## average_income                                                  60282.3
## energy_consumption_potential                                   -31968.4
## energy_consumption_current                                      -3455.7
## current_energy_ratingC                                           7340.9
## current_energy_ratingD                                          11157.3
## current_energy_ratingE                                           1872.5
## current_energy_ratingF                                          -6706.5
## current_energy_ratingG                                          -6338.3
## windows_energy_effGood                                           6860.1
## windows_energy_effPoor                                          12230.9
## windows_energy_effVery Good                                      5449.2
## windows_energy_effVery Poor                                     15294.0
## co2_emissions_potential                                         52468.6
## co2_emissions_current                                           19618.9
## water_companyEssex &amp; Suffolk Water                               1951.1
## water_companyLeep Utilities                                       480.6
## water_companySES Water                                          16647.1
## water_companyThames Water                                       19487.2
## districtBarking and Dagenham:property_typeD                       741.2
## districtBarnet:property_typeD                                    8899.5
## districtBexley:property_typeD                                    6705.5
## districtBrent:property_typeD                                       17.9
## districtBromley:property_typeD                                   4916.5
## districtCamden:property_typeD                                   20854.7
## districtCity of London:property_typeD                               .  
## districtCroydon:property_typeD                                      .  
## districtEaling:property_typeD                                   -2317.4
## districtEnfield:property_typeD                                   1697.5
## districtGreenwich:property_typeD                                -2060.0
## districtHackney:property_typeD                                      .  
## districtHammersmith and Fulham:property_typeD                       .  
## districtHaringey:property_typeD                                     .  
## districtHarrow:property_typeD                                   15067.9
## districtHavering:property_typeD                                  8804.1
## districtHillingdon:property_typeD                               11477.0
## districtHounslow:property_typeD                                 -1948.6
## districtIslington:property_typeD                                 3586.6
## districtKensington and Chelsea:property_typeD                   26187.9
## districtKingston upon Thames:property_typeD                     17165.4
## districtLambeth:property_typeD                                      .  
## districtLewisham:property_typeD                                 -3538.1
## districtMerton:property_typeD                                    7032.9
## districtNewham:property_typeD                                    -830.4
## districtRedbridge:property_typeD                                 -505.6
## districtRichmond upon Thames:property_typeD                     21716.2
## districtSouthwark:property_typeD                                 1695.9
## districtSutton:property_typeD                                   -2205.3
## districtTower Hamlets:property_typeD                                .  
## districtWaltham Forest:property_typeD                           -2466.1
## districtWandsworth:property_typeD                                1418.8
## districtWestminster:property_typeD                                  .  
## districtBarking and Dagenham:property_typeF                     -2026.1
## districtBarnet:property_typeF                                   -3295.1
## districtBexley:property_typeF                                   -6900.2
## districtBrent:property_typeF                                     1751.8
## districtBromley:property_typeF                                 -10417.3
## districtCamden:property_typeF                                   17719.7
## districtCity of London:property_typeF                            6747.4
## districtCroydon:property_typeF                                 -11591.3
## districtEaling:property_typeF                                   -3341.8
## districtEnfield:property_typeF                                  -3003.8
## districtGreenwich:property_typeF                                -4605.3
## districtHackney:property_typeF                                   5717.0
## districtHammersmith and Fulham:property_typeF                    6835.5
## districtHaringey:property_typeF                                  2921.2
## districtHarrow:property_typeF                                   -3248.2
## districtHavering:property_typeF                                 -1685.6
## districtHillingdon:property_typeF                               -2903.0
## districtHounslow:property_typeF                                 -4087.1
## districtIslington:property_typeF                                 7575.7
## districtKensington and Chelsea:property_typeF                   58576.9
## districtKingston upon Thames:property_typeF                     -6698.3
## districtLambeth:property_typeF                                    190.1
## districtLewisham:property_typeF                                 -9213.2
## districtMerton:property_typeF                                   -5475.4
## districtNewham:property_typeF                                   -2019.2
## districtRedbridge:property_typeF                                -6521.9
## districtRichmond upon Thames:property_typeF                     -1321.1
## districtSouthwark:property_typeF                                 3226.7
## districtSutton:property_typeF                                  -13613.8
## districtTower Hamlets:property_typeF                            -5952.0
## districtWaltham Forest:property_typeF                            -377.0
## districtWandsworth:property_typeF                                 432.1
## districtWestminster:property_typeF                              51586.5
## districtBarking and Dagenham:property_typeS                     -2821.9
## districtBarnet:property_typeS                                    9386.9
## districtBexley:property_typeS                                   -9391.0
## districtBrent:property_typeS                                      941.9
## districtBromley:property_typeS                                  -4364.0
## districtCamden:property_typeS                                    4957.4
## districtCity of London:property_typeS                               .  
## districtCroydon:property_typeS                                 -14299.3
## districtEaling:property_typeS                                     545.1
## districtEnfield:property_typeS                                    229.0
## districtGreenwich:property_typeS                                -8143.4
## districtHackney:property_typeS                                   4730.4
## districtHammersmith and Fulham:property_typeS                    4410.2
## districtHaringey:property_typeS                                  -583.5
## districtHarrow:property_typeS                                    3694.2
## districtHavering:property_typeS                                  6868.8
## districtHillingdon:property_typeS                                5663.6
## districtHounslow:property_typeS                                   732.9
## districtIslington:property_typeS                                10416.9
## districtKensington and Chelsea:property_typeS                   21702.0
## districtKingston upon Thames:property_typeS                      6164.4
## districtLambeth:property_typeS                                  -5793.6
## districtLewisham:property_typeS                                 -9075.0
## districtMerton:property_typeS                                   -3421.5
## districtNewham:property_typeS                                   -1764.4
## districtRedbridge:property_typeS                                -8344.5
## districtRichmond upon Thames:property_typeS                     18367.4
## districtSouthwark:property_typeS                                 4246.4
## districtSutton:property_typeS                                   -7473.4
## districtTower Hamlets:property_typeS                                .  
## districtWaltham Forest:property_typeS                            2508.4
## districtWandsworth:property_typeS                                   .  
## districtWestminster:property_typeS                              36645.3
## districtBarking and Dagenham:property_typeT                     -3750.0
## districtBarnet:property_typeT                                    2038.4
## districtBexley:property_typeT                                   -9459.4
## districtBrent:property_typeT                                     5873.7
## districtBromley:property_typeT                                  -9290.5
## districtCamden:property_typeT                                   17439.6
## districtCity of London:property_typeT                               .  
## districtCroydon:property_typeT                                 -19230.9
## districtEaling:property_typeT                                     925.4
## districtEnfield:property_typeT                                   -909.1
## districtGreenwich:property_typeT                                -8340.4
## districtHackney:property_typeT                                   5746.9
## districtHammersmith and Fulham:property_typeT                   19177.7
## districtHaringey:property_typeT                                  3045.0
## districtHarrow:property_typeT                                     945.0
## districtHavering:property_typeT                                  3049.0
## districtHillingdon:property_typeT                                 -95.0
## districtHounslow:property_typeT                                  3878.1
## districtIslington:property_typeT                                11445.4
## districtKensington and Chelsea:property_typeT                  104020.5
## districtKingston upon Thames:property_typeT                      1782.9
## districtLambeth:property_typeT                                  -6490.8
## districtLewisham:property_typeT                                -13920.0
## districtMerton:property_typeT                                   -7423.7
## districtNewham:property_typeT                                  -13263.4
## districtRedbridge:property_typeT                                -9798.2
## districtRichmond upon Thames:property_typeT                     15582.9
## districtSouthwark:property_typeT                                    .  
## districtSutton:property_typeT                                  -11001.5
## districtTower Hamlets:property_typeT                             -551.7
## districtWaltham Forest:property_typeT                             398.7
## districtWandsworth:property_typeT                                 456.0
## districtWestminster:property_typeT                              35411.7
## london_zone:poly(total_floor_area, 2)1                        -791217.7
## london_zone:poly(total_floor_area, 2)2                        -272639.0
## london_zone:number_habitable_rooms                             103682.4
## poly(total_floor_area, 2)1:number_habitable_rooms             -401559.0
## poly(total_floor_area, 2)2:number_habitable_rooms              -68996.2
## london_zone:poly(total_floor_area, 2)1:number_habitable_rooms  399638.7
## london_zone:poly(total_floor_area, 2)2:number_habitable_rooms   57036.3</code></pre>
<div id="predict-lasso" class="section level3">
<h3>Predict lasso</h3>
<pre class="r"><code>#lasso_fit$results
plot(lasso_fit)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/lasso_predict-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>predictions_lasso &lt;- predict(lasso_fit, test_data)
lasso_results &lt;- data.frame( RMSE =RMSE(predictions_lasso, test_data$price),
                             Rsquare =R2(predictions_lasso, test_data$price))

lasso_results</code></pre>
<pre><code>##     RMSE Rsquare
## 1 207501   0.836</code></pre>
<p>The performance of the model (in R²):
- Training: 0.8026139
- Testing: 0.8360793</p>
</div>
</div>
<div id="knn" class="section level2">
<h2>KNN</h2>
<p>As third model I use the k-Nearest Neighbours (k-NN) model. It predicts a value based on a datapoint’s k nearest neighbours. This means, that the price of a property is predicted based on the k most similar properties in the training dataset.
To select the variables, I use the knowledge gained from the linear regression and take the significant variables from the linear regression. Furthermore, I include latitude and longitude as this model does not assume a linear relationship between the dependent and the independent variable. Finally, I remove the interaction variables given this model’s ability in determining them by itself.
Before running the model, I make sure to standardize the variables, as the distance between the points should not be influenced by different units of the variables. Then, I optimize my model using different numbers for the number of neighbours (k).</p>
<p>To do so, I first use 10 random values for k with tuneLength, and then optimize for values close to the best performing k-value with tuneGrid.</p>
<div id="knn-10-random-values-for-k" class="section level3">
<h3>KNN: 10 random values for k</h3>
<pre class="r"><code>#knn
# selecting the best k with the highest R²
set.seed(1) #because I use cross-validation and want to be able to replicate the model

knn_fit_1 &lt;- train(
  price ~ 
    
        #  distance_to_station #not significant
   num_tube_lines #not significant
    
    +latitude
    +longitude
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,
                   
                method = &quot;knn&quot;, 
                 trControl = control, #use the same as I used in linear regression
                 tuneLength = 10, #number of parameter values train function will try
                 preProcess = c(&quot;center&quot;, &quot;scale&quot;), #center and scale the data in k-nn this is pretty important
                 metric=&quot;RMSE&quot; #default metric is accuracy, I change it to R²

  )

print(knn_fit_1)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 10499 samples
##    13 predictor
## 
## Pre-processing: centered (52), scaled (52) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results across tuning parameters:
## 
##   k   RMSE    Rsquared  MAE   
##    5  267358  0.746     125679
##    7  268003  0.750     124951
##    9  268917  0.754     125417
##   11  272270  0.753     126574
##   13  275337  0.750     127294
##   15  278772  0.746     128228
##   17  279448  0.749     128974
##   19  280789  0.749     129780
##   21  283118  0.748     130544
##   23  285960  0.745     131288
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code>plot(knn_fit_1)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/knn_model_1-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="knn-tunegrid" class="section level3">
<h3>KNN: tuneGrid</h3>
<p>The best k seems to be between 1 and 7, therefore I use tuneGrid to get the best k.</p>
<pre class="r"><code>#knn2
Grid_knn &lt;- expand.grid(k=seq(1, 7, 1))
# selecting the best k with the highest R²
set.seed(1) #because I use cross-validation and want to be able to replicate the model

knn_fit_2 &lt;- train(  
  price ~ 
    
        #  distance_to_station #not significant
   num_tube_lines #not significant
    
    +latitude
    +longitude
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,

    method = &quot;knn&quot;, 
     trControl = control, #use the same as I used in linear regression
     tuneGrid = Grid_knn, #looking for numbers around 
     preProcess = c(&quot;center&quot;, &quot;scale&quot;), #center and scale the data in k-nn this is pretty important
     metric=&quot;RMSE&quot;) #default metric is accuracy is binary, otherwise RMSE, I change it to R²

print(knn_fit_2)</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 10499 samples
##    13 predictor
## 
## Pre-processing: centered (52), scaled (52) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results across tuning parameters:
## 
##   k  RMSE    Rsquared  MAE   
##   1  313051  0.658     149998
##   2  281924  0.709     134824
##   3  275575  0.725     130291
##   4  271762  0.734     127669
##   5  267358  0.746     125679
##   6  265788  0.752     124721
##   7  268003  0.750     124951
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was k = 6.</code></pre>
<pre class="r"><code>plot(knn_fit_2)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/knn_model_2-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="prediction-knn" class="section level3">
<h3>Prediction KNN</h3>
<pre class="r"><code>#predict the price of each house in the test data set
#recall that the output of &quot;train&quot; function (knn_fit) automatically keeps the best model 
knn_prediction &lt;- predict(knn_fit_2, newdata = test_data)

knn_results&lt;-data.frame(RMSE = RMSE(knn_prediction, test_data$price), Rsquare = R2(knn_prediction, test_data$price))

knn_results</code></pre>
<pre><code>##     RMSE Rsquare
## 1 260115   0.751</code></pre>
<p>The number of neighbors that optimize RMSE are k=6.</p>
<p>The performance of the model (in R²):
- training:0.7524809
- testing: 0.7509709</p>
</div>
</div>
<div id="regression-tree-model" class="section level2">
<h2>Regression Tree Model</h2>
<p>The fourth model is a regression tree and splits the data base multiple times based on various variables with respective cut-off values. After each split, subsets are created that are again divided based on another variable. The splitting stops after a predefined number of splits or other parameters that can be pre-set.
One of these parameters, is the complexity parameter (cp) that stabilizes that a split is executed, only if the cost this additional split is below its value. I optimized the model (low RMSE and high R²) for this parameter.
This model detects relationships between variables as well as nonlinear variables. Consequently, I do not need to create interaction variables myself. I use all the significant variables from the linear regression but remove the interactions between them.
On the other side, this model is not as good in detecting linear relationships and is a very unstable method due to overfitting (high variance). This means if the data changes even slightly they can fit very different models.</p>
<div id="tree-1" class="section level3">
<h3>Tree 1</h3>
<pre class="r"><code>#no need to scale the data

set.seed(12) #because I use cross-validation and want to be able to replicate the model
model_tree_1 &lt;- train(
  price ~ 
    
        #  distance_to_station #not significant
   num_tube_lines #not significant
    
    +latitude
    +longitude
    
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,
  method = &quot;rpart&quot;, 
  metric= &quot;RMSE&quot;,
  trControl = control, #I use the same as in lm  
  tuneLength= 30
  
    )

#You can view how the tree performs
model_tree_1$results</code></pre>
<pre><code>##         cp   RMSE Rsquared    MAE RMSESD RsquaredSD MAESD
## 1  0.00164 264365    0.742 141511  38949     0.0554  5740
## 2  0.00186 266556    0.738 142519  39248     0.0550  5941
## 3  0.00198 267970    0.735 143592  39405     0.0556  6322
## 4  0.00202 268254    0.735 143988  39548     0.0559  6702
## 5  0.00273 272978    0.726 147145  38766     0.0526  7032
## 6  0.00283 273553    0.725 147789  39076     0.0525  7533
## 7  0.00289 273818    0.725 148295  38975     0.0521  7398
## 8  0.00318 276656    0.719 150837  39662     0.0559  7903
## 9  0.00408 278710    0.714 152584  38184     0.0530  7414
## 10 0.00443 281791    0.708 153687  39279     0.0513  7013
## 11 0.00456 282010    0.708 153932  39086     0.0518  6708
## 12 0.00462 282636    0.707 154158  39313     0.0526  6738
## 13 0.00510 285748    0.701 155335  40228     0.0553  6965
## 14 0.00571 288520    0.695 156575  41560     0.0596  7778
## 15 0.00619 293865    0.682 157678  41021     0.0672  7851
## 16 0.00632 294350    0.680 158019  40738     0.0679  7639
## 17 0.00798 297009    0.675 162522  42001     0.0736  7525
## 18 0.00857 299525    0.670 164962  44730     0.0729  8582
## 19 0.00891 300604    0.667 165095  44285     0.0747  8356
## 20 0.00966 303419    0.659 168440  44942     0.0764  9998
## 21 0.01282 315338    0.632 174684  44254     0.0797 11046
## 22 0.01352 319583    0.621 177083  42237     0.0855 10596
## 23 0.01359 319583    0.621 177083  42237     0.0855 10596
## 24 0.01832 327989    0.601 183778  41518     0.0846  8308
## 25 0.02398 332593    0.589 185846  41072     0.0773  8996
## 26 0.03224 345498    0.563 188729  45582     0.0573  9130
## 27 0.04310 358185    0.527 196768  42264     0.0782  9802
## 28 0.07590 376073    0.474 215196  36290     0.0903 13055
## 29 0.16197 422396    0.345 235651  66448     0.0874 13000
## 30 0.31416 465807    0.276 254039  70395     0.0327 26705</code></pre>
<pre class="r"><code>#summary(model2_tree)

#You can view the final tree
rpart.plot(model_tree_1$finalModel)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/tree_model%20-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#you can also visualize the variable importance
importance &lt;- varImp(model_tree_1, scale=TRUE)
plot(importance)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/tree_model%20-2.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="tree-2" class="section level3">
<h3>Tree 2</h3>
<pre class="r"><code>#no need to scale the data

#run model
set.seed(1) #because I use cross-validation and want to be able to replicate the model
model_tree_2 &lt;- train(
  price ~ 
    
        #  distance_to_station #not significant
   num_tube_lines #not significant
    
    +latitude
    +longitude
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,
 
 
  method = &quot;rpart&quot;,
  metric=&quot;RMSE&quot;,
  trControl = control, #I use the same as in lm  
  tuneGrid= expand.grid(cp=seq(0.000, 0.0001, 0.00001))
    )

#You can view how the tree performs
model_tree_2$results</code></pre>
<pre><code>##       cp   RMSE Rsquared    MAE RMSESD RsquaredSD MAESD
## 1  0e+00 243218    0.786 117368  38730     0.0502  6176
## 2  1e-05 242872    0.787 116591  38809     0.0500  6334
## 3  2e-05 242700    0.787 116504  38766     0.0497  6220
## 4  3e-05 242835    0.787 116555  38590     0.0498  6031
## 5  4e-05 243097    0.786 117376  38655     0.0500  6023
## 6  5e-05 243311    0.785 117656  38492     0.0499  5799
## 7  6e-05 243437    0.785 117937  38576     0.0500  6003
## 8  7e-05 243507    0.785 118145  38853     0.0507  6221
## 9  8e-05 243700    0.784 118314  38962     0.0517  6125
## 10 9e-05 243853    0.784 118551  38927     0.0523  6049
## 11 1e-04 243958    0.784 118951  38977     0.0526  6112</code></pre>
<pre class="r"><code>#summary(model_tree_2)
plot(model_tree_2)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/tree_model_hypertune2%20-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#You can view the final tree
rpart.plot(model_tree_2$finalModel)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/tree_model_hypertune2%20-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#you can also visualize the variable importance
importance &lt;- varImp(model_tree_2, scale=TRUE)
plot(importance)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/tree_model_hypertune2%20-3.png" width="768" style="display: block; margin: auto;" /></p>
<p>RSquared is 0.7869522 for cp = 0.00002</p>
</div>
<div id="prediction" class="section level3">
<h3>Prediction</h3>
<pre class="r"><code># We can predict the testing values
predictions_tree &lt;- predict(model_tree_2,test_data)

tree_results&lt;-data.frame(RMSE = RMSE(predictions_tree, test_data$price), #how much did qe predict wrong
                            Rsquare = R2(predictions_tree, test_data$price)) #how much does the model cover
tree_results                         </code></pre>
<pre><code>##     RMSE Rsquare
## 1 229721     0.8</code></pre>
<p>The performance of the model (in R²):
- Training R² 0.7869522
- Testing R² is 0.8000181.</p>
<p>We need to be careful about making conclusions based on model trees because there is a high variance. This means if the data changes even slightly they can fit very different models. (you could test this using different seeds)</p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>Random Forest is an ensembled learning method that creates multiple trees and takes the average of the individual trees’ predictions as prediction. It corrects the tendency of regression trees to overfitt to their training dataset.
To optimize RMSE and R² for the random trees, I tuned the number of variables to possibly split at in each node and as split rule I selected “variance” as opposed to “extratrees”. To save computational power I used 5 as a minimum node size (which is the default option for prediction).</p>
<div id="rf-1" class="section level3">
<h3>RF 1</h3>
<pre class="r"><code>#random forest is an assembled method 

set.seed(1)
rf_fit &lt;- train(
  price ~ 
    
        #  distance_to_station #not significant
   num_tube_lines #not significant
    
    +latitude
    +longitude
    
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,
 
  
  method = &quot;ranger&quot;,
  metric=&quot;RMSE&quot;, 
  trControl = control,
  tuneLength= 10,
  importance = &#39;permutation&#39;)

print(rf_fit)</code></pre>
<pre><code>## Random Forest 
## 
## 10499 samples
##    13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   RMSE    Rsquared  MAE   
##    2    variance    326210  0.768     155557
##    2    extratrees  367703  0.710     180575
##    7    variance    219461  0.840      98794
##    7    extratrees  239633  0.815     106881
##   13    variance    206101  0.850      95272
##   13    extratrees  216523  0.838      97900
##   18    variance    203677  0.852      95053
##   18    extratrees  210693  0.844      96271
##   24    variance    202533  0.852      95173
##   24    extratrees  208625  0.845      95546
##   29    variance    202227  0.851      95203
##   29    extratrees  207037  0.847      95353
##   35    variance    201855  0.851      95260
##   35    extratrees  205923  0.848      95334
##   40    variance    202009  0.851      95441
##   40    extratrees  207782  0.844      95555
##   46    variance    202827  0.849      95701
##   46    extratrees  205341  0.848      95319
##   52    variance    202402  0.850      95710
##   52    extratrees  205920  0.846      95628
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 35, splitrule = variance
##  and min.node.size = 5.</code></pre>
<pre class="r"><code>plot(rf_fit)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/random_forest-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="rf-2" class="section level3">
<h3>RF 2</h3>
<pre class="r"><code>#random forest is an assembled method 
gridRF &lt;- data.frame(.mtry = c(25:29), .splitrule=&quot;variance&quot;, .min.node.size = 5)


set.seed(1)
rf_fit_2 &lt;- train(price~
  
   distance_to_station
   +latitude
   +longitude
    
   #+num_tube_lines #not significant
    
   # +whether_old_or_new #not significant
   +freehold_or_leasehold
  
   +district
   +property_type
   +london_zone
   +total_floor_area
   +number_habitable_rooms 
   
   +energy_consumption_potential 
   +windows_energy_eff
   +co2_emissions_potential
   +water_company,
  
    train_data, 
                                  
    method = &quot;ranger&quot;,
    metric=&quot;RMSE&quot;, #?? rmse or R²
    trControl = control, #same as lm
    tuneGrid = gridRF, # The tuneGrid parameter lets us decide which values the main parameter will take While tuneLength only limit the number of default parameters to use.
    importance = &#39;permutation&#39;,
    verbose = TRUE)

print(rf_fit_2)</code></pre>
<pre><code>## Random Forest 
## 
## 10499 samples
##    13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE    Rsquared  MAE  
##   25    208283  0.843     98899
##   26    208096  0.843     98988
##   27    207808  0.843     98923
##   28    208763  0.841     98830
##   29    208463  0.842     98984
## 
## Tuning parameter &#39;splitrule&#39; was held constant at a value of variance
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 27, splitrule = variance
##  and min.node.size = 5.</code></pre>
<pre class="r"><code>plot(rf_fit_2)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/unnamed-chunk-1-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#random forest is an assembled method 
gridRF &lt;- data.frame(.mtry = 27, .splitrule=&quot;variance&quot;, .min.node.size = 5)


set.seed(1)
rf_fit_2 &lt;- train(price~
  
   distance_to_station
   +latitude
   +longitude
    
   #+num_tube_lines #not significant
    
   # +whether_old_or_new #not significant
   +freehold_or_leasehold
  
   +district
   +property_type
   +london_zone
   +total_floor_area
   +number_habitable_rooms 
   
   +energy_consumption_potential 
   +windows_energy_eff
   +co2_emissions_potential
   +water_company,
  
    train_data, 
                                  
    method = &quot;ranger&quot;,
    metric=&quot;RMSE&quot;, #?? rmse or R²
    trControl = control, #same as lm
    tuneGrid = gridRF, # The tuneGrid parameter lets us decide which values the main parameter will take While tuneLength only limit the number of default parameters to use.
    importance = &#39;permutation&#39;,
    verbose = TRUE)

rf_fit_2</code></pre>
<pre><code>## Random Forest 
## 
## 10499 samples
##    13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results:
## 
##   RMSE    Rsquared  MAE  
##   206460  0.845     98707
## 
## Tuning parameter &#39;mtry&#39; was held constant at a value of 27
## Tuning
##  parameter &#39;splitrule&#39; was held constant at a value of variance
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5</code></pre>
</div>
<div id="prediction-rf" class="section level3">
<h3>Prediction RF</h3>
<pre class="r"><code>rf_prediction &lt;- predict(rf_fit_2, newdata = test_data)

rf_results&lt;-data.frame(RMSE = RMSE(rf_prediction, test_data$price), Rsquare = R2(rf_prediction, test_data$price))

rf_results</code></pre>
<pre><code>##     RMSE Rsquare
## 1 195090   0.854</code></pre>
</div>
</div>
<div id="gradient-boosting-machine" class="section level2">
<h2>Gradient Boosting Machine</h2>
<p>Also gradient boosting is an ensembled learning method based on trees. Gradient boosting method combines the current model with the next best possible model as long as the combined model presents a lower overall error (RMSE) than the individual model.
To optimize RMSE and R², I tune the maximum nodes per tree and the number of trees. An increasing number of trees reduces the error but could lead to over-fitting and needs much computational power. In addition, the learning rate (shrinkage) and the minimum number of observations in tree’s terminal nodes could potentially be tuned. I used a slow learn rate of 0.05 as recommended when growing trees and due to the size of my training data, 10 as minimum number of observations.</p>
<pre class="r"><code>modelLookup(&quot;gbm&quot;)</code></pre>
<pre><code>##   model         parameter                   label forReg forClass probModel
## 1   gbm           n.trees   # Boosting Iterations   TRUE     TRUE      TRUE
## 2   gbm interaction.depth          Max Tree Depth   TRUE     TRUE      TRUE
## 3   gbm         shrinkage               Shrinkage   TRUE     TRUE      TRUE
## 4   gbm    n.minobsinnode Min. Terminal Node Size   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>#Usual trainControl - take the same

#Expand the search grid (see above for definitions)
grid&lt;-expand.grid(interaction.depth = seq(4, 8, by = 2), #2. interaction.depth (Maximum nodes per tree) - number of splits it has to perform on a tree (starting from a single node).
                  n.trees = seq(500, 1500, by = 500), #Number of trees (the number of gradient boosting iteration) i.e. N. Increasing N reduces the error on training set, but setting it too high may lead to over-fitting.
                  shrinkage =0.05, #It is considered as a learning rate.Shrinkage is commonly used in ridge regression where it reduces regression coefficients to zero and, thus, reduces the impact of potentially unstable regression coefficients. , Use a small shrinkage (slow learn rate) when growing many trees. 
                  n.minobsinnode = 10)#the minimum number of observations in trees&#39; terminal nodes. Set n.minobsinnode = 10. When working with small training samples it may be vital to lower this setting to five or even three.

set.seed(1)
#Train for gbm
gbmFit1 &lt;- train(price~
    
    distance_to_station 
    +latitude
    +longitude
    
    +freehold_or_leasehold
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company,
  
     train_data,
                 
                 method = &quot;gbm&quot;, 
                 trControl = control,#same as for lm
                 tuneGrid =grid,
                   metric = &quot;RMSE&quot;,
                 verbose = TRUE
                 )</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 265118878075.1004             nan     0.0500 12077464215.9918
##      2 250728419685.8587             nan     0.0500 14150514541.3410
##      3 237642760360.4348             nan     0.0500 13378131077.3854
##      4 224159958358.7344             nan     0.0500 11925272307.8607
##      5 212263262791.2426             nan     0.0500 12705915081.1072
##      6 202219856708.4123             nan     0.0500 10148103117.1733
##      7 191904718546.2598             nan     0.0500 8042162579.5792
##      8 182958637635.2893             nan     0.0500 7545066522.9018
##      9 174726624535.3060             nan     0.0500 7644635125.9678
##     10 167871394906.0122             nan     0.0500 6847580714.1351
##     20 118639073992.5880             nan     0.0500 3524104243.4664
##     40 75484709686.7674             nan     0.0500 485757681.0967
##     60 57578768252.5955             nan     0.0500 294561854.8354
##     80 50148528986.0311             nan     0.0500 245880756.0505
##    100 46244901857.4936             nan     0.0500 105473660.2042
##    120 43587653469.7939             nan     0.0500 70849088.8487
##    140 41729024788.4822             nan     0.0500 -46123981.9816
##    160 40196775467.9338             nan     0.0500 23200176.9985
##    180 38781812514.4297             nan     0.0500 -34235468.7089
##    200 37489555485.2494             nan     0.0500 -77246886.4143
##    220 36561796575.5714             nan     0.0500 1027091.8364
##    240 35371255092.4716             nan     0.0500 -35035468.1965
##    260 34497320543.5220             nan     0.0500 -60764484.9144
##    280 33670012387.6871             nan     0.0500 -48337757.9736
##    300 32994267623.3864             nan     0.0500 -52171341.9013
##    320 32304995314.1459             nan     0.0500 -30862683.4811
##    340 31618475379.4416             nan     0.0500 7642297.2182
##    360 30973659104.9665             nan     0.0500 -25616315.4865
##    380 30420330778.3910             nan     0.0500 2315309.9350
##    400 29792180505.7759             nan     0.0500 31327111.1581
##    420 29309877788.9421             nan     0.0500 -83976091.1257
##    440 28871808867.7724             nan     0.0500 -12741842.9945
##    460 28410236706.1219             nan     0.0500 -16901564.0056
##    480 27827551572.8769             nan     0.0500 -35842458.3246
##    500 27349366544.5687             nan     0.0500 -5518562.0220
##    520 26925485951.9915             nan     0.0500 -11648270.3064
##    540 26610462475.0939             nan     0.0500 -16047018.2815
##    560 26122719720.7682             nan     0.0500 -24253826.3328
##    580 25789252246.1190             nan     0.0500 -28714804.0345
##    600 25462715222.8940             nan     0.0500 -55202105.9718
##    620 25059389144.9538             nan     0.0500 -3587293.7219
##    640 24764296731.2971             nan     0.0500 -16652985.5874
##    660 24431617588.9947             nan     0.0500 -10091845.9491
##    680 24127009889.3837             nan     0.0500 -38528725.3618
##    700 23859679985.2284             nan     0.0500 -11648939.1124
##    720 23614445525.2254             nan     0.0500 -39764619.1357
##    740 23295089776.3196             nan     0.0500 -39176825.7357
##    760 22987520287.0794             nan     0.0500 -20035172.7300
##    780 22670942612.2170             nan     0.0500 -1504892.5028
##    800 22484124207.8250             nan     0.0500 -20405313.8527
##    820 22214256891.1884             nan     0.0500 -6043586.1007
##    840 21995701976.7976             nan     0.0500 -17815073.8822
##    860 21738059221.0977             nan     0.0500 -10853093.5999
##    880 21479052054.8011             nan     0.0500 -30684659.0442
##    900 21261499427.9819             nan     0.0500 -9930240.6495
##    920 21017848123.7574             nan     0.0500 -14332640.0015
##    940 20775128458.3675             nan     0.0500 3271525.6133
##    960 20547728529.2281             nan     0.0500 -28371021.1602
##    980 20414590850.4881             nan     0.0500 -8331696.9033
##   1000 20228299271.8788             nan     0.0500 2205088.1809
##   1020 20007026043.2441             nan     0.0500 13889662.1430
##   1040 19811301313.3099             nan     0.0500 -14691864.9823
##   1060 19618869436.6212             nan     0.0500 -897667.2299
##   1080 19476991567.0469             nan     0.0500 -11637392.8156
##   1100 19311970249.9585             nan     0.0500 -19650207.5109
##   1120 19135778585.6319             nan     0.0500 -20022188.1954
##   1140 18954030379.2733             nan     0.0500 -25112574.9611
##   1160 18799967273.7812             nan     0.0500 -23524712.6612
##   1180 18665346431.2393             nan     0.0500 -24472765.2929
##   1200 18543624896.9244             nan     0.0500 -11411452.9250
##   1220 18368841884.4959             nan     0.0500 -653290.9228
##   1240 18253824338.2238             nan     0.0500 -14782882.7555
##   1260 18065793574.3297             nan     0.0500 -15375092.8049
##   1280 17869632192.8792             nan     0.0500 -18626083.8035
##   1300 17697014703.7964             nan     0.0500 -14444931.3326
##   1320 17557822885.1993             nan     0.0500 -12150374.7134
##   1340 17415299964.7209             nan     0.0500 1290232.0973
##   1360 17298441867.2524             nan     0.0500 -11776304.5583
##   1380 17168326489.1928             nan     0.0500 -4831001.8088
##   1400 17027953242.7083             nan     0.0500 1239570.4168
##   1420 16903122157.6100             nan     0.0500 -17125929.7776
##   1440 16732384782.3790             nan     0.0500 -7549810.4442
##   1460 16643172603.6599             nan     0.0500 -10165961.6772
##   1480 16524185411.7047             nan     0.0500 -19095830.9204
##   1500 16414791204.5252             nan     0.0500 -6380256.2858
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 263293004408.2946             nan     0.0500 18013739580.4925
##      2 248606500184.7868             nan     0.0500 14191029229.9133
##      3 233237848287.3221             nan     0.0500 14106162325.0338
##      4 218947803427.9325             nan     0.0500 15126108120.8793
##      5 206674285910.6352             nan     0.0500 9952185299.9761
##      6 195153649765.0098             nan     0.0500 10284468108.7262
##      7 185134774969.7502             nan     0.0500 8178882163.6879
##      8 175700891402.6022             nan     0.0500 8137104569.6431
##      9 166683026630.5045             nan     0.0500 9055378256.6734
##     10 159192757556.6932             nan     0.0500 8144793930.0765
##     20 107434937618.6672             nan     0.0500 3069267395.2437
##     40 65800814003.9553             nan     0.0500 897992414.5366
##     60 51536083587.5586             nan     0.0500 355274018.0982
##     80 45282361190.7701             nan     0.0500 45857572.6671
##    100 41655917375.6007             nan     0.0500 13924747.0510
##    120 39308656169.8316             nan     0.0500 22836867.8216
##    140 37385341688.7973             nan     0.0500 65871342.7930
##    160 35825990466.7894             nan     0.0500 -164184369.4639
##    180 34413972404.5874             nan     0.0500 -121319561.8913
##    200 33141090356.6040             nan     0.0500 -38846192.7720
##    220 31849564229.7753             nan     0.0500 3843352.4184
##    240 30763031658.9271             nan     0.0500 -50871649.7212
##    260 29730995197.1098             nan     0.0500 -6396346.2194
##    280 28796261360.3203             nan     0.0500 -26130681.5805
##    300 28122741134.6981             nan     0.0500 -20745794.5762
##    320 27470386995.1519             nan     0.0500 -37679932.9092
##    340 26824759154.7917             nan     0.0500 -4136322.7834
##    360 26214462097.7890             nan     0.0500 -48148849.2508
##    380 25626389804.3228             nan     0.0500 -52842052.5707
##    400 25042637208.2306             nan     0.0500 -54654493.5596
##    420 24425638617.9252             nan     0.0500 -51051836.6294
##    440 23926777520.1425             nan     0.0500 -44794067.0866
##    460 23475533063.8399             nan     0.0500 -39089020.5235
##    480 23055441707.2563             nan     0.0500 -27466439.5869
##    500 22615102051.7629             nan     0.0500 -33703786.0075
##    520 22243637378.1497             nan     0.0500 -35903026.4873
##    540 21854023154.1513             nan     0.0500 -19636283.0962
##    560 21449296459.6656             nan     0.0500 -37864144.9819
##    580 21055973316.3944             nan     0.0500 -12436980.2736
##    600 20751083578.6869             nan     0.0500 -15833708.0510
##    620 20442381414.4162             nan     0.0500 -23215802.6550
##    640 20099683880.0596             nan     0.0500 -24316172.4243
##    660 19746491491.7060             nan     0.0500 8574605.4781
##    680 19452198330.8931             nan     0.0500 -17497995.7597
##    700 19158424828.4751             nan     0.0500 -22417010.9774
##    720 18849003748.0161             nan     0.0500 11615525.7609
##    740 18631803456.5202             nan     0.0500 -15194172.2115
##    760 18370292188.3177             nan     0.0500 -15896562.8646
##    780 18075731496.8702             nan     0.0500 -16073430.8447
##    800 17791744866.3873             nan     0.0500 -12275109.3905
##    820 17522507574.9281             nan     0.0500 -12106739.6529
##    840 17272002696.0466             nan     0.0500 -25324385.1335
##    860 17011236071.5084             nan     0.0500 -5778520.1213
##    880 16750732750.6719             nan     0.0500 -151452.6183
##    900 16560757528.0163             nan     0.0500 -16149597.9546
##    920 16339954399.1472             nan     0.0500 -7394967.9318
##    940 16145162109.7814             nan     0.0500 -28445743.2733
##    960 15914475902.5543             nan     0.0500 -14859915.7365
##    980 15715723578.5911             nan     0.0500 3460807.9225
##   1000 15522018297.4196             nan     0.0500 -19473277.0261
##   1020 15333388469.8701             nan     0.0500 -1822916.6261
##   1040 15135444187.6899             nan     0.0500 -27995375.0178
##   1060 14953145982.6823             nan     0.0500 -13954682.1408
##   1080 14783216448.3284             nan     0.0500 -8938532.1509
##   1100 14596516276.2811             nan     0.0500 -3062466.2783
##   1120 14452067699.7072             nan     0.0500 -4574827.6124
##   1140 14301876703.9963             nan     0.0500 -12858496.5651
##   1160 14150554468.7818             nan     0.0500 1607402.4145
##   1180 13970164352.6327             nan     0.0500 -15287146.7962
##   1200 13814836991.8100             nan     0.0500 -18448892.9487
##   1220 13682911636.9982             nan     0.0500 -10535321.3509
##   1240 13566325828.2169             nan     0.0500 -12270106.2851
##   1260 13427239185.0920             nan     0.0500 -7738275.7111
##   1280 13310845345.2892             nan     0.0500 -15156057.7455
##   1300 13158748784.8310             nan     0.0500 -6724114.2525
##   1320 13018805473.8391             nan     0.0500 -5082314.6774
##   1340 12888921303.9215             nan     0.0500 6744715.4144
##   1360 12760113848.3792             nan     0.0500 2006176.3635
##   1380 12616963268.9764             nan     0.0500 -11392228.9139
##   1400 12487757370.6729             nan     0.0500 -13394944.0548
##   1420 12381129723.4138             nan     0.0500 -10139513.4518
##   1440 12278174088.9810             nan     0.0500 -2361565.7210
##   1460 12150571068.1484             nan     0.0500 -8645501.8723
##   1480 12022793707.6074             nan     0.0500 -6001037.6674
##   1500 11901827365.6807             nan     0.0500 -14544716.4813
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 263020908038.1813             nan     0.0500 15897328060.6788
##      2 246948649267.7280             nan     0.0500 17055325827.0796
##      3 231911002500.6823             nan     0.0500 14873833860.3375
##      4 218414049471.6024             nan     0.0500 12052815820.2670
##      5 205086661777.8351             nan     0.0500 10845124641.0654
##      6 192690719265.6432             nan     0.0500 11620334440.7731
##      7 183144409089.2480             nan     0.0500 10309065082.8939
##      8 172741424859.6038             nan     0.0500 9866199905.4519
##      9 162840967236.7597             nan     0.0500 7863842920.7437
##     10 154737606782.2744             nan     0.0500 6631990646.3429
##     20 99643619172.1660             nan     0.0500 3221083847.8012
##     40 59657332011.4463             nan     0.0500 827738593.3481
##     60 45947729253.6686             nan     0.0500 310069675.7467
##     80 40321206677.3281             nan     0.0500 -22332325.6873
##    100 37355649002.7825             nan     0.0500 -243477508.3377
##    120 34996017795.7311             nan     0.0500 -91557996.4275
##    140 33121642168.4369             nan     0.0500 -162828887.7089
##    160 31611354623.8092             nan     0.0500 -91466192.3305
##    180 30101227339.8599             nan     0.0500 -57313115.4044
##    200 28947502460.1353             nan     0.0500 -21160749.8024
##    220 27716199755.8983             nan     0.0500 17189716.0346
##    240 26860982150.4448             nan     0.0500 -8811383.2711
##    260 26041352936.2394             nan     0.0500 -59869533.9691
##    280 25248306829.0692             nan     0.0500 -39087074.6321
##    300 24402314971.7113             nan     0.0500 -74783692.9726
##    320 23629334577.3357             nan     0.0500 -26810154.0372
##    340 22951497616.1243             nan     0.0500 -7561352.2951
##    360 22287965241.7864             nan     0.0500 -31692841.2080
##    380 21714406275.2596             nan     0.0500 -12453709.7645
##    400 21195003876.8946             nan     0.0500 -9183457.9735
##    420 20786435780.3614             nan     0.0500 -49474324.2605
##    440 20254167925.5372             nan     0.0500 -31179244.4345
##    460 19802872694.3656             nan     0.0500 432633.5679
##    480 19418779277.1924             nan     0.0500 -25589358.6957
##    500 18921550545.3025             nan     0.0500 -31017273.1788
##    520 18484950987.2506             nan     0.0500 -44763899.0537
##    540 18076060132.7125             nan     0.0500 -7470094.8072
##    560 17750162978.0999             nan     0.0500 -10374666.5724
##    580 17335741376.9240             nan     0.0500 -26419746.3808
##    600 17040099591.5942             nan     0.0500 -39579275.5636
##    620 16748526843.4437             nan     0.0500 -28628278.5482
##    640 16471724422.5314             nan     0.0500 -9015835.9916
##    660 16177754235.6237             nan     0.0500 -15593193.2400
##    680 15913175167.4570             nan     0.0500 -14621467.8348
##    700 15583144048.6102             nan     0.0500 -1136076.4698
##    720 15276109646.8869             nan     0.0500 -20393219.8810
##    740 15024193822.5091             nan     0.0500 -22901848.3138
##    760 14795360823.3372             nan     0.0500 -11890379.2573
##    780 14583354637.5450             nan     0.0500 -13346404.7380
##    800 14359501626.4241             nan     0.0500 6089825.1123
##    820 14122819728.2746             nan     0.0500 -4572640.6524
##    840 13909867610.2111             nan     0.0500 -20368016.5726
##    860 13684954516.7690             nan     0.0500 -9020350.8794
##    880 13468987562.5299             nan     0.0500 4075084.5974
##    900 13271039605.8770             nan     0.0500 -15883510.7686
##    920 13104524901.7110             nan     0.0500 -9089703.6626
##    940 12949646271.8371             nan     0.0500 -18696868.6169
##    960 12750746731.3013             nan     0.0500 -14491784.9201
##    980 12572843394.5129             nan     0.0500 -11819077.0970
##   1000 12388513108.4990             nan     0.0500 -2957335.5630
##   1020 12217083117.0297             nan     0.0500 -13223374.8498
##   1040 12058444074.2456             nan     0.0500 -4394880.1931
##   1060 11902605188.8543             nan     0.0500 -25538234.7778
##   1080 11752937911.3014             nan     0.0500 -8927012.5760
##   1100 11579555577.5641             nan     0.0500 -14152870.3220
##   1120 11450074858.6977             nan     0.0500 -12180865.2742
##   1140 11316871078.5259             nan     0.0500 -3078582.1635
##   1160 11160536470.5500             nan     0.0500 -5483672.7463
##   1180 11044309338.2585             nan     0.0500 -3441026.3411
##   1200 10895617744.2084             nan     0.0500 -5089938.2127
##   1220 10760862899.9289             nan     0.0500 -6267551.3960
##   1240 10628379127.1557             nan     0.0500 -7020479.5868
##   1260 10503769698.6590             nan     0.0500 1827415.9129
##   1280 10370975531.8211             nan     0.0500 -2842691.9454
##   1300 10260675079.5094             nan     0.0500 -8793466.7147
##   1320 10158453748.6819             nan     0.0500 -5514085.0312
##   1340 10055826527.6125             nan     0.0500 -12315800.7584
##   1360 9954688422.7901             nan     0.0500 -5392577.1502
##   1380 9851541378.5437             nan     0.0500 -7676083.1473
##   1400 9746949919.8533             nan     0.0500 -5646382.4171
##   1420 9634015715.1186             nan     0.0500 -998370.5751
##   1440 9533245839.4805             nan     0.0500 -6347655.9474
##   1460 9441833585.3906             nan     0.0500 -5864090.4409
##   1480 9334952054.9596             nan     0.0500 -2586840.9661
##   1500 9221791309.1507             nan     0.0500 -6716625.5307
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 262496011235.4902             nan     0.0500 15541655951.0661
##      2 247706368206.1032             nan     0.0500 14133767154.9458
##      3 234040427836.8919             nan     0.0500 14106807092.3269
##      4 222374432404.1644             nan     0.0500 12550204290.8182
##      5 212086074451.4703             nan     0.0500 11015673978.7515
##      6 201105777080.6847             nan     0.0500 9440369899.1741
##      7 191409155538.6529             nan     0.0500 8175131458.9499
##      8 183605633567.8853             nan     0.0500 7962709083.9237
##      9 175930991064.3016             nan     0.0500 8043249296.1624
##     10 169852245964.8464             nan     0.0500 5498959576.4079
##     20 118046056604.1160             nan     0.0500 2985633962.1544
##     40 74347255458.5343             nan     0.0500 1105563953.4459
##     60 56373188587.3751             nan     0.0500 406538069.7341
##     80 48049268051.7453             nan     0.0500 198915254.2808
##    100 44357473413.7788             nan     0.0500 -38867064.0022
##    120 41777472813.7214             nan     0.0500 62269916.6747
##    140 39976269248.2354             nan     0.0500 -52804362.1685
##    160 38551095433.7882             nan     0.0500 -102148774.5423
##    180 37716529062.5856             nan     0.0500 -53799205.7001
##    200 36539446760.1443             nan     0.0500 -16015105.5975
##    220 35467643230.7935             nan     0.0500 -79358277.9579
##    240 34621486837.7828             nan     0.0500 -20600233.1823
##    260 33937922407.7233             nan     0.0500 -8467746.8215
##    280 33327161687.3233             nan     0.0500 -91008439.9430
##    300 32742778340.7048             nan     0.0500 -56251765.2721
##    320 32170433353.8339             nan     0.0500 -49812968.8322
##    340 31583581255.6021             nan     0.0500 -53145324.9132
##    360 31093522171.3310             nan     0.0500 -47391850.3702
##    380 30540614553.7193             nan     0.0500 17474790.8858
##    400 30096688816.1235             nan     0.0500 -61508680.4449
##    420 29701217788.6388             nan     0.0500 -38706467.9759
##    440 29097787117.0964             nan     0.0500 -31811061.9825
##    460 28725861691.1588             nan     0.0500 -32353445.4612
##    480 28295718026.4122             nan     0.0500 -51454090.3107
##    500 27967424339.4094             nan     0.0500 -38876571.4159
##    520 27570946397.8368             nan     0.0500 -55899090.3692
##    540 27195544427.4482             nan     0.0500 -65685957.7889
##    560 26758454732.8677             nan     0.0500 -38225190.3895
##    580 26403778870.7637             nan     0.0500 -46659464.1313
##    600 26024110582.0959             nan     0.0500 -31326449.2700
##    620 25619861467.7899             nan     0.0500 -26060063.9144
##    640 25338894443.1404             nan     0.0500 -6045634.1338
##    660 25060698733.1967             nan     0.0500 -19752366.7455
##    680 24723075226.5939             nan     0.0500 -14616251.3287
##    700 24423494826.5677             nan     0.0500 10389159.0605
##    720 24088416681.4734             nan     0.0500 -40411377.7706
##    740 23795775808.5421             nan     0.0500 -16111508.4765
##    760 23509644460.9172             nan     0.0500 -15211026.5983
##    780 23244088549.3596             nan     0.0500 -30684992.1353
##    800 23014828979.5321             nan     0.0500 -20220568.4767
##    820 22762171108.6307             nan     0.0500 -31715577.0616
##    840 22487837553.0163             nan     0.0500 -47742598.4462
##    860 22279099399.3226             nan     0.0500 -6935592.9250
##    880 22054012424.0028             nan     0.0500 -48797025.6453
##    900 21826871899.2334             nan     0.0500 -14612221.0198
##    920 21543393691.2661             nan     0.0500 9074059.8874
##    940 21307733361.8151             nan     0.0500 -3641968.2418
##    960 21107256194.0684             nan     0.0500 -20090740.5116
##    980 20887297560.1492             nan     0.0500 -301271.7397
##   1000 20637700196.1053             nan     0.0500 -9955099.9248
##   1020 20395681327.9811             nan     0.0500 -6243894.5668
##   1040 20216819831.9351             nan     0.0500 -18724795.4794
##   1060 20008833933.8698             nan     0.0500 -15127680.4754
##   1080 19862669874.2423             nan     0.0500 908720.3203
##   1100 19655765987.3005             nan     0.0500 -12551641.7828
##   1120 19490508477.8887             nan     0.0500 2499446.4985
##   1140 19317738982.4944             nan     0.0500 -16028641.9900
##   1160 19183751328.9235             nan     0.0500 -8423514.9405
##   1180 19024943742.7911             nan     0.0500 -12070972.6813
##   1200 18844229139.5567             nan     0.0500 -29401489.6747
##   1220 18681344554.4124             nan     0.0500 -38136930.6679
##   1240 18548141567.7630             nan     0.0500 25918.8474
##   1260 18396237903.9819             nan     0.0500 -24465826.0572
##   1280 18250597744.4665             nan     0.0500 -3484253.0150
##   1300 18102614661.2325             nan     0.0500 -18328701.2226
##   1320 17952524367.5327             nan     0.0500 -9561799.3369
##   1340 17807330064.8424             nan     0.0500 -13260056.0287
##   1360 17667766622.9766             nan     0.0500 -14078726.2931
##   1380 17542232996.6726             nan     0.0500 -14889103.3863
##   1400 17392250043.3474             nan     0.0500 -17706347.9195
##   1420 17246576650.5438             nan     0.0500 -12287472.8303
##   1440 17099471581.8611             nan     0.0500 -7669764.7286
##   1460 16948203897.0554             nan     0.0500 -9414144.7861
##   1480 16827265602.5223             nan     0.0500 -15162288.0032
##   1500 16681388856.0026             nan     0.0500 -14052514.3749
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 259705281293.8161             nan     0.0500 15545594956.6175
##      2 243606530928.6775             nan     0.0500 14604313747.0201
##      3 231127939454.6131             nan     0.0500 13811915126.9583
##      4 219118320781.7937             nan     0.0500 13464394192.6783
##      5 206004778928.5830             nan     0.0500 12885659073.3654
##      6 194545979217.2047             nan     0.0500 10574534136.5884
##      7 184168483776.3476             nan     0.0500 10276084958.8511
##      8 175874239234.3291             nan     0.0500 6492255393.0636
##      9 167159888848.5244             nan     0.0500 8423370406.9467
##     10 159182636091.8912             nan     0.0500 7554477424.5777
##     20 107436826740.1401             nan     0.0500 3407819052.8837
##     40 63485993627.3966             nan     0.0500 877431521.6446
##     60 49016678467.1808             nan     0.0500 368794615.9821
##     80 43073885761.3892             nan     0.0500 46090398.8200
##    100 39915585450.5605             nan     0.0500 -43992345.0341
##    120 37691491469.1495             nan     0.0500 -35898507.8826
##    140 35888870936.8405             nan     0.0500 -67801917.4602
##    160 34582044014.5399             nan     0.0500 -8390632.8491
##    180 33222347298.9741             nan     0.0500 -12419633.1656
##    200 32078556553.3404             nan     0.0500 -54016258.1282
##    220 31129499347.6936             nan     0.0500 -6433276.7979
##    240 30240392402.1418             nan     0.0500 -22842793.1109
##    260 29366501253.7992             nan     0.0500 -38711735.9356
##    280 28556661094.9676             nan     0.0500 -47742707.7211
##    300 27796871121.5401             nan     0.0500 -23251679.8305
##    320 27054711397.7406             nan     0.0500 -41490505.8284
##    340 26554154783.6236             nan     0.0500 -5988152.0274
##    360 25816354980.4271             nan     0.0500 -34556413.1488
##    380 25162341820.5164             nan     0.0500 -2986098.0311
##    400 24676239672.8186             nan     0.0500 -20149083.5138
##    420 24182541003.2951             nan     0.0500 -66376227.0801
##    440 23761327938.9573             nan     0.0500 -15418460.7383
##    460 23307111332.3317             nan     0.0500 -10442648.9442
##    480 22889853417.4610             nan     0.0500 -22893739.7275
##    500 22422740815.6437             nan     0.0500 -34035787.3736
##    520 21882572904.5404             nan     0.0500 20806615.7079
##    540 21524090705.3022             nan     0.0500 -29473273.1220
##    560 21184258177.1575             nan     0.0500 -3448797.8929
##    580 20838389651.2509             nan     0.0500 -37121337.0361
##    600 20483690775.0167             nan     0.0500 -51277227.0927
##    620 20143308933.5054             nan     0.0500 -22860962.5905
##    640 19876199349.5472             nan     0.0500 -69603436.2800
##    660 19606953927.6439             nan     0.0500 13172348.1651
##    680 19288672615.0452             nan     0.0500 -41815367.8126
##    700 19005773958.1951             nan     0.0500 -9007375.3534
##    720 18687251341.9565             nan     0.0500 -17557504.7619
##    740 18448378599.1555             nan     0.0500 -21368736.1875
##    760 18176258232.9279             nan     0.0500 6026880.2550
##    780 17955199722.4715             nan     0.0500 -7048335.5177
##    800 17732138970.3678             nan     0.0500 -17666561.6618
##    820 17461441398.0551             nan     0.0500 -24349601.8463
##    840 17259858546.1396             nan     0.0500 -22962422.7611
##    860 17030345329.8776             nan     0.0500 -15721154.7822
##    880 16759638603.1601             nan     0.0500 -21911.6465
##    900 16544524465.5431             nan     0.0500 -13566695.6455
##    920 16335520171.4785             nan     0.0500 -26684707.3370
##    940 16142672769.3984             nan     0.0500 -15511937.8653
##    960 15948812340.9312             nan     0.0500 -8554571.2485
##    980 15748934758.1318             nan     0.0500 -14745589.9406
##   1000 15528674738.2546             nan     0.0500 -14303269.0977
##   1020 15326973267.9885             nan     0.0500 -8428121.1489
##   1040 15155151626.1790             nan     0.0500 -21128148.4802
##   1060 14962850282.6003             nan     0.0500 -3848569.8497
##   1080 14781006668.9417             nan     0.0500 -28501235.5437
##   1100 14598704903.6255             nan     0.0500 -17002154.5164
##   1120 14416037058.4835             nan     0.0500 -6175896.5326
##   1140 14284152258.7263             nan     0.0500 -8397869.9142
##   1160 14106733091.0188             nan     0.0500 -5821409.1440
##   1180 13958539918.4158             nan     0.0500 -5214299.5002
##   1200 13812995814.2202             nan     0.0500 -12824739.4300
##   1220 13644341864.5757             nan     0.0500 -7064029.1529
##   1240 13499337681.3250             nan     0.0500 -16837544.5369
##   1260 13358239401.7835             nan     0.0500 -16549670.8406
##   1280 13195648036.3499             nan     0.0500 -11176089.7096
##   1300 13060758315.1870             nan     0.0500 -12401749.6939
##   1320 12914021704.4098             nan     0.0500 -9547087.7188
##   1340 12789397552.7339             nan     0.0500 281807.0544
##   1360 12659246667.0838             nan     0.0500 -18637191.4152
##   1380 12515118800.3825             nan     0.0500 -7043981.4733
##   1400 12379793497.5177             nan     0.0500 -3444909.4379
##   1420 12240605735.7845             nan     0.0500 -9836539.6092
##   1440 12110865160.7194             nan     0.0500 1151650.4699
##   1460 11988012115.2993             nan     0.0500 -7725731.5445
##   1480 11869820707.1399             nan     0.0500 -4570135.8302
##   1500 11768828162.9721             nan     0.0500 3116203.6851
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258468399451.8250             nan     0.0500 17887846872.7125
##      2 242087362758.0534             nan     0.0500 13469084921.3420
##      3 227287910794.5264             nan     0.0500 14704201991.3707
##      4 214444952014.9381             nan     0.0500 12930269449.0225
##      5 201368327222.8546             nan     0.0500 13573159188.8448
##      6 189131127408.9401             nan     0.0500 9803183808.5446
##      7 178897310239.7106             nan     0.0500 11119942639.6775
##      8 170023396560.6435             nan     0.0500 9291898981.0245
##      9 161396220402.7297             nan     0.0500 7066397926.1768
##     10 152983105499.7485             nan     0.0500 8621381938.4563
##     20 98369359473.6217             nan     0.0500 3522815968.9261
##     40 57339881523.7197             nan     0.0500 537639320.9332
##     60 44196100159.3079             nan     0.0500 297808527.0907
##     80 39003826871.5515             nan     0.0500 98543281.8305
##    100 36316763823.5594             nan     0.0500 9839850.4110
##    120 34058532977.0727             nan     0.0500 -86641745.6385
##    140 32219310285.3015             nan     0.0500 -47606119.3741
##    160 30820272635.9873             nan     0.0500 -49420524.4744
##    180 29515846018.8198             nan     0.0500 -91187110.3599
##    200 28406681013.2220             nan     0.0500 -17781774.3431
##    220 27339264184.1477             nan     0.0500 62103883.6478
##    240 26552610334.0114             nan     0.0500 -22877557.9745
##    260 25723566221.7130             nan     0.0500 -58341827.7480
##    280 24928646335.0801             nan     0.0500 1189301.2916
##    300 24193188028.5682             nan     0.0500 -983705.0541
##    320 23498934356.7824             nan     0.0500 -78844211.6509
##    340 22750463881.0690             nan     0.0500 -7424599.9875
##    360 22181763272.5869             nan     0.0500 -29094542.4492
##    380 21656268331.2456             nan     0.0500 -30580476.8667
##    400 21144848093.2693             nan     0.0500 -31511547.6756
##    420 20627955170.6287             nan     0.0500 -19120591.5639
##    440 20138842384.1745             nan     0.0500 -34775036.6637
##    460 19650592555.5520             nan     0.0500 -12269335.9637
##    480 19204548733.4565             nan     0.0500 3504858.7369
##    500 18744925814.0346             nan     0.0500 -15665599.1820
##    520 18375179497.4081             nan     0.0500 -21018400.3750
##    540 18017318352.4130             nan     0.0500 -13751175.5724
##    560 17642885450.6924             nan     0.0500 -16119345.9844
##    580 17303011805.6005             nan     0.0500 -32537320.4228
##    600 16957767926.2450             nan     0.0500 -41803234.7216
##    620 16664957347.0740             nan     0.0500 -54077326.5038
##    640 16382024710.8307             nan     0.0500 -19796160.4389
##    660 16069974457.7272             nan     0.0500 -10445603.6313
##    680 15760832569.9342             nan     0.0500 -18258085.8265
##    700 15525508350.6624             nan     0.0500 -25829036.9391
##    720 15237322326.0282             nan     0.0500 -9445854.4053
##    740 14979992276.4879             nan     0.0500 -18498352.6166
##    760 14742107024.9963             nan     0.0500 -21646253.5853
##    780 14494364119.7831             nan     0.0500 -12719216.6710
##    800 14257285430.6568             nan     0.0500 -26077425.2345
##    820 14080849283.7785             nan     0.0500 -15857032.1346
##    840 13884799122.0213             nan     0.0500 -16045677.9656
##    860 13668158633.6469             nan     0.0500 -8711168.9979
##    880 13432607354.9458             nan     0.0500 -9239223.5013
##    900 13256196525.9304             nan     0.0500 -11638315.0629
##    920 13097587374.5066             nan     0.0500 -12206450.4391
##    940 12919639364.5952             nan     0.0500 -7581256.1497
##    960 12748820569.0554             nan     0.0500 -10210629.4637
##    980 12537610379.5749             nan     0.0500 -13505963.1325
##   1000 12368775418.0127             nan     0.0500 -32872432.8273
##   1020 12192664368.9665             nan     0.0500 -5640781.4623
##   1040 12013243345.5345             nan     0.0500 -8908787.9795
##   1060 11870603326.9598             nan     0.0500 -21079668.0139
##   1080 11722729826.1507             nan     0.0500 -5350905.3707
##   1100 11581748398.8369             nan     0.0500 -14151117.3274
##   1120 11423320907.6039             nan     0.0500 -8167265.9464
##   1140 11288617419.2114             nan     0.0500 -12976626.5855
##   1160 11146046921.6663             nan     0.0500 2724477.8690
##   1180 11010422920.2166             nan     0.0500 -9423412.5729
##   1200 10896915354.5572             nan     0.0500 -7124206.9123
##   1220 10771028307.9420             nan     0.0500 -16011495.7982
##   1240 10614580033.6708             nan     0.0500 -8422517.2163
##   1260 10479462479.3006             nan     0.0500 -5310043.7228
##   1280 10356265577.8950             nan     0.0500 -9104621.2312
##   1300 10253273826.2481             nan     0.0500 -6356969.9559
##   1320 10157674444.3959             nan     0.0500 -2937608.1467
##   1340 10055193632.0723             nan     0.0500 591297.0586
##   1360 9956577099.2972             nan     0.0500 -11622109.4922
##   1380 9860595602.6639             nan     0.0500 -12051922.9573
##   1400 9755298817.8833             nan     0.0500 -4824936.8856
##   1420 9653685819.5013             nan     0.0500 -4610537.8633
##   1440 9563337153.3621             nan     0.0500 -7110346.7339
##   1460 9461632483.2030             nan     0.0500 -9976792.1404
##   1480 9371608331.7034             nan     0.0500 -8411503.2275
##   1500 9288898825.6178             nan     0.0500 -6350134.0257
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 260229491985.2115             nan     0.0500 15252348102.9177
##      2 245572419001.9522             nan     0.0500 16284433018.1517
##      3 230804851104.7589             nan     0.0500 12997953865.0955
##      4 218262533097.8822             nan     0.0500 11258222486.8590
##      5 207554899303.8446             nan     0.0500 10109515370.4134
##      6 197732718195.2049             nan     0.0500 8995434426.4052
##      7 189021123816.7050             nan     0.0500 9200997947.6430
##      8 180447427819.7920             nan     0.0500 7893374409.3547
##      9 173317059823.0333             nan     0.0500 7549199725.2134
##     10 165839769963.2982             nan     0.0500 6693513656.9041
##     20 116206608397.3645             nan     0.0500 3611008498.0148
##     40 74288727236.7715             nan     0.0500 997872095.1209
##     60 57165989495.5638             nan     0.0500 316920955.9189
##     80 49117693016.7104             nan     0.0500 133716845.0185
##    100 45346909922.1954             nan     0.0500 88819927.7961
##    120 42929072238.0888             nan     0.0500 -71709359.9174
##    140 41230212319.1844             nan     0.0500 105510548.0376
##    160 39992611278.0549             nan     0.0500 -93603338.1385
##    180 38677033945.3751             nan     0.0500 19229618.8750
##    200 37537979304.5827             nan     0.0500 -116363381.2404
##    220 36526963184.4235             nan     0.0500 -10441267.2072
##    240 35818811479.0461             nan     0.0500 -63752192.2313
##    260 35046658584.3463             nan     0.0500 -109593595.4983
##    280 34091895186.0243             nan     0.0500 -45422539.9407
##    300 33363956240.4032             nan     0.0500 24067624.8738
##    320 32760291802.5571             nan     0.0500 -35663973.7007
##    340 32240137834.1427             nan     0.0500 9313795.7023
##    360 31527745735.7596             nan     0.0500 -9036028.3724
##    380 30932449749.0447             nan     0.0500 19440800.9636
##    400 30405593467.8182             nan     0.0500 -52904038.7401
##    420 29886072145.5412             nan     0.0500 -24609839.3514
##    440 29423610357.8286             nan     0.0500 -74948136.8178
##    460 29047203774.4144             nan     0.0500 -34037236.1103
##    480 28689228160.6502             nan     0.0500 -48888338.9342
##    500 28261892337.7234             nan     0.0500 -39122423.3111
##    520 27861801077.5140             nan     0.0500 -9492905.6095
##    540 27503529296.3522             nan     0.0500 -56889284.0575
##    560 27067814910.8176             nan     0.0500 -22410446.7111
##    580 26576008833.5477             nan     0.0500 -19385082.9944
##    600 26222502674.9689             nan     0.0500 -20646591.2773
##    620 25872758814.3298             nan     0.0500 -11875695.3828
##    640 25576570487.9752             nan     0.0500 -38411781.8918
##    660 25247637987.4786             nan     0.0500 -30431248.0750
##    680 24828069788.6947             nan     0.0500 -68309751.3971
##    700 24556356699.8025             nan     0.0500 -47841299.9087
##    720 24248460547.0512             nan     0.0500 -889395.8021
##    740 23941207568.4535             nan     0.0500 -62369502.0038
##    760 23615553099.4088             nan     0.0500 -3117068.5712
##    780 23294944250.3342             nan     0.0500 -3561889.0401
##    800 23031590070.8699             nan     0.0500 -36308610.3451
##    820 22721622801.5738             nan     0.0500 -18136499.7060
##    840 22349268271.8085             nan     0.0500 -39492146.8226
##    860 22118512424.7808             nan     0.0500 -7515467.9907
##    880 21880561215.5991             nan     0.0500 -10079387.3844
##    900 21635988711.6352             nan     0.0500 -20634324.3887
##    920 21412803170.4495             nan     0.0500 -22901721.3878
##    940 21187395587.9658             nan     0.0500 -38267229.5550
##    960 20984654094.5545             nan     0.0500 2455386.3456
##    980 20780923195.1526             nan     0.0500 -9351622.1269
##   1000 20606502143.2313             nan     0.0500 -200605.4842
##   1020 20380474166.2267             nan     0.0500 -17314675.3207
##   1040 20202863231.9272             nan     0.0500 -7789164.2680
##   1060 20017221498.3619             nan     0.0500 -5810375.6402
##   1080 19850882584.6141             nan     0.0500 -9555301.6786
##   1100 19676001375.7034             nan     0.0500 -2955783.4127
##   1120 19502126144.4844             nan     0.0500 -5782239.2459
##   1140 19354639515.9174             nan     0.0500 -15215044.3917
##   1160 19207775071.2133             nan     0.0500 -111933.2463
##   1180 19026558993.1890             nan     0.0500 -15821437.9316
##   1200 18847335459.6894             nan     0.0500 -21292116.1083
##   1220 18685631166.9944             nan     0.0500 -7365699.2813
##   1240 18545768833.7883             nan     0.0500 -21160041.2902
##   1260 18398304206.1651             nan     0.0500 -19591871.5330
##   1280 18210920531.3819             nan     0.0500 -25384897.9848
##   1300 18046303119.4458             nan     0.0500 -10088323.9039
##   1320 17869952500.3277             nan     0.0500 -8150520.2445
##   1340 17735771844.9060             nan     0.0500 -8693612.0398
##   1360 17558530835.9016             nan     0.0500 -30177901.8982
##   1380 17442029464.9935             nan     0.0500 -24453117.4649
##   1400 17312188241.3568             nan     0.0500 -23656624.1351
##   1420 17151692877.0628             nan     0.0500 -5702578.8739
##   1440 17014134709.0184             nan     0.0500 5712636.4807
##   1460 16910601740.6968             nan     0.0500 -4540183.6930
##   1480 16763493595.5793             nan     0.0500 -805280.1652
##   1500 16630887554.8016             nan     0.0500 -5360852.1210
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 257462567728.0022             nan     0.0500 15664526003.1509
##      2 242715651252.9531             nan     0.0500 15459960692.8236
##      3 228836003326.7213             nan     0.0500 15285163015.7446
##      4 217434066504.9101             nan     0.0500 12371162143.9438
##      5 205997200055.4737             nan     0.0500 10937230815.8186
##      6 196312281746.8504             nan     0.0500 10193369350.8444
##      7 185299045539.7079             nan     0.0500 9981190592.6337
##      8 176227786925.8785             nan     0.0500 8350178825.0096
##      9 167617408607.4595             nan     0.0500 7262693820.4730
##     10 160199556762.2589             nan     0.0500 7004461957.6509
##     20 106666542037.5370             nan     0.0500 3725311815.3446
##     40 64442298333.3237             nan     0.0500 928609063.6493
##     60 50067890588.7459             nan     0.0500 239399834.0627
##     80 43933574289.0312             nan     0.0500 205370691.9155
##    100 40253486386.8192             nan     0.0500 -95111005.0518
##    120 38007527510.4797             nan     0.0500 8121855.2740
##    140 36088648419.0938             nan     0.0500 -77183096.7287
##    160 34668757528.9800             nan     0.0500 -94517438.6441
##    180 33392858941.4699             nan     0.0500 -29758531.8612
##    200 32192451695.2913             nan     0.0500 -25170176.1430
##    220 31091466582.1423             nan     0.0500 -68577217.1089
##    240 29926997546.3735             nan     0.0500 -915223.1538
##    260 28955627939.8923             nan     0.0500 -13626976.8676
##    280 28136164401.2993             nan     0.0500 -42890716.0949
##    300 27424403570.0240             nan     0.0500 -55973989.8931
##    320 26720697836.9002             nan     0.0500 -14815548.8234
##    340 26064244913.8851             nan     0.0500 -4182754.1282
##    360 25392366422.1542             nan     0.0500 -27758966.5216
##    380 24875604149.2221             nan     0.0500 -9531675.9330
##    400 24336573505.0037             nan     0.0500 -5004316.4515
##    420 23917604602.1759             nan     0.0500 -40099001.6001
##    440 23485408786.5311             nan     0.0500 -46187280.8666
##    460 22942287277.2591             nan     0.0500 -17861661.8919
##    480 22544837028.9301             nan     0.0500 -34789317.5941
##    500 22091036777.9245             nan     0.0500 -27399634.1690
##    520 21709109895.3516             nan     0.0500 12654433.0715
##    540 21309295432.3852             nan     0.0500 -1994473.2630
##    560 20960428292.5805             nan     0.0500 -28237252.4723
##    580 20574422226.0340             nan     0.0500 -7197169.4170
##    600 20268146044.4329             nan     0.0500 -14773621.8559
##    620 19970451503.9160             nan     0.0500 -18016324.1648
##    640 19721986067.6528             nan     0.0500 -8579141.6327
##    660 19434280670.3786             nan     0.0500 -35525024.7594
##    680 19073376884.2580             nan     0.0500 -2375554.8440
##    700 18831034384.9789             nan     0.0500 -9121685.8230
##    720 18550596633.8803             nan     0.0500 -16463007.4026
##    740 18306144896.8179             nan     0.0500 -12782122.9468
##    760 18066487585.0312             nan     0.0500 -24231494.4457
##    780 17777162163.3238             nan     0.0500 -6597104.9998
##    800 17541668424.6213             nan     0.0500 -631643.1665
##    820 17291520016.5313             nan     0.0500 -21179460.4602
##    840 17042948042.7155             nan     0.0500 -47686029.6004
##    860 16816112984.9977             nan     0.0500 -9317458.5994
##    880 16601561655.2925             nan     0.0500 -24478035.8727
##    900 16368833717.8300             nan     0.0500 -14258219.4526
##    920 16128593382.2291             nan     0.0500 -11211291.8664
##    940 15898376857.4353             nan     0.0500 -14818098.9122
##    960 15680479289.2979             nan     0.0500 2628316.3486
##    980 15489082640.6165             nan     0.0500 -11658832.2901
##   1000 15318233783.4415             nan     0.0500 -18311063.2153
##   1020 15117766853.9968             nan     0.0500 -19074404.6662
##   1040 14946985237.7568             nan     0.0500 -23972372.9691
##   1060 14761378642.7628             nan     0.0500 -7120751.3152
##   1080 14590629083.4835             nan     0.0500 -4107717.7795
##   1100 14436158377.2230             nan     0.0500 -15774880.0568
##   1120 14258498838.9580             nan     0.0500 5458034.5787
##   1140 14088793143.5772             nan     0.0500 -8034646.6849
##   1160 13963346098.3519             nan     0.0500 -8493296.4577
##   1180 13807586406.0702             nan     0.0500 -286470.1557
##   1200 13654271988.7883             nan     0.0500 -11064753.2521
##   1220 13522879479.6282             nan     0.0500 -7907280.6774
##   1240 13406710612.1448             nan     0.0500 -11382444.0412
##   1260 13270648137.2584             nan     0.0500 -14740042.8239
##   1280 13167820191.4572             nan     0.0500 -17468473.9115
##   1300 13048552467.6262             nan     0.0500 -12563278.0937
##   1320 12941800501.4462             nan     0.0500 -15121066.4509
##   1340 12816841424.0117             nan     0.0500 -5385257.4178
##   1360 12703056497.5178             nan     0.0500 -18961698.3517
##   1380 12564074467.5349             nan     0.0500 -8188117.0424
##   1400 12458076524.8881             nan     0.0500 1531055.6688
##   1420 12335847305.0125             nan     0.0500 -14658139.9556
##   1440 12236148835.1028             nan     0.0500 -11165427.3796
##   1460 12125779101.6737             nan     0.0500 -5741376.6482
##   1480 12024950028.4645             nan     0.0500 -13470768.5391
##   1500 11907286756.9108             nan     0.0500 -5131287.5436
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 255753317248.3520             nan     0.0500 15051072093.0012
##      2 239640079174.0162             nan     0.0500 17965984355.9028
##      3 225037275989.9686             nan     0.0500 14449067008.3711
##      4 211925646608.2646             nan     0.0500 11818022175.6861
##      5 199794945799.3810             nan     0.0500 12236373890.2609
##      6 187803023887.0146             nan     0.0500 10441035287.1251
##      7 178269620715.9462             nan     0.0500 10876457685.1654
##      8 169691159186.3121             nan     0.0500 8372624951.9159
##      9 160591663481.9470             nan     0.0500 9366088703.0469
##     10 152528128756.6138             nan     0.0500 7857767282.0754
##     20 98694476063.3101             nan     0.0500 3864054163.4586
##     40 59373252537.8892             nan     0.0500 762280044.6457
##     60 46029995890.9798             nan     0.0500 272187109.7773
##     80 39717833668.9185             nan     0.0500 43622085.5538
##    100 36761848040.2877             nan     0.0500 -63967318.8166
##    120 34529369339.4654             nan     0.0500 42251136.2294
##    140 32861519867.2520             nan     0.0500 -18643293.1060
##    160 31431793983.7275             nan     0.0500 -42726185.3666
##    180 30042274354.7748             nan     0.0500 -47564727.7184
##    200 28887797406.3015             nan     0.0500 -124097981.4514
##    220 27855485195.3409             nan     0.0500 -50498010.2760
##    240 26860281229.0190             nan     0.0500 -928817.5466
##    260 25925995492.6869             nan     0.0500 -83128456.9703
##    280 25100367732.7201             nan     0.0500 -12559714.6102
##    300 24372008624.9420             nan     0.0500 -12636709.7615
##    320 23649332091.5049             nan     0.0500 12952704.2095
##    340 22978642279.1168             nan     0.0500 -7666643.0442
##    360 22385139747.8890             nan     0.0500 -43554199.2576
##    380 21775614296.7472             nan     0.0500 -9352517.8841
##    400 21243011487.4316             nan     0.0500 -33793065.1370
##    420 20750905618.2698             nan     0.0500 -31877057.8367
##    440 20282893438.1178             nan     0.0500 -40750880.2652
##    460 19781532728.4558             nan     0.0500 -18538789.6669
##    480 19287353114.7313             nan     0.0500 -8407737.6950
##    500 18837247313.0190             nan     0.0500 -42543274.8061
##    520 18376294777.4265             nan     0.0500 -5344742.7365
##    540 18042552102.9961             nan     0.0500 -20239442.7936
##    560 17621169673.7871             nan     0.0500 -27065067.4343
##    580 17301545349.8012             nan     0.0500 -7326162.9823
##    600 16941904812.0197             nan     0.0500 -33194642.3300
##    620 16674193928.3200             nan     0.0500 -22452611.5254
##    640 16327776489.0428             nan     0.0500 -20466787.1279
##    660 16053177479.8951             nan     0.0500 -29694954.0960
##    680 15760395269.2701             nan     0.0500 -11619078.7077
##    700 15461690307.9453             nan     0.0500 -27026186.7988
##    720 15178339077.1978             nan     0.0500 -13720894.3760
##    740 14919290543.5661             nan     0.0500 -18276887.4817
##    760 14682433358.7469             nan     0.0500 -20615392.2988
##    780 14423027832.5969             nan     0.0500 -10770489.3580
##    800 14187176440.5854             nan     0.0500 -33879607.7912
##    820 13991238342.1605             nan     0.0500 -19381359.2964
##    840 13789602354.5656             nan     0.0500 -19687004.4509
##    860 13563342576.4858             nan     0.0500 -16480636.8357
##    880 13327222067.9006             nan     0.0500 -30951182.9793
##    900 13166172426.3244             nan     0.0500 -7289768.3793
##    920 12982364380.0917             nan     0.0500 -17863903.9471
##    940 12797789304.2691             nan     0.0500 37815.4226
##    960 12619844624.1388             nan     0.0500 -11354597.4307
##    980 12476905357.0968             nan     0.0500 -8994372.1314
##   1000 12334263879.8444             nan     0.0500 -16019183.6116
##   1020 12169529455.6339             nan     0.0500 -11139602.3206
##   1040 11993827681.7093             nan     0.0500 -4202292.7185
##   1060 11847718473.2104             nan     0.0500 -5719789.0144
##   1080 11675940569.3136             nan     0.0500 -9327700.2545
##   1100 11536312720.8837             nan     0.0500 -21045265.5610
##   1120 11390149299.4745             nan     0.0500 -12443107.0329
##   1140 11259308873.0678             nan     0.0500 -2173339.8251
##   1160 11112417894.9884             nan     0.0500 -212029.6043
##   1180 10966536413.6297             nan     0.0500 -11164801.3007
##   1200 10813807385.1566             nan     0.0500 -6379769.5996
##   1220 10690076767.9883             nan     0.0500 -13371350.4733
##   1240 10557409259.7721             nan     0.0500 -9153701.5124
##   1260 10438648146.6014             nan     0.0500 -7393853.4384
##   1280 10326396531.3816             nan     0.0500 -12599117.9987
##   1300 10201487859.5145             nan     0.0500 -5680580.4496
##   1320 10088843380.3736             nan     0.0500 -11063151.5061
##   1340 9979064121.0805             nan     0.0500 -2493145.4406
##   1360 9889569181.0334             nan     0.0500 -2048873.6844
##   1380 9768771731.0366             nan     0.0500 -8528922.5585
##   1400 9671349946.7535             nan     0.0500 6795787.0948
##   1420 9570780705.9354             nan     0.0500 -5336671.2332
##   1440 9461823561.1218             nan     0.0500 -2263225.9165
##   1460 9366598207.1254             nan     0.0500 -7273094.8271
##   1480 9260212531.0512             nan     0.0500 2652376.1120
##   1500 9175976816.3850             nan     0.0500 -9459342.0828
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 260975933325.3763             nan     0.0500 18175823005.6958
##      2 247334875950.9948             nan     0.0500 12445042213.3294
##      3 233336045386.5390             nan     0.0500 12263080321.2033
##      4 221045977875.3291             nan     0.0500 10676956416.8044
##      5 209630752972.8223             nan     0.0500 10565784515.9798
##      6 200101546339.0479             nan     0.0500 8288448435.4883
##      7 190874327563.0057             nan     0.0500 9824980034.6694
##      8 182853576638.5069             nan     0.0500 8348813492.3918
##      9 174191576361.7823             nan     0.0500 7296195719.7175
##     10 167766171340.7907             nan     0.0500 6622140995.9402
##     20 117325431677.1398             nan     0.0500 3055179325.3850
##     40 73576301377.8708             nan     0.0500 824115350.0011
##     60 56823846378.7269             nan     0.0500 490424369.2668
##     80 49294118090.4332             nan     0.0500 -109969246.9804
##    100 45740292015.5711             nan     0.0500 132362440.4166
##    120 43324992227.1390             nan     0.0500 -37172585.3537
##    140 41702101442.6740             nan     0.0500 -55186460.9818
##    160 40195272192.7500             nan     0.0500 554133.4180
##    180 38937173884.4668             nan     0.0500 -51645523.3112
##    200 37819755043.3550             nan     0.0500 39845843.5122
##    220 36788926457.6528             nan     0.0500 43307807.5685
##    240 35589705775.7746             nan     0.0500 -7478961.9513
##    260 34747481509.5026             nan     0.0500 -23335872.9482
##    280 33761782303.7686             nan     0.0500 -66309838.7696
##    300 33191533995.0173             nan     0.0500 -58362111.8618
##    320 32574157675.3204             nan     0.0500 -102150709.7637
##    340 31994927452.0782             nan     0.0500 -790329.5703
##    360 31324758918.5821             nan     0.0500 -40290147.9363
##    380 30832664947.1725             nan     0.0500 -663123.7103
##    400 30215630580.7962             nan     0.0500 -51542206.5548
##    420 29619589905.4541             nan     0.0500 -103356357.6106
##    440 29113103266.4626             nan     0.0500 -64350134.8607
##    460 28587540757.3473             nan     0.0500 -67973860.2562
##    480 28134593334.2755             nan     0.0500 -51665440.5321
##    500 27689154645.2185             nan     0.0500 -23604230.6737
##    520 27390524976.7385             nan     0.0500 -24769776.3231
##    540 26966276189.2321             nan     0.0500 -83695697.8665
##    560 26542513322.8010             nan     0.0500 -7651039.3719
##    580 26157167470.5917             nan     0.0500 1662885.2383
##    600 25845735330.7830             nan     0.0500 -58360236.9656
##    620 25559357002.9688             nan     0.0500 -78913887.4745
##    640 25162834517.6046             nan     0.0500 -12178424.5311
##    660 24933092482.3416             nan     0.0500 -48182322.5812
##    680 24615095409.5469             nan     0.0500 -41678663.8871
##    700 24320279541.1859             nan     0.0500 7765555.9158
##    720 24078087983.2846             nan     0.0500 -21810482.5834
##    740 23792624792.5725             nan     0.0500 -26173962.1864
##    760 23550258000.2565             nan     0.0500 -10724809.6558
##    780 23311834096.5743             nan     0.0500 -22332808.1275
##    800 23035030525.6992             nan     0.0500 -3524004.9113
##    820 22821552071.2717             nan     0.0500 -55392600.4067
##    840 22622968611.0851             nan     0.0500 -47726964.8396
##    860 22307374667.9381             nan     0.0500 -12119932.8574
##    880 22055190635.4030             nan     0.0500 -24713522.1131
##    900 21836318956.6770             nan     0.0500 -19904692.3678
##    920 21604254827.3272             nan     0.0500 -5361411.4725
##    940 21401675919.3476             nan     0.0500 -11326150.8209
##    960 21175154362.8655             nan     0.0500 -28055496.1759
##    980 20982110583.1013             nan     0.0500 -14421023.9287
##   1000 20755648694.2141             nan     0.0500 -37257788.9350
##   1020 20557784009.7906             nan     0.0500 -7119166.0463
##   1040 20368265928.1020             nan     0.0500 -24440650.1234
##   1060 20211807745.8461             nan     0.0500 -19158855.2140
##   1080 20077893336.0125             nan     0.0500 -15971109.7693
##   1100 19915111073.5349             nan     0.0500 -26708908.1020
##   1120 19759417479.4537             nan     0.0500 -24630476.7788
##   1140 19549852657.6792             nan     0.0500 -23432984.1350
##   1160 19399113995.3826             nan     0.0500 5665016.8902
##   1180 19279550069.1792             nan     0.0500 -4592042.1417
##   1200 19132468767.8848             nan     0.0500 -19583812.5693
##   1220 18967717803.6934             nan     0.0500 -14920637.4485
##   1240 18813462060.8939             nan     0.0500 -12176856.0868
##   1260 18625358161.8093             nan     0.0500 -23042258.1056
##   1280 18412212510.6721             nan     0.0500 -26943349.9754
##   1300 18209907642.5974             nan     0.0500 -13079156.7881
##   1320 18059491038.9483             nan     0.0500 200727.4639
##   1340 17920301169.7400             nan     0.0500 -27108591.6514
##   1360 17801639510.1270             nan     0.0500 -2717185.8896
##   1380 17650848212.4907             nan     0.0500 -5536223.9270
##   1400 17531434532.8705             nan     0.0500 -867463.3893
##   1420 17368595264.0891             nan     0.0500 -7475533.4178
##   1440 17222613013.0063             nan     0.0500 -9341733.9693
##   1460 17066867325.5107             nan     0.0500 -9303144.5782
##   1480 16924749792.9946             nan     0.0500 -35829653.0093
##   1500 16767600666.7181             nan     0.0500 -9690646.1240
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 262174790022.3857             nan     0.0500 16327345095.4584
##      2 246206641110.8828             nan     0.0500 14778257744.0634
##      3 232097587597.3284             nan     0.0500 14007804766.0978
##      4 218990903234.2192             nan     0.0500 11219471846.8169
##      5 206843459115.8377             nan     0.0500 11369038124.0628
##      6 196313136338.1389             nan     0.0500 12028233507.5462
##      7 186218926004.7817             nan     0.0500 10367359245.9204
##      8 177229822909.4780             nan     0.0500 8451195163.0607
##      9 168772684422.5472             nan     0.0500 7890760237.5315
##     10 160928394062.5210             nan     0.0500 7659417195.0589
##     20 107182297656.1432             nan     0.0500 2930108804.3057
##     40 65648380319.4334             nan     0.0500 907149231.8432
##     60 50720766627.3308             nan     0.0500 289048645.4984
##     80 44988196495.2261             nan     0.0500 60543532.3778
##    100 42039733898.2793             nan     0.0500 -148157641.4700
##    120 39475728870.6003             nan     0.0500 -51228305.3862
##    140 37735997003.4529             nan     0.0500 -144309151.5413
##    160 36097233111.2355             nan     0.0500 51029544.9909
##    180 34719294534.5174             nan     0.0500 -81133573.1492
##    200 33570861451.9813             nan     0.0500 -68460588.1153
##    220 32214454978.1045             nan     0.0500 27595747.5978
##    240 31126391724.0549             nan     0.0500 -16732619.1101
##    260 30134044824.3159             nan     0.0500 -99874241.2090
##    280 29424303824.1083             nan     0.0500 -38563024.9027
##    300 28716581328.3739             nan     0.0500 -11307559.9949
##    320 27882104366.6301             nan     0.0500 -19477175.4551
##    340 27192376898.5606             nan     0.0500 -54771662.8114
##    360 26633727990.0906             nan     0.0500 -63286112.0340
##    380 25942799618.2679             nan     0.0500 -7132745.0805
##    400 25395261998.8425             nan     0.0500 -43404957.9401
##    420 24871590997.7398             nan     0.0500 -55491994.9679
##    440 24347512941.8229             nan     0.0500 -49358394.0777
##    460 23842053369.7375             nan     0.0500 -24526719.9628
##    480 23337657719.5374             nan     0.0500 8203613.3380
##    500 22904842227.0174             nan     0.0500 -56025827.3196
##    520 22477321327.9477             nan     0.0500 -61474327.9982
##    540 22038963937.9346             nan     0.0500 -43464026.3985
##    560 21640249932.7715             nan     0.0500 -30689601.3813
##    580 21254694544.7592             nan     0.0500 -37878647.6080
##    600 20884342068.3194             nan     0.0500 -31159075.7000
##    620 20536894584.0080             nan     0.0500 10255632.6091
##    640 20227363223.1924             nan     0.0500 -43757575.3094
##    660 19933279854.8529             nan     0.0500 -37169997.0948
##    680 19624289879.7078             nan     0.0500 -26935858.7404
##    700 19329118177.5476             nan     0.0500 -24741842.1354
##    720 19028964471.8219             nan     0.0500 -11660164.9636
##    740 18777482965.7193             nan     0.0500 -19405884.4537
##    760 18524654340.6427             nan     0.0500 -24301934.0415
##    780 18295923287.7749             nan     0.0500 -25555059.1518
##    800 18031655234.8664             nan     0.0500 -9901084.2190
##    820 17836889408.4035             nan     0.0500 -19085903.1338
##    840 17604523188.3219             nan     0.0500 -22957946.1078
##    860 17399053683.9839             nan     0.0500 -1466927.7145
##    880 17117930932.1689             nan     0.0500 -26817656.8703
##    900 16897993748.1521             nan     0.0500 -23052794.0490
##    920 16656644068.7822             nan     0.0500 -20483283.4835
##    940 16458621370.8245             nan     0.0500 -10837841.4028
##    960 16254523713.4128             nan     0.0500 -21986095.2213
##    980 16056244104.5571             nan     0.0500 -20497964.8210
##   1000 15843882025.8394             nan     0.0500 -17573587.3855
##   1020 15633585141.3831             nan     0.0500 -4251148.1761
##   1040 15467965652.4097             nan     0.0500 9656736.9887
##   1060 15294726756.9453             nan     0.0500 -18606703.5090
##   1080 15083707269.2644             nan     0.0500 -25522403.9293
##   1100 14894302285.1019             nan     0.0500 4881911.4512
##   1120 14720210441.5045             nan     0.0500 2104582.1384
##   1140 14573757164.2627             nan     0.0500 -16347401.7176
##   1160 14397658121.9504             nan     0.0500 -4410125.3414
##   1180 14265631138.2666             nan     0.0500 -24969846.4037
##   1200 14153265328.5816             nan     0.0500 -12765493.3920
##   1220 14009497999.5603             nan     0.0500 -13483868.7297
##   1240 13865083838.0636             nan     0.0500 -4988915.4990
##   1260 13724847146.4794             nan     0.0500 -10873743.6371
##   1280 13589882761.3676             nan     0.0500 -22440339.5737
##   1300 13451012928.1545             nan     0.0500 -11329887.4195
##   1320 13302893612.6819             nan     0.0500 -10568568.5882
##   1340 13158677860.4942             nan     0.0500 -10405035.4033
##   1360 13017516229.6315             nan     0.0500 -3424824.0311
##   1380 12900011952.7427             nan     0.0500 6495407.4968
##   1400 12774959929.4822             nan     0.0500 -8866788.5825
##   1420 12658478401.2907             nan     0.0500 -9645638.4785
##   1440 12542591625.5143             nan     0.0500 6808321.9539
##   1460 12418712596.5012             nan     0.0500 -2869346.9378
##   1480 12289311978.1818             nan     0.0500 -6158856.4023
##   1500 12199356773.0678             nan     0.0500 -15030331.6990
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 259328024535.2764             nan     0.0500 18172569011.7695
##      2 243121776551.3655             nan     0.0500 15387996425.8311
##      3 228602210462.9976             nan     0.0500 13601844679.6273
##      4 215365070351.4677             nan     0.0500 12431764848.6120
##      5 203211250325.9725             nan     0.0500 12836988251.7026
##      6 192094528926.2636             nan     0.0500 10886661296.1718
##      7 181663855189.2198             nan     0.0500 10560564091.6737
##      8 171528803854.6305             nan     0.0500 10654761137.9262
##      9 162180809706.7899             nan     0.0500 8455107506.2972
##     10 153953340160.2045             nan     0.0500 6875588384.8685
##     20 100492317778.7768             nan     0.0500 2833699815.5768
##     40 59980030291.0483             nan     0.0500 1005790457.1743
##     60 46772966630.6099             nan     0.0500 199301167.4548
##     80 41512138096.3502             nan     0.0500 193202220.1887
##    100 37988631576.6546             nan     0.0500 -77080304.1964
##    120 35438005215.2382             nan     0.0500 -158124035.9746
##    140 33456133412.0521             nan     0.0500 -117478045.1128
##    160 32061115725.0016             nan     0.0500 -121299021.8745
##    180 30688533044.5156             nan     0.0500 -106666622.8630
##    200 29414529785.1793             nan     0.0500 -142502727.4673
##    220 28235124221.6266             nan     0.0500 -108796485.5343
##    240 27236701425.3956             nan     0.0500 -66868009.7207
##    260 26383508937.5277             nan     0.0500 -29559478.5451
##    280 25620678732.5426             nan     0.0500 -57001013.9824
##    300 24782817883.0750             nan     0.0500 -39469203.9738
##    320 23938972887.9470             nan     0.0500 -32383321.8806
##    340 23308058653.8384             nan     0.0500 -32620574.1525
##    360 22654839501.6304             nan     0.0500 2471581.2006
##    380 22079479388.8194             nan     0.0500 -28340661.4269
##    400 21481903462.7229             nan     0.0500 -53366476.6256
##    420 20948301333.9343             nan     0.0500 -28992127.0452
##    440 20465517872.0632             nan     0.0500 -563562.2195
##    460 20020468220.0618             nan     0.0500 -42144898.8075
##    480 19546639980.8565             nan     0.0500 -622158.8543
##    500 19097613282.9067             nan     0.0500 -37482489.2854
##    520 18728244980.9543             nan     0.0500 -24163471.8273
##    540 18340283153.7246             nan     0.0500 -31335606.5029
##    560 17995350681.8050             nan     0.0500 -26342476.6314
##    580 17630072591.0756             nan     0.0500 -8000772.0471
##    600 17268809592.7946             nan     0.0500 -33478804.9363
##    620 16913296376.8417             nan     0.0500 -23032882.6070
##    640 16555325476.4797             nan     0.0500 -5681162.5924
##    660 16310606360.2495             nan     0.0500 -14909224.6767
##    680 16019763147.8987             nan     0.0500 9939146.2151
##    700 15768051213.2364             nan     0.0500 -21254183.3932
##    720 15500117999.1450             nan     0.0500 3951822.6041
##    740 15240095389.6665             nan     0.0500 -1127089.8778
##    760 15029291674.1579             nan     0.0500 -15241812.3261
##    780 14753271998.1622             nan     0.0500 -13297909.7178
##    800 14547008446.8702             nan     0.0500 -10288117.0932
##    820 14362384781.9466             nan     0.0500 -16734144.8214
##    840 14141109369.6536             nan     0.0500 -16300402.6650
##    860 13960786172.4850             nan     0.0500 -16715027.7050
##    880 13740832679.9920             nan     0.0500 -19936962.2223
##    900 13537828379.4869             nan     0.0500 -21797353.5336
##    920 13344047715.0660             nan     0.0500 -8807894.3935
##    940 13153747004.1705             nan     0.0500 -11357031.2949
##    960 12960621513.6235             nan     0.0500 -14184773.8904
##    980 12793068554.8939             nan     0.0500 -4418966.6606
##   1000 12608449584.5880             nan     0.0500 -20471309.7654
##   1020 12450765155.2292             nan     0.0500 -6898105.3963
##   1040 12276543111.3372             nan     0.0500 -6545760.0697
##   1060 12150162227.5506             nan     0.0500 -5449046.4147
##   1080 11982844361.5500             nan     0.0500 -5682562.7903
##   1100 11836277572.2169             nan     0.0500 -14895191.1783
##   1120 11699144539.2550             nan     0.0500 -4858159.8282
##   1140 11560328820.0769             nan     0.0500 -15149054.0131
##   1160 11410111456.0674             nan     0.0500 -10790978.3949
##   1180 11242684545.5577             nan     0.0500 -5511166.8255
##   1200 11113389946.7975             nan     0.0500 -7062398.4723
##   1220 11000777839.9641             nan     0.0500 -18484618.7240
##   1240 10870041036.3081             nan     0.0500 -13961848.4771
##   1260 10741750098.6724             nan     0.0500 -3669599.5104
##   1280 10610129359.1057             nan     0.0500 1017583.7040
##   1300 10501686677.6482             nan     0.0500 -5433688.6336
##   1320 10366341690.4559             nan     0.0500 -3496901.7771
##   1340 10262248772.5925             nan     0.0500 -17258095.9258
##   1360 10163918187.5345             nan     0.0500 -15553878.5273
##   1380 10055761173.1027             nan     0.0500 -10796552.3899
##   1400 9954284593.3360             nan     0.0500 -7723204.6881
##   1420 9850728179.1063             nan     0.0500 -8030818.1766
##   1440 9739900215.6395             nan     0.0500 -8582010.8697
##   1460 9631720596.6972             nan     0.0500 -3119799.9790
##   1480 9529016437.7638             nan     0.0500 -1071804.6062
##   1500 9433179228.5464             nan     0.0500 -7448839.5640
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 246540041242.7248             nan     0.0500 14501280338.6512
##      2 233026324518.6146             nan     0.0500 14251995561.1824
##      3 220697848393.4014             nan     0.0500 10792968394.2835
##      4 209611291969.5905             nan     0.0500 10484359584.9495
##      5 199203121751.4777             nan     0.0500 7774348445.6973
##      6 189925631021.4776             nan     0.0500 8295166491.4524
##      7 180981923716.2787             nan     0.0500 7149498861.9553
##      8 172569535502.9793             nan     0.0500 8503973365.0660
##      9 165152627783.3111             nan     0.0500 7024077461.5155
##     10 157754212182.3015             nan     0.0500 5580097567.6089
##     20 111591526860.8770             nan     0.0500 3583871592.7844
##     40 69783246463.2636             nan     0.0500 1114752380.3915
##     60 54150214845.8428             nan     0.0500 288457555.7665
##     80 47593717768.1008             nan     0.0500 182597234.0353
##    100 44049002005.7853             nan     0.0500 -91434895.5848
##    120 41846327100.0516             nan     0.0500 -1527479.4607
##    140 40376534347.0895             nan     0.0500 -51609417.9954
##    160 39098831636.1764             nan     0.0500 -58963399.4535
##    180 37906542188.6168             nan     0.0500 62455775.5332
##    200 36786019980.3931             nan     0.0500 -19970818.1520
##    220 35815147725.7555             nan     0.0500 -56192720.4271
##    240 35186648672.4353             nan     0.0500 -54017148.7895
##    260 34362276741.8043             nan     0.0500 -125505455.1657
##    280 33599194270.6005             nan     0.0500 -6481479.7866
##    300 32754102713.8803             nan     0.0500 -18387559.9323
##    320 31953317795.4914             nan     0.0500 -23432997.8988
##    340 31274556764.6811             nan     0.0500 -13347162.5650
##    360 30699873785.8034             nan     0.0500 -58869744.2025
##    380 30132249082.6653             nan     0.0500 -49202101.1770
##    400 29656340108.0568             nan     0.0500 -45991127.3725
##    420 29181380812.6662             nan     0.0500 -10028521.1042
##    440 28818394186.4711             nan     0.0500 -35676543.8767
##    460 28447589885.5269             nan     0.0500 -62457831.9899
##    480 27916995685.8135             nan     0.0500 -40600747.7917
##    500 27448468699.0536             nan     0.0500 -11567943.8012
##    520 27109588913.1359             nan     0.0500 -3851771.1342
##    540 26642168393.3934             nan     0.0500 -31401782.4693
##    560 26309799861.5115             nan     0.0500 -32985952.7795
##    580 25918261399.9460             nan     0.0500 -102974872.8177
##    600 25544279084.5294             nan     0.0500 8211890.3640
##    620 25311355501.1832             nan     0.0500 -8814392.6482
##    640 24936113831.6425             nan     0.0500 -42684541.8465
##    660 24662764924.0583             nan     0.0500 -16932351.2285
##    680 24299030848.4475             nan     0.0500 -3428025.9223
##    700 23952240312.4164             nan     0.0500 -30400064.7728
##    720 23736400254.5018             nan     0.0500 -38399532.5360
##    740 23425335927.3472             nan     0.0500 -10872622.7691
##    760 23163130942.9061             nan     0.0500 -8705157.6285
##    780 22976746722.0339             nan     0.0500 -35169829.6979
##    800 22782600208.4534             nan     0.0500 -39081279.4212
##    820 22600858874.5932             nan     0.0500 -22537855.9450
##    840 22295016661.9651             nan     0.0500 -37315469.7385
##    860 22021139535.9194             nan     0.0500 -21045012.3585
##    880 21802540767.4281             nan     0.0500 -28439200.6897
##    900 21543915738.6577             nan     0.0500 -15513535.1037
##    920 21301053517.4294             nan     0.0500 461536.4318
##    940 21114261883.8193             nan     0.0500 -20290401.3120
##    960 20897773001.2938             nan     0.0500 -34186930.0268
##    980 20720193738.4406             nan     0.0500 -18920792.4167
##   1000 20496377863.8981             nan     0.0500 -24045266.7087
##   1020 20332872362.4063             nan     0.0500 -14680654.7520
##   1040 20153372348.5303             nan     0.0500 -6401188.0798
##   1060 19960749560.7018             nan     0.0500 -13212389.3661
##   1080 19757106560.8166             nan     0.0500 -11177733.8483
##   1100 19536077018.4426             nan     0.0500 -18609683.8224
##   1120 19350953330.0899             nan     0.0500 -22831594.8012
##   1140 19173870950.6089             nan     0.0500 -23224075.0661
##   1160 19051172515.1480             nan     0.0500 -7119044.8627
##   1180 18877381448.9705             nan     0.0500 -24805176.7150
##   1200 18721265942.7258             nan     0.0500 -7407957.5302
##   1220 18565811852.6435             nan     0.0500 -15738721.1592
##   1240 18415446007.8682             nan     0.0500 7135697.7047
##   1260 18276050002.3078             nan     0.0500 -17068119.3946
##   1280 18147315116.7630             nan     0.0500 -14850293.5963
##   1300 18013360094.9309             nan     0.0500 -11209976.3861
##   1320 17890283441.7003             nan     0.0500 7995679.6774
##   1340 17757302942.4268             nan     0.0500 -4203457.2871
##   1360 17658089645.3173             nan     0.0500 -6417439.0860
##   1380 17497166266.9673             nan     0.0500 -21894893.7667
##   1400 17336044569.0993             nan     0.0500 -18312187.6139
##   1420 17209204233.0713             nan     0.0500 -20315518.0854
##   1440 17052877371.7372             nan     0.0500 3969585.2062
##   1460 16900117328.1838             nan     0.0500 -11076510.5170
##   1480 16772177993.7314             nan     0.0500 -16196394.3861
##   1500 16636945313.7803             nan     0.0500 -15849694.0340
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 244127558157.8876             nan     0.0500 13004703826.5830
##      2 229326132538.4482             nan     0.0500 12794774805.3561
##      3 216075841941.9083             nan     0.0500 12955980164.7774
##      4 204278185701.4473             nan     0.0500 12662776645.7497
##      5 193223343286.5376             nan     0.0500 11973329527.5442
##      6 183029044807.6972             nan     0.0500 9333174231.7580
##      7 173868946097.3840             nan     0.0500 7988289259.7503
##      8 165447936290.5393             nan     0.0500 8147516779.0772
##      9 157799532359.6198             nan     0.0500 6758785721.0146
##     10 149983918320.0465             nan     0.0500 5240406659.0847
##     20 101097989648.1510             nan     0.0500 3531346734.3219
##     40 61351643002.1496             nan     0.0500 846739848.6932
##     60 47500635381.4020             nan     0.0500 127532263.5926
##     80 42312261319.1166             nan     0.0500 69023190.6091
##    100 39259607187.0003             nan     0.0500 -3074371.1594
##    120 36881487616.0087             nan     0.0500 36095417.5541
##    140 35206534181.4722             nan     0.0500 -41051645.0480
##    160 33689743917.6479             nan     0.0500 -4382098.4955
##    180 32539288822.5741             nan     0.0500 -65447779.3194
##    200 31482754891.4435             nan     0.0500 -94632572.2597
##    220 30637165025.5159             nan     0.0500 -97875816.4947
##    240 29672913343.0878             nan     0.0500 -47593423.9280
##    260 28807741220.9146             nan     0.0500 -35684118.8785
##    280 28152281666.9085             nan     0.0500 -61668833.7196
##    300 27427591057.7688             nan     0.0500 -31703738.8363
##    320 26699997499.8602             nan     0.0500 -27519747.1312
##    340 26110576770.2249             nan     0.0500 -30160204.7551
##    360 25467026666.7961             nan     0.0500 -28052482.7094
##    380 24888202840.2241             nan     0.0500 -34144224.9719
##    400 24367638767.7409             nan     0.0500 -8571304.4060
##    420 23852490765.0124             nan     0.0500 4485229.1468
##    440 23370574885.3158             nan     0.0500 -20498359.4026
##    460 22952062683.8744             nan     0.0500 -29889197.4691
##    480 22484032746.8054             nan     0.0500 -265122.0926
##    500 22054345649.6292             nan     0.0500 -4329580.3031
##    520 21615309242.3003             nan     0.0500 -7509129.6520
##    540 21260225163.7102             nan     0.0500 1168564.1827
##    560 20890565681.0870             nan     0.0500 -26927963.0011
##    580 20610953797.6300             nan     0.0500 5450160.7296
##    600 20209306395.0103             nan     0.0500 -15931591.9098
##    620 19856399157.2728             nan     0.0500 -15038966.9409
##    640 19499634611.9791             nan     0.0500 -10417555.4250
##    660 19192331955.6707             nan     0.0500 -18694626.9020
##    680 18928182171.1635             nan     0.0500 -11739558.6663
##    700 18592961841.0171             nan     0.0500 -26543960.2053
##    720 18287255847.8877             nan     0.0500 -20208236.0324
##    740 17985848898.0830             nan     0.0500 -6796286.4460
##    760 17709038887.5561             nan     0.0500 28882974.7138
##    780 17444814234.6208             nan     0.0500 -17018743.3659
##    800 17214551859.5335             nan     0.0500 8426130.6976
##    820 16977726266.6079             nan     0.0500 -16122553.9334
##    840 16754204995.2970             nan     0.0500 -39686511.0184
##    860 16556228447.3095             nan     0.0500 -14018818.4044
##    880 16318370075.7578             nan     0.0500 -25771052.0758
##    900 16110239585.3717             nan     0.0500 -15668501.7971
##    920 15914748812.8533             nan     0.0500 -5735536.2291
##    940 15752346545.6617             nan     0.0500 -20203018.1407
##    960 15532583217.6238             nan     0.0500 -11990041.4889
##    980 15374776526.1216             nan     0.0500 -17160148.5178
##   1000 15191584654.5519             nan     0.0500 -21738244.3451
##   1020 15027989921.8937             nan     0.0500 -17277840.4844
##   1040 14840687080.2223             nan     0.0500 -15167809.6294
##   1060 14703918455.6141             nan     0.0500 -14463915.4131
##   1080 14564916836.8214             nan     0.0500 -18082230.3826
##   1100 14375651466.3584             nan     0.0500 -16008466.8956
##   1120 14215456161.2878             nan     0.0500 -4039826.5147
##   1140 14060304104.3556             nan     0.0500 -11247887.5031
##   1160 13894432995.7702             nan     0.0500 -24609141.7489
##   1180 13776762532.5109             nan     0.0500 -11732104.2937
##   1200 13650299063.6509             nan     0.0500 -10395151.3879
##   1220 13520810681.1628             nan     0.0500 -17295917.6418
##   1240 13390825821.4513             nan     0.0500 -8652281.8813
##   1260 13260149519.5920             nan     0.0500 -1356509.8057
##   1280 13085939145.8814             nan     0.0500 -2815191.9287
##   1300 12962796534.6581             nan     0.0500 -11429161.8080
##   1320 12858244982.1317             nan     0.0500 -5521923.2912
##   1340 12746063223.1003             nan     0.0500 -13806452.0945
##   1360 12625243698.7917             nan     0.0500 1680107.3738
##   1380 12516150311.4219             nan     0.0500 -11058097.8922
##   1400 12424165089.5900             nan     0.0500 861731.9117
##   1420 12301241301.9952             nan     0.0500 -3038848.4324
##   1440 12184400251.4220             nan     0.0500 1464251.4561
##   1460 12073326592.9358             nan     0.0500 -4277927.0227
##   1480 11968405233.9190             nan     0.0500 -3420662.8000
##   1500 11858420018.0865             nan     0.0500 -5960298.8378
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 243836412604.1834             nan     0.0500 15437054516.2069
##      2 228528111771.7418             nan     0.0500 16302670835.3184
##      3 214850860963.5244             nan     0.0500 13578458108.9808
##      4 201401352620.5847             nan     0.0500 11175217159.2356
##      5 188675206185.8349             nan     0.0500 13202233461.4550
##      6 177272038610.2029             nan     0.0500 10794943802.1034
##      7 168104952552.6789             nan     0.0500 10761622943.7464
##      8 158916398870.0820             nan     0.0500 7422243471.8705
##      9 150971473949.0257             nan     0.0500 7454195232.6954
##     10 143400448564.0033             nan     0.0500 6088578090.3758
##     20 94388703476.0643             nan     0.0500 2921739240.6962
##     40 56712395653.3978             nan     0.0500 1031941659.5684
##     60 44814048247.7220             nan     0.0500 354803206.9012
##     80 39345125915.6138             nan     0.0500 118939316.6099
##    100 36031288487.4859             nan     0.0500 -71291572.3149
##    120 33916639462.7867             nan     0.0500 -3387855.6168
##    140 32443304954.6404             nan     0.0500 -123375748.4574
##    160 30900779973.6880             nan     0.0500 -71839784.1188
##    180 29420616828.3802             nan     0.0500 -79802062.1166
##    200 28178359844.5916             nan     0.0500 -38015615.8453
##    220 27139747868.7006             nan     0.0500 -90126686.1209
##    240 26253931709.1113             nan     0.0500 -61115152.3279
##    260 25413675806.1125             nan     0.0500 -17163877.7506
##    280 24630094842.3240             nan     0.0500 -43046165.7344
##    300 24057777190.0527             nan     0.0500 -77204090.4150
##    320 23415896729.3110             nan     0.0500 -2514672.6387
##    340 22901045538.0802             nan     0.0500 2892311.1201
##    360 22317825684.6749             nan     0.0500 -40017007.7486
##    380 21739037319.0968             nan     0.0500 -8201474.3081
##    400 21252073428.1492             nan     0.0500 -24297333.8964
##    420 20732206987.1258             nan     0.0500 -21695778.3926
##    440 20192841394.0598             nan     0.0500 -23126442.2198
##    460 19767270998.3150             nan     0.0500 -19902877.8351
##    480 19315078846.8571             nan     0.0500 -10188136.9708
##    500 18950776432.8499             nan     0.0500 -21414816.4467
##    520 18635363985.7650             nan     0.0500 -34769598.2164
##    540 18252500824.3083             nan     0.0500 -28300686.0890
##    560 17928785826.5991             nan     0.0500 -3230027.3034
##    580 17521477477.2473             nan     0.0500 -18994303.3166
##    600 17179959820.0766             nan     0.0500 -5651435.4991
##    620 16874774028.2342             nan     0.0500 -12813793.6978
##    640 16630820687.3682             nan     0.0500 -12379034.9453
##    660 16337678608.8075             nan     0.0500 -16132513.2941
##    680 16079302682.3021             nan     0.0500 -21959776.3256
##    700 15785280937.8677             nan     0.0500 -7442888.7900
##    720 15533404145.9038             nan     0.0500 -27484216.6705
##    740 15275479462.1993             nan     0.0500 -23582725.7760
##    760 15036335351.3145             nan     0.0500 2125206.3499
##    780 14787186344.9481             nan     0.0500 -1681899.6145
##    800 14596529904.1995             nan     0.0500 -38818726.1288
##    820 14374431102.6037             nan     0.0500 -15002797.0050
##    840 14149356167.1505             nan     0.0500 -10545156.7524
##    860 13945507632.4071             nan     0.0500 -14957117.9405
##    880 13740664424.7721             nan     0.0500 -7405801.3467
##    900 13549729594.0666             nan     0.0500 5809747.1231
##    920 13326826105.0122             nan     0.0500 -18110405.4225
##    940 13142073314.9284             nan     0.0500 -16139914.5907
##    960 12950980315.4973             nan     0.0500 -18181531.3451
##    980 12761227977.0607             nan     0.0500 -13018010.5923
##   1000 12557767234.3401             nan     0.0500 4485061.9192
##   1020 12401859694.6773             nan     0.0500 -9243627.6817
##   1040 12264220414.1977             nan     0.0500 -7153465.7021
##   1060 12065391634.5350             nan     0.0500 -6013228.1689
##   1080 11942406810.3067             nan     0.0500 -18169750.9784
##   1100 11803745267.2815             nan     0.0500 -19052643.5658
##   1120 11676207855.8328             nan     0.0500 -12945657.3955
##   1140 11532802175.3880             nan     0.0500 -347526.8980
##   1160 11397258896.1029             nan     0.0500 -16558091.4159
##   1180 11261513491.4860             nan     0.0500 -1614342.1286
##   1200 11144216195.7331             nan     0.0500 -4183290.2522
##   1220 11000879000.9836             nan     0.0500 -5238629.4319
##   1240 10879303462.1899             nan     0.0500 -3251885.5199
##   1260 10732695793.0053             nan     0.0500 -13173490.3807
##   1280 10616615503.9165             nan     0.0500 -7601386.9969
##   1300 10508475419.1527             nan     0.0500 -8351192.7632
##   1320 10386599394.4931             nan     0.0500 -6664554.9447
##   1340 10259670245.5431             nan     0.0500 -12761172.3227
##   1360 10134109342.4555             nan     0.0500 -8578744.2558
##   1380 10022564481.4308             nan     0.0500 -3021261.6384
##   1400 9912444360.1642             nan     0.0500 -4597856.6937
##   1420 9810968547.7176             nan     0.0500 -1516110.3875
##   1440 9707961569.1140             nan     0.0500 -4184206.0334
##   1460 9584524048.4724             nan     0.0500 -5508760.4617
##   1480 9484556925.7822             nan     0.0500 -10574537.6949
##   1500 9396692898.6434             nan     0.0500 -10955030.0664
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 260264893647.2052             nan     0.0500 17296315592.6689
##      2 247038090829.2964             nan     0.0500 13583949116.5222
##      3 233086559669.8362             nan     0.0500 12084436379.4957
##      4 221562371030.6758             nan     0.0500 12241128622.4127
##      5 210736722991.4995             nan     0.0500 9757144045.4161
##      6 201418083620.0138             nan     0.0500 9774297816.6987
##      7 193056237698.7715             nan     0.0500 8652288105.3103
##      8 184625233927.7574             nan     0.0500 7576091799.8767
##      9 175482281016.7662             nan     0.0500 8249461778.7539
##     10 167979178446.2324             nan     0.0500 6580392124.7450
##     20 117219561503.8852             nan     0.0500 3564549255.9632
##     40 75162832107.7774             nan     0.0500 690458594.6982
##     60 57881363496.4149             nan     0.0500 431266917.2281
##     80 50010779054.6518             nan     0.0500 88084581.9966
##    100 45743753350.7804             nan     0.0500 9875002.8044
##    120 43301760868.9735             nan     0.0500 47797343.3961
##    140 41476101501.7038             nan     0.0500 8779719.5769
##    160 40053858850.4367             nan     0.0500 -37098952.6369
##    180 38939794656.8313             nan     0.0500 13328962.7398
##    200 38008656040.3847             nan     0.0500 -18769376.4341
##    220 36795638134.0751             nan     0.0500 10491595.0728
##    240 35795662984.0965             nan     0.0500 -85977740.7374
##    260 35176036509.3471             nan     0.0500 -50436881.9450
##    280 34366402488.2236             nan     0.0500 -72063179.4618
##    300 33561389731.3738             nan     0.0500 -65612755.6780
##    320 32808686542.1825             nan     0.0500 -17536406.2409
##    340 32206202911.1730             nan     0.0500 -60357353.8266
##    360 31479541358.2722             nan     0.0500 36250464.1323
##    380 31035761407.2283             nan     0.0500 -42097247.7907
##    400 30477311912.5681             nan     0.0500 -14473133.5152
##    420 29826676882.0419             nan     0.0500 26676.2796
##    440 29260830748.2968             nan     0.0500 -37964101.5166
##    460 28783460400.6865             nan     0.0500 -5121210.4226
##    480 28296395317.0810             nan     0.0500 -8176693.5606
##    500 27888834647.4847             nan     0.0500 -6183440.2743
##    520 27488224458.9213             nan     0.0500 -609652.2804
##    540 27014200950.5877             nan     0.0500 -20370428.4009
##    560 26570069769.9830             nan     0.0500 -19479404.8276
##    580 26211624314.3592             nan     0.0500 -17598030.7380
##    600 25814595344.4525             nan     0.0500 -36574022.1754
##    620 25506372906.0686             nan     0.0500 -16352774.5907
##    640 25193758033.7768             nan     0.0500 -41466005.0975
##    660 24829437716.6001             nan     0.0500 -60374160.0898
##    680 24572030135.3551             nan     0.0500 -41774443.7455
##    700 24264663790.3882             nan     0.0500 -30804509.5683
##    720 23950818059.2511             nan     0.0500 -24182796.7753
##    740 23694310367.7552             nan     0.0500 -30140711.0291
##    760 23421373256.2464             nan     0.0500 -11018287.3387
##    780 23160930247.3833             nan     0.0500 -18966186.9787
##    800 22923533488.2674             nan     0.0500 -33241828.5840
##    820 22627308869.9134             nan     0.0500 -14152120.2879
##    840 22347501701.7299             nan     0.0500 6161562.5611
##    860 22115839998.7504             nan     0.0500 -10119642.3104
##    880 21926551731.0953             nan     0.0500 -20014257.2504
##    900 21702457281.9325             nan     0.0500 -11447902.3997
##    920 21430937598.5359             nan     0.0500 -2805318.3901
##    940 21259782182.4439             nan     0.0500 -16714778.5277
##    960 21092356268.4072             nan     0.0500 -4598530.9569
##    980 20886622843.2333             nan     0.0500 -18316414.3310
##   1000 20718395138.1400             nan     0.0500 -10049828.0502
##   1020 20496933049.2126             nan     0.0500 -18853193.7370
##   1040 20292327792.1027             nan     0.0500 -17827710.9113
##   1060 20071130384.3031             nan     0.0500 -21516034.8597
##   1080 19920237047.2437             nan     0.0500 -26458413.3606
##   1100 19752362168.0402             nan     0.0500 -29264296.9063
##   1120 19556246742.6159             nan     0.0500 3660442.2517
##   1140 19338439348.6118             nan     0.0500 -2728158.8416
##   1160 19161178784.5871             nan     0.0500 -27516636.4924
##   1180 19015790993.5882             nan     0.0500 -22697557.9146
##   1200 18846160353.1123             nan     0.0500 -18145679.8139
##   1220 18701897982.2261             nan     0.0500 -42344515.9844
##   1240 18533363212.6910             nan     0.0500 5183123.0711
##   1260 18362265764.2952             nan     0.0500 -23872683.7828
##   1280 18236988438.7535             nan     0.0500 -17135078.8080
##   1300 18056688904.1328             nan     0.0500 -19350518.9848
##   1320 17919411210.7019             nan     0.0500 -23402860.6377
##   1340 17777868613.5069             nan     0.0500 -8887821.2810
##   1360 17605381952.2171             nan     0.0500 -25309799.4070
##   1380 17482565247.9715             nan     0.0500 -33544871.0174
##   1400 17346588725.0075             nan     0.0500 617610.3804
##   1420 17204761265.5905             nan     0.0500 -17558271.4686
##   1440 17076539371.8267             nan     0.0500 -5226741.8800
##   1460 16960452586.4712             nan     0.0500 -29401364.9486
##   1480 16850015802.9115             nan     0.0500 -5811502.2094
##   1500 16726142747.4858             nan     0.0500 -6961640.5454
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 259888712138.1349             nan     0.0500 18061203588.5040
##      2 243949039471.8060             nan     0.0500 14746987119.6801
##      3 229960324063.7485             nan     0.0500 12691945985.2353
##      4 216897297077.4694             nan     0.0500 13328564406.8195
##      5 205685549915.8757             nan     0.0500 11546574088.6556
##      6 194259172435.5103             nan     0.0500 10792512868.0051
##      7 183771917124.3910             nan     0.0500 8742010368.5978
##      8 174323328443.7970             nan     0.0500 8962343039.2638
##      9 166216492406.0822             nan     0.0500 7728083892.6085
##     10 158593798462.1206             nan     0.0500 7526969997.5256
##     20 106577217775.2917             nan     0.0500 3733631790.1131
##     40 64251544745.1656             nan     0.0500 925069308.6770
##     60 49460283928.9698             nan     0.0500 120451147.8621
##     80 43515375142.0320             nan     0.0500 -50734349.2580
##    100 40298164308.1310             nan     0.0500 6336264.0393
##    120 38022119342.6284             nan     0.0500 -9775015.3066
##    140 36058367142.5707             nan     0.0500 -86528612.8704
##    160 34506749041.9020             nan     0.0500 -55400589.5221
##    180 33203813125.6866             nan     0.0500 -80595486.1022
##    200 32009649895.6157             nan     0.0500 -25930468.0938
##    220 30924038620.0692             nan     0.0500 -53879812.6297
##    240 29914380807.5875             nan     0.0500 30475246.9792
##    260 28947202909.0063             nan     0.0500 -47504787.4722
##    280 28098962670.6099             nan     0.0500 -29800974.0665
##    300 27334712539.1107             nan     0.0500 -33801387.3802
##    320 26695250202.9335             nan     0.0500 20526028.4970
##    340 26132989155.9222             nan     0.0500 -49412674.7051
##    360 25470197438.2140             nan     0.0500 -18977680.3809
##    380 24877820480.4496             nan     0.0500 -31057039.4437
##    400 24252123599.8474             nan     0.0500 -6401347.3573
##    420 23734413530.4269             nan     0.0500 -19883638.9492
##    440 23308482797.5618             nan     0.0500 -51550137.1004
##    460 22908308914.8630             nan     0.0500 -15391213.1937
##    480 22464503993.3732             nan     0.0500 -43634990.6417
##    500 21971524323.2150             nan     0.0500 3043816.7881
##    520 21583620660.6905             nan     0.0500 -41147398.0460
##    540 21208228688.7073             nan     0.0500 -27042402.7882
##    560 20880618244.0186             nan     0.0500 -21445636.6691
##    580 20490520650.0394             nan     0.0500 -17697956.5211
##    600 20142074120.1571             nan     0.0500 -14817260.1560
##    620 19820640365.0514             nan     0.0500 -25206007.3681
##    640 19507483468.7465             nan     0.0500 -55318070.3550
##    660 19224429230.4224             nan     0.0500 -8704683.0477
##    680 18962301600.4706             nan     0.0500 1915703.4585
##    700 18645460283.9559             nan     0.0500 -17089718.5580
##    720 18369501037.4720             nan     0.0500 3911025.5177
##    740 18069601359.1745             nan     0.0500 -1453962.2537
##    760 17838399087.0577             nan     0.0500 -20948572.7359
##    780 17612883219.2544             nan     0.0500 -27539472.1754
##    800 17324475016.4054             nan     0.0500 -25295801.8978
##    820 17105837576.0204             nan     0.0500 -13416729.3089
##    840 16895935931.6940             nan     0.0500 -12601114.8994
##    860 16663876202.4737             nan     0.0500 -3750824.2238
##    880 16445396419.5420             nan     0.0500 -16108752.2096
##    900 16217846743.6670             nan     0.0500 -6166349.7007
##    920 15978516970.7640             nan     0.0500 -9112156.9839
##    940 15745153856.3239             nan     0.0500 -8326345.0981
##    960 15574781149.1062             nan     0.0500 -19657149.0868
##    980 15386930074.4011             nan     0.0500 -19960325.6895
##   1000 15207182393.7521             nan     0.0500 -34770991.8837
##   1020 15057442238.8553             nan     0.0500 -13871764.1768
##   1040 14877753225.8046             nan     0.0500 2092028.5858
##   1060 14692622026.3742             nan     0.0500 -17144657.3856
##   1080 14544389243.4914             nan     0.0500 -15029223.7848
##   1100 14405299885.6133             nan     0.0500 -18104920.6477
##   1120 14249580975.3857             nan     0.0500 -4982994.1717
##   1140 14129703811.8215             nan     0.0500 -16802860.2703
##   1160 13975476919.2314             nan     0.0500 -18787648.6960
##   1180 13837102217.8233             nan     0.0500 -11691943.2998
##   1200 13688799935.0371             nan     0.0500 2042160.6275
##   1220 13569908504.6568             nan     0.0500 -10242859.7015
##   1240 13417980828.3309             nan     0.0500 -2799409.0176
##   1260 13293624806.9875             nan     0.0500 -11812669.0219
##   1280 13169434833.5988             nan     0.0500 -11393652.8793
##   1300 13043424233.4569             nan     0.0500 -533329.7602
##   1320 12880974580.7769             nan     0.0500 1793173.1139
##   1340 12758683710.5165             nan     0.0500 -2172275.0075
##   1360 12654834676.7837             nan     0.0500 -6739625.6418
##   1380 12546911822.3266             nan     0.0500 -10985246.2498
##   1400 12418179035.1224             nan     0.0500 -9221097.0448
##   1420 12316331246.9506             nan     0.0500 -18437589.5632
##   1440 12204280820.4075             nan     0.0500 -7327425.5690
##   1460 12100425828.1681             nan     0.0500 -7590113.1939
##   1480 11982075414.5390             nan     0.0500 -9719866.7184
##   1500 11864048480.3012             nan     0.0500 -2506651.3448
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258361410224.8152             nan     0.0500 18178853643.0658
##      2 242444484807.3392             nan     0.0500 18479610352.1579
##      3 227637981830.5281             nan     0.0500 14042373686.9924
##      4 214390876535.0289             nan     0.0500 12139359481.0446
##      5 201902901028.0454             nan     0.0500 11074552097.8495
##      6 190643293670.8179             nan     0.0500 10310307184.3658
##      7 180727421341.1720             nan     0.0500 10375750459.7508
##      8 171166042139.3281             nan     0.0500 8794391829.2589
##      9 162744850039.4083             nan     0.0500 7952180284.4859
##     10 154300432191.1297             nan     0.0500 7549643552.8777
##     20 100497269860.0869             nan     0.0500 2829393450.7514
##     40 60257795754.3034             nan     0.0500 925640705.2894
##     60 46630726781.7455             nan     0.0500 61293039.0351
##     80 41070298340.2817             nan     0.0500 189752682.7359
##    100 37990251475.5144             nan     0.0500 -194598217.0805
##    120 35707860735.9793             nan     0.0500 -57829215.0374
##    140 33763661165.0804             nan     0.0500 -84433427.0587
##    160 32177270758.2100             nan     0.0500 -142753690.3744
##    180 30707852264.6717             nan     0.0500 -71384570.6479
##    200 29607240817.6824             nan     0.0500 -5786198.1071
##    220 28579830781.5750             nan     0.0500 -71316886.4540
##    240 27632354304.8419             nan     0.0500 -344690.5566
##    260 26818537753.6939             nan     0.0500 -26164549.5734
##    280 25917216219.9439             nan     0.0500 -66203590.2108
##    300 25077013592.4376             nan     0.0500 -3227991.1397
##    320 24349578175.3156             nan     0.0500 -4309111.9238
##    340 23553393888.2606             nan     0.0500 -47470947.1349
##    360 22845163132.8978             nan     0.0500 -42595584.3394
##    380 22175452865.4585             nan     0.0500 -9053419.3192
##    400 21639244384.1957             nan     0.0500 -3546231.7158
##    420 21117613135.0393             nan     0.0500 -42441079.4095
##    440 20656644195.9420             nan     0.0500 -6870379.5432
##    460 20082525878.4791             nan     0.0500 -28854873.9569
##    480 19622287801.8526             nan     0.0500 -19560154.5354
##    500 19239505097.2241             nan     0.0500 -16442228.7231
##    520 18883469306.2482             nan     0.0500 -15154860.4804
##    540 18474120096.7575             nan     0.0500 -49018970.7457
##    560 18155287137.9496             nan     0.0500 -3937288.5002
##    580 17790284909.3737             nan     0.0500 -25146656.7630
##    600 17476798873.0260             nan     0.0500 -34049215.2338
##    620 17105821231.0708             nan     0.0500 -18872342.7622
##    640 16739483632.9901             nan     0.0500 7194199.8991
##    660 16443530231.3920             nan     0.0500 3904479.9173
##    680 16151837348.8033             nan     0.0500 -22255330.1200
##    700 15828294968.2917             nan     0.0500 -10648319.0333
##    720 15579590274.7588             nan     0.0500 -21696578.4840
##    740 15333950706.0637             nan     0.0500 -20127996.5964
##    760 15117803701.9290             nan     0.0500 -12868777.4541
##    780 14906474060.1148             nan     0.0500 -16674843.2261
##    800 14640594215.3609             nan     0.0500 -5645953.7755
##    820 14391830897.6574             nan     0.0500 -5522103.9105
##    840 14181282276.3874             nan     0.0500 -5571979.1110
##    860 13974629397.8976             nan     0.0500 -18032992.7466
##    880 13756546992.0093             nan     0.0500 5952515.7160
##    900 13531679528.3982             nan     0.0500 -12315827.3369
##    920 13373162643.4791             nan     0.0500 -21833635.1590
##    940 13151370729.7738             nan     0.0500 -11735958.1940
##    960 12956944322.8162             nan     0.0500 1940251.0868
##    980 12781027722.7589             nan     0.0500 -12355277.4852
##   1000 12610975226.7538             nan     0.0500 -607521.4916
##   1020 12441958655.5589             nan     0.0500 -5340500.9798
##   1040 12263660899.6191             nan     0.0500 -3645703.2787
##   1060 12097364218.4030             nan     0.0500 -6017502.8471
##   1080 11946911996.2055             nan     0.0500 -8773797.5867
##   1100 11785246473.1082             nan     0.0500 -7705435.3506
##   1120 11639893695.4735             nan     0.0500 -7208407.4447
##   1140 11484370089.8341             nan     0.0500 -2637677.7143
##   1160 11330757451.7645             nan     0.0500 -10086260.9281
##   1180 11188555335.7784             nan     0.0500 -7180998.3426
##   1200 11047352449.4902             nan     0.0500 -2863598.8823
##   1220 10911150698.1674             nan     0.0500 -14314158.0936
##   1240 10779051623.4262             nan     0.0500 -7774850.8614
##   1260 10633998356.9366             nan     0.0500 -10002345.6657
##   1280 10512014940.3140             nan     0.0500 -5325348.7661
##   1300 10404386784.0947             nan     0.0500 -8505404.7541
##   1320 10288349259.3498             nan     0.0500 -1573857.4386
##   1340 10182545409.1943             nan     0.0500 -13594667.8191
##   1360 10085931379.6942             nan     0.0500 -9316780.1767
##   1380 9972191090.6034             nan     0.0500 1267662.9887
##   1400 9843255754.6548             nan     0.0500 -6489540.0103
##   1420 9743033305.8825             nan     0.0500 -2529447.1489
##   1440 9626532034.9821             nan     0.0500 -1617962.6253
##   1460 9515724800.6629             nan     0.0500 -9716431.0543
##   1480 9424900231.9607             nan     0.0500 -11609031.1627
##   1500 9344154367.3356             nan     0.0500 -6380682.4252
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 242266619909.2628             nan     0.0500 14468261569.6359
##      2 229804300394.0679             nan     0.0500 13201490212.2416
##      3 216713700294.2440             nan     0.0500 14141057392.8398
##      4 205201775163.5795             nan     0.0500 8306599018.4722
##      5 195465510968.2423             nan     0.0500 9896832443.7902
##      6 185667175897.0831             nan     0.0500 9009368876.7822
##      7 177403159398.9228             nan     0.0500 8853119923.9443
##      8 169628246981.6236             nan     0.0500 7268481451.3860
##      9 161795738847.4409             nan     0.0500 7172988304.3926
##     10 154705551527.4162             nan     0.0500 6484807402.9068
##     20 107216978616.8888             nan     0.0500 3227084661.7205
##     40 66530343659.1767             nan     0.0500 485244841.5220
##     60 50334790383.0514             nan     0.0500 326002238.8243
##     80 43556784799.8194             nan     0.0500 198843081.4727
##    100 40096276918.9796             nan     0.0500 62995949.3973
##    120 38041769811.9424             nan     0.0500 24307578.2438
##    140 36567442663.4962             nan     0.0500 50766143.1826
##    160 35223562277.7293             nan     0.0500 6604442.4281
##    180 34088899094.8459             nan     0.0500 5163859.9335
##    200 33154273286.1641             nan     0.0500 -34490384.0452
##    220 32267596985.9767             nan     0.0500 -26083267.6538
##    240 31597097678.0984             nan     0.0500 -12990792.4165
##    260 30964258703.0184             nan     0.0500 -51184841.5753
##    280 30259303945.5429             nan     0.0500 -35319223.3147
##    300 29724539641.1435             nan     0.0500 -25281461.3212
##    320 29011439620.1284             nan     0.0500 -3829605.5811
##    340 28515052139.3725             nan     0.0500 -50509594.9573
##    360 28064500475.6753             nan     0.0500 -11055843.0238
##    380 27388467779.7276             nan     0.0500 -13501537.9201
##    400 26913792339.5116             nan     0.0500 -19282224.3889
##    420 26465301021.1651             nan     0.0500 -11125600.0909
##    440 26028100611.7048             nan     0.0500 -23967200.8072
##    460 25619043486.2929             nan     0.0500 -18329537.7840
##    480 25327839929.6037             nan     0.0500 -31924392.0910
##    500 25040514862.8525             nan     0.0500 -23178599.2098
##    520 24705346909.7553             nan     0.0500 -4290563.0144
##    540 24376570893.8396             nan     0.0500 -131821.2291
##    560 24059371544.6201             nan     0.0500 10189456.9784
##    580 23760178797.5545             nan     0.0500 -49164657.5889
##    600 23470065550.0064             nan     0.0500 -12859773.6413
##    620 23228553142.6115             nan     0.0500 -29030511.9715
##    640 22931789164.0916             nan     0.0500 -37777389.8776
##    660 22700179308.8206             nan     0.0500 -39913909.2509
##    680 22452406384.4124             nan     0.0500 -21592647.8440
##    700 22185909382.0977             nan     0.0500 -20905920.2096
##    720 21917668672.2517             nan     0.0500 -22359952.0469
##    740 21680988352.2315             nan     0.0500 -20405125.2144
##    760 21438445144.9915             nan     0.0500 -22048633.4218
##    780 21204958085.7255             nan     0.0500 -18357777.2515
##    800 21001885763.2368             nan     0.0500 -15263519.4764
##    820 20804474229.1105             nan     0.0500 -30594884.5872
##    840 20601339315.6529             nan     0.0500 -39693075.0278
##    860 20408137988.5652             nan     0.0500 334897.8203
##    880 20244006418.7592             nan     0.0500 -18090826.4697
##    900 19995817934.8656             nan     0.0500 -9735300.3035
##    920 19818756269.9682             nan     0.0500 -37252279.7214
##    940 19610633483.1679             nan     0.0500 -12721001.1012
##    960 19435821193.8761             nan     0.0500 -18843168.1562
##    980 19261726029.2350             nan     0.0500 -19007193.2440
##   1000 19066138039.5762             nan     0.0500 -4107172.8378
##   1020 18848021645.2560             nan     0.0500 -31059900.8483
##   1040 18654409300.0155             nan     0.0500 -16394964.3547
##   1060 18475318127.5686             nan     0.0500 -18626829.4686
##   1080 18290022815.9462             nan     0.0500 -10077280.1611
##   1100 18145886376.5108             nan     0.0500 -11802046.1044
##   1120 17949866389.7660             nan     0.0500 -30438147.1654
##   1140 17814162697.5242             nan     0.0500 -3356406.6890
##   1160 17658018981.1155             nan     0.0500 -11117707.5326
##   1180 17518818909.8877             nan     0.0500 -20526341.8579
##   1200 17380743034.9966             nan     0.0500 -17584697.7509
##   1220 17204035427.6223             nan     0.0500 -8312095.0608
##   1240 17094899095.6081             nan     0.0500 -14096563.7790
##   1260 16971307895.8148             nan     0.0500 -13725186.9411
##   1280 16818385338.2463             nan     0.0500 -12140378.3602
##   1300 16705772541.2837             nan     0.0500 -14311522.9298
##   1320 16521422726.9133             nan     0.0500 -15761108.3247
##   1340 16385097725.5680             nan     0.0500 -11190105.4434
##   1360 16262808385.9259             nan     0.0500 -6300298.6129
##   1380 16121428359.4465             nan     0.0500 -12500915.9103
##   1400 15967054315.1435             nan     0.0500 -11689886.2544
##   1420 15819316132.9929             nan     0.0500 657018.2458
##   1440 15683795109.8087             nan     0.0500 -11819306.1851
##   1460 15598815036.8624             nan     0.0500 -8464223.8925
##   1480 15456006961.7318             nan     0.0500 -17336335.3100
##   1500 15334589854.9489             nan     0.0500 -18679061.2128
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 242523226919.1456             nan     0.0500 16224683617.1035
##      2 228151994683.4593             nan     0.0500 14819781974.2204
##      3 215108978102.8671             nan     0.0500 12578731381.2232
##      4 203227235013.4019             nan     0.0500 11718542608.2764
##      5 192206059001.7238             nan     0.0500 11243777410.8697
##      6 181676947072.2724             nan     0.0500 10687492921.4917
##      7 172436299312.2039             nan     0.0500 8793503148.4203
##      8 163468454295.8911             nan     0.0500 8741201466.5659
##      9 155284623586.3470             nan     0.0500 7557419013.7142
##     10 147979077821.3530             nan     0.0500 7592258882.5319
##     20 98785654107.4063             nan     0.0500 3312659276.3982
##     40 58252444307.6733             nan     0.0500 837602844.3239
##     60 44757327745.9599             nan     0.0500 316217713.0971
##     80 39690547603.4818             nan     0.0500 85230383.0154
##    100 36492869546.1056             nan     0.0500 58524753.8880
##    120 34618827035.1529             nan     0.0500 75692402.9533
##    140 32992204449.2901             nan     0.0500 -8842380.8296
##    160 31652299583.4911             nan     0.0500 -35319388.9490
##    180 30317645969.2731             nan     0.0500 -69794615.2916
##    200 29292962472.0548             nan     0.0500 -33053255.2687
##    220 28213107129.1336             nan     0.0500 -21981628.6259
##    240 27546768172.4745             nan     0.0500 -34281254.7499
##    260 26704105784.9310             nan     0.0500 7386803.2267
##    280 26002014589.6820             nan     0.0500 -6742702.6631
##    300 25220684215.2926             nan     0.0500 -35355088.4297
##    320 24621256096.4864             nan     0.0500 -33795941.0427
##    340 24070502983.4964             nan     0.0500 -4993166.7912
##    360 23630947145.4641             nan     0.0500 -39777205.7154
##    380 23061525103.5552             nan     0.0500 10193509.6970
##    400 22615454390.7834             nan     0.0500 -45885962.5723
##    420 22207897545.5497             nan     0.0500 -21013359.9413
##    440 21821484403.0674             nan     0.0500 -55232161.0191
##    460 21407777237.8546             nan     0.0500 -42386358.0414
##    480 21018452410.0086             nan     0.0500 -12827704.9945
##    500 20676771900.1516             nan     0.0500 -11109449.7986
##    520 20320942816.9243             nan     0.0500 -19570044.0171
##    540 19993997822.9313             nan     0.0500 -19503774.6318
##    560 19683719483.8044             nan     0.0500 -26927483.5121
##    580 19395274107.5849             nan     0.0500 -19254134.3597
##    600 19078535737.2601             nan     0.0500 517386.6293
##    620 18821113004.7417             nan     0.0500 -28053363.6901
##    640 18559612282.0027             nan     0.0500 -3663100.7669
##    660 18310949348.0168             nan     0.0500 -7564434.6224
##    680 18052451996.9101             nan     0.0500 -29694521.1879
##    700 17769421131.0592             nan     0.0500 -622678.1547
##    720 17567463316.5418             nan     0.0500 -37834804.0498
##    740 17359205011.4128             nan     0.0500 -999217.4990
##    760 17059690162.3926             nan     0.0500 -11240922.0420
##    780 16789568669.5634             nan     0.0500 -20217338.5576
##    800 16551396951.4542             nan     0.0500 14040171.2123
##    820 16334186616.7909             nan     0.0500 -7288082.6926
##    840 16094472058.3154             nan     0.0500 -8349386.8560
##    860 15899148004.2529             nan     0.0500 -15424770.1306
##    880 15701027926.6383             nan     0.0500 -3942915.8757
##    900 15505072855.2469             nan     0.0500 -13824176.8403
##    920 15315170454.6520             nan     0.0500 -21950958.5817
##    940 15122578701.3073             nan     0.0500 -3345299.2899
##    960 14922218173.9855             nan     0.0500 -15509404.9311
##    980 14740199997.0219             nan     0.0500 -19610207.6073
##   1000 14559391337.7354             nan     0.0500 -8447618.2622
##   1020 14400295975.4283             nan     0.0500 -20395536.8152
##   1040 14227259128.5434             nan     0.0500 -12244646.7159
##   1060 14072195894.4563             nan     0.0500 -7078519.5785
##   1080 13906776479.8270             nan     0.0500 -3246084.4812
##   1100 13770623203.0345             nan     0.0500 -23144558.1585
##   1120 13614573885.1216             nan     0.0500 -13833296.9930
##   1140 13474334597.1149             nan     0.0500 -8136915.5663
##   1160 13326316066.4062             nan     0.0500 -15668969.1007
##   1180 13185335269.1618             nan     0.0500 -11441723.2482
##   1200 13059505501.6839             nan     0.0500 -8041748.7222
##   1220 12915589894.0040             nan     0.0500 -4907300.9743
##   1240 12788967148.9352             nan     0.0500 -2348824.5200
##   1260 12661590739.6259             nan     0.0500 -7134107.0279
##   1280 12533040204.0739             nan     0.0500 -8986891.2682
##   1300 12398830400.9034             nan     0.0500 4896370.4358
##   1320 12261104432.7494             nan     0.0500 -4798329.3067
##   1340 12158457712.6342             nan     0.0500 -9839400.6674
##   1360 12033787368.0130             nan     0.0500 -7501311.4489
##   1380 11924648084.2673             nan     0.0500 -18681363.0109
##   1400 11790744191.8327             nan     0.0500 -13627690.2476
##   1420 11697561955.3295             nan     0.0500 -2859450.3314
##   1440 11587776499.7195             nan     0.0500 -6956593.6881
##   1460 11487249675.6899             nan     0.0500 -9814476.9427
##   1480 11390173111.8256             nan     0.0500 -3821936.1381
##   1500 11281564673.3356             nan     0.0500 -5601926.5302
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 241915152856.2670             nan     0.0500 17327595003.6943
##      2 226887634737.9724             nan     0.0500 15033446057.7094
##      3 212301225485.8920             nan     0.0500 13990289320.0200
##      4 199501470905.8185             nan     0.0500 12239549145.6720
##      5 187770092113.7915             nan     0.0500 10683124573.4386
##      6 177321539769.6724             nan     0.0500 10609954961.5767
##      7 166999272059.3432             nan     0.0500 9597820606.3417
##      8 158497011519.7775             nan     0.0500 8613629618.9820
##      9 149539993075.5577             nan     0.0500 7797825027.1687
##     10 142468205093.3682             nan     0.0500 7010235313.9919
##     20 91033167108.3983             nan     0.0500 3572664764.7375
##     40 53281350142.2703             nan     0.0500 660842601.4468
##     60 40679965760.4984             nan     0.0500 125795199.0351
##     80 35883541480.9733             nan     0.0500 37718571.6033
##    100 33030547327.4349             nan     0.0500 -38054007.4954
##    120 31200534995.2372             nan     0.0500 -73772022.9932
##    140 29212485732.6882             nan     0.0500 325397.7338
##    160 27896184289.2516             nan     0.0500 -25300337.4586
##    180 26839833431.4285             nan     0.0500 -97763983.3859
##    200 25821224659.5726             nan     0.0500 3955824.0766
##    220 24817509566.4695             nan     0.0500 12880183.7650
##    240 24001772504.8865             nan     0.0500 7872963.9402
##    260 23163958344.7131             nan     0.0500 -12263973.9969
##    280 22361588476.5571             nan     0.0500 -32835590.4526
##    300 21735178389.5719             nan     0.0500 -34483916.6035
##    320 21139901076.6314             nan     0.0500 -45869388.8131
##    340 20594379425.8116             nan     0.0500 -6477918.4680
##    360 20091964776.1514             nan     0.0500 -17815005.9907
##    380 19653731572.8365             nan     0.0500 -5384738.5067
##    400 19276267399.0238             nan     0.0500 -34708343.9592
##    420 18829284191.2650             nan     0.0500 -11905047.5600
##    440 18358818292.7960             nan     0.0500 -34048842.4641
##    460 17968830742.9179             nan     0.0500 12211039.5493
##    480 17666551010.7164             nan     0.0500 -32683968.5994
##    500 17308953954.2219             nan     0.0500 -27363870.7909
##    520 16980694738.9949             nan     0.0500 -33210823.1146
##    540 16640835475.0915             nan     0.0500 -10685149.3341
##    560 16343874325.9257             nan     0.0500 -2244592.7941
##    580 16066109157.0198             nan     0.0500 -22799490.4752
##    600 15755530735.4913             nan     0.0500 -3456598.5631
##    620 15485889819.2808             nan     0.0500 -32349391.9256
##    640 15217897934.7518             nan     0.0500 -13607447.8228
##    660 14966768999.2671             nan     0.0500 -21771080.4708
##    680 14710819282.1884             nan     0.0500 -3164427.7460
##    700 14439880099.4270             nan     0.0500 3471097.0360
##    720 14202913264.1642             nan     0.0500 -20213045.1243
##    740 13983698791.2975             nan     0.0500 2937697.8370
##    760 13787878033.2285             nan     0.0500 -15971585.9241
##    780 13550158807.1863             nan     0.0500 1687766.5697
##    800 13353214156.6527             nan     0.0500 -28062891.9987
##    820 13162675971.9483             nan     0.0500 -9798658.0350
##    840 12969664366.6416             nan     0.0500 -17445488.0694
##    860 12811959224.8134             nan     0.0500 -19177950.7587
##    880 12616094050.8289             nan     0.0500 -12474022.2558
##    900 12424747560.2628             nan     0.0500 -15486069.8701
##    920 12257432671.0235             nan     0.0500 -6360127.1936
##    940 12109556009.4511             nan     0.0500 -11177812.2924
##    960 11937393594.3713             nan     0.0500 -10831428.3515
##    980 11753724460.5642             nan     0.0500 -12464553.2708
##   1000 11602600158.6213             nan     0.0500 -16531824.3428
##   1020 11438290207.9127             nan     0.0500 -15164293.0657
##   1040 11292267787.4223             nan     0.0500 -10687113.1327
##   1060 11165363673.6688             nan     0.0500 -5602818.8777
##   1080 11015878596.0041             nan     0.0500 -11129820.0653
##   1100 10874376486.2749             nan     0.0500 -12004926.6091
##   1120 10743920100.0640             nan     0.0500 -13209557.9764
##   1140 10636891278.2012             nan     0.0500 -5299640.3222
##   1160 10524085316.0928             nan     0.0500 -11171246.0571
##   1180 10405073201.7784             nan     0.0500 -10613356.2332
##   1200 10279812404.7298             nan     0.0500 -1777094.9957
##   1220 10173082907.1296             nan     0.0500 -1374480.3584
##   1240 10060689397.2170             nan     0.0500 -6303836.1063
##   1260 9947887822.0305             nan     0.0500 -4304935.8815
##   1280 9832623594.4342             nan     0.0500 -9552350.4619
##   1300 9714809976.1754             nan     0.0500 -10561750.8667
##   1320 9609749291.1648             nan     0.0500 -9962497.3793
##   1340 9503050895.6080             nan     0.0500 -12483550.4137
##   1360 9415336963.9954             nan     0.0500 -12774727.0986
##   1380 9306597746.6193             nan     0.0500 -2374956.1332
##   1400 9214967403.3444             nan     0.0500 -15846185.1358
##   1420 9124919292.0964             nan     0.0500 -207314.9669
##   1440 9029274284.0988             nan     0.0500 -6211046.1294
##   1460 8934277768.5967             nan     0.0500 270794.4365
##   1480 8860272582.0489             nan     0.0500 -11127640.6708
##   1500 8771871251.0830             nan     0.0500 -9080423.7050
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 251352400922.2961             nan     0.0500 12492145942.3937
##      2 238024712364.1944             nan     0.0500 13456959493.4706
##      3 225007111658.5169             nan     0.0500 10382163010.1149
##      4 213313361139.0788             nan     0.0500 11165268593.1067
##      5 202807541919.6204             nan     0.0500 9594503299.9946
##      6 194575508799.8741             nan     0.0500 8767941770.0300
##      7 185590654347.4076             nan     0.0500 8492192944.3621
##      8 176749823307.8112             nan     0.0500 7788059578.9209
##      9 169238198301.9807             nan     0.0500 8064893574.2257
##     10 162322077244.0692             nan     0.0500 6629214099.7297
##     20 116104640423.6161             nan     0.0500 3587837270.3286
##     40 73002825537.4684             nan     0.0500 1007739162.1448
##     60 56382730394.2275             nan     0.0500 352685770.3110
##     80 48922587449.5460             nan     0.0500 198924670.2989
##    100 44923268917.2252             nan     0.0500 -142950149.9193
##    120 42219435335.5433             nan     0.0500 28925803.4090
##    140 40603098662.3958             nan     0.0500 -8441037.9514
##    160 39413880481.0547             nan     0.0500 -21685973.1559
##    180 38381966463.8380             nan     0.0500 4244252.1054
##    200 37355495921.1533             nan     0.0500 -119253852.8735
##    220 36255877254.5314             nan     0.0500 -12847669.3428
##    240 35175053719.5103             nan     0.0500 -49434263.4743
##    260 34487831664.7968             nan     0.0500 -124849834.9819
##    280 33470081454.8579             nan     0.0500 8850042.5030
##    300 32719293725.6147             nan     0.0500 17375285.4370
##    320 32070521540.0814             nan     0.0500 -44570295.2029
##    340 31494952991.3502             nan     0.0500 -52426046.2820
##    360 30951292612.6355             nan     0.0500 -54313440.5045
##    380 30401564360.0819             nan     0.0500 -53693154.7305
##    400 29781454527.6244             nan     0.0500 -24391601.2537
##    420 29297689357.9621             nan     0.0500 -13911642.7550
##    440 28855508133.6240             nan     0.0500 -32425547.6659
##    460 28404705956.0432             nan     0.0500 -13228971.3466
##    480 27851770517.4314             nan     0.0500 -51945188.7017
##    500 27463214143.5630             nan     0.0500 -8871256.4628
##    520 27060374902.1100             nan     0.0500 9509157.7938
##    540 26636616813.0529             nan     0.0500 -57707.8729
##    560 26238727625.0719             nan     0.0500 3844447.3192
##    580 25900925609.5571             nan     0.0500 -92699031.6028
##    600 25510105676.4062             nan     0.0500 -1336454.5291
##    620 25226243110.4038             nan     0.0500 11033115.3344
##    640 24902731689.6613             nan     0.0500 -45111464.5499
##    660 24559434647.4011             nan     0.0500 -31285011.8898
##    680 24279210544.7048             nan     0.0500 -42443633.3922
##    700 24076222999.1706             nan     0.0500 -9559949.3566
##    720 23756775439.9382             nan     0.0500 8856494.5994
##    740 23456075967.6780             nan     0.0500 -5016596.0502
##    760 23200270403.4350             nan     0.0500 -12518489.0664
##    780 22985011111.9924             nan     0.0500 -14614856.7878
##    800 22766012700.3674             nan     0.0500 -16859489.0280
##    820 22546773828.5790             nan     0.0500 -13294939.0872
##    840 22305170412.8272             nan     0.0500 -13636232.6631
##    860 22068399075.5888             nan     0.0500 -12293514.3741
##    880 21828155227.4971             nan     0.0500 -8461054.2406
##    900 21635396510.4131             nan     0.0500 -27299286.6010
##    920 21405639573.5758             nan     0.0500 -24817658.5761
##    940 21191437363.6187             nan     0.0500 -16893825.6279
##    960 20961003143.2466             nan     0.0500 -17636304.6752
##    980 20742708275.7702             nan     0.0500 -26609671.1198
##   1000 20572241832.5167             nan     0.0500 -10847258.7210
##   1020 20377411833.2695             nan     0.0500 -2745801.7748
##   1040 20189263136.8175             nan     0.0500 -27965148.4736
##   1060 20006106873.2540             nan     0.0500 -13015771.8233
##   1080 19814961087.0030             nan     0.0500 -1993694.4059
##   1100 19606938602.5410             nan     0.0500 -19089790.4617
##   1120 19407418967.0871             nan     0.0500 -22973637.6676
##   1140 19250655840.5548             nan     0.0500 -2337297.1246
##   1160 19099423331.6056             nan     0.0500 -8541261.6919
##   1180 18940214345.7378             nan     0.0500 -11481135.7113
##   1200 18769671472.9281             nan     0.0500 -6729282.8455
##   1220 18632276466.5679             nan     0.0500 -17687792.5450
##   1240 18479189232.3901             nan     0.0500 -22561892.5491
##   1260 18362124262.7432             nan     0.0500 -26260057.4816
##   1280 18211898005.2017             nan     0.0500 -32551023.4094
##   1300 18078924169.3723             nan     0.0500 -12895291.0327
##   1320 17941781627.8476             nan     0.0500 7195695.5411
##   1340 17772249497.2203             nan     0.0500 17107539.6915
##   1360 17652729072.3841             nan     0.0500 -17341491.9577
##   1380 17525465880.9207             nan     0.0500 3159203.5041
##   1400 17381222942.0913             nan     0.0500 -41375190.3205
##   1420 17243663562.3611             nan     0.0500 -18253460.1068
##   1440 17106574801.7796             nan     0.0500 -11395673.9124
##   1460 16968717641.0584             nan     0.0500 -26233244.0487
##   1480 16836488739.0402             nan     0.0500 -4250117.9209
##   1500 16690599489.1185             nan     0.0500 2180512.6352
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 250849369577.3679             nan     0.0500 14751818100.7379
##      2 235196243078.9872             nan     0.0500 14341897989.3611
##      3 221640091866.6289             nan     0.0500 13074309843.2232
##      4 209503291796.2547             nan     0.0500 9730713053.8529
##      5 197975323556.5601             nan     0.0500 12486516123.5687
##      6 188039739308.9170             nan     0.0500 10583665593.1175
##      7 178259814919.7553             nan     0.0500 8777758560.7027
##      8 168905158285.5634             nan     0.0500 7297258291.3918
##      9 161181518101.5525             nan     0.0500 7745701233.0700
##     10 153823859463.5493             nan     0.0500 8220758499.1278
##     20 103844250924.8549             nan     0.0500 2824996433.8594
##     40 63443996788.7779             nan     0.0500 927114047.3334
##     60 49736858828.9573             nan     0.0500 335960680.1573
##     80 43473961666.8537             nan     0.0500 55691759.4285
##    100 39993446189.1108             nan     0.0500 22534849.3032
##    120 37916283934.1419             nan     0.0500 12244928.2694
##    140 35899154823.0733             nan     0.0500 -34624929.4669
##    160 34358084216.3493             nan     0.0500 -35260780.5587
##    180 32900636930.6913             nan     0.0500 -14366679.0743
##    200 31764920249.6800             nan     0.0500 -102409046.1833
##    220 30827801822.2695             nan     0.0500 -47563443.8775
##    240 29912189570.3865             nan     0.0500 -36770921.0588
##    260 29112437919.3812             nan     0.0500 -31966574.1736
##    280 28391091474.5657             nan     0.0500 -19160501.3892
##    300 27769761159.6932             nan     0.0500 -24178281.2824
##    320 27080630127.4525             nan     0.0500 -43788090.9088
##    340 26463499542.5946             nan     0.0500 -19165086.9447
##    360 25849948066.8355             nan     0.0500 -35957220.7135
##    380 25247208124.2761             nan     0.0500 -561897.4987
##    400 24793985003.4379             nan     0.0500 -11914561.5814
##    420 24195031848.7900             nan     0.0500 -24120379.3149
##    440 23718863893.7814             nan     0.0500 -29267120.2900
##    460 23228558282.5001             nan     0.0500 -56202211.9291
##    480 22796666764.7418             nan     0.0500 -50745131.1841
##    500 22291308028.2238             nan     0.0500 -40658278.7818
##    520 21899429216.8864             nan     0.0500 -12680105.5709
##    540 21510541079.9942             nan     0.0500 -22995726.3014
##    560 21117941536.9227             nan     0.0500 -24879449.2542
##    580 20863110379.6456             nan     0.0500 -6881698.6643
##    600 20463656231.9742             nan     0.0500 -25075025.0769
##    620 20170856254.1033             nan     0.0500 -25585244.6842
##    640 19856379612.8034             nan     0.0500 -24916696.6431
##    660 19600263876.9386             nan     0.0500 -20279482.5042
##    680 19293391467.6411             nan     0.0500 3989823.4826
##    700 18984733049.8309             nan     0.0500 -22264151.7885
##    720 18661276385.3532             nan     0.0500 -47934688.3703
##    740 18430161325.1715             nan     0.0500 -8814733.2469
##    760 18177370634.7771             nan     0.0500 -2520270.0169
##    780 17907083789.4401             nan     0.0500 -21549106.4057
##    800 17700806238.8123             nan     0.0500 -26765374.9819
##    820 17433883246.1228             nan     0.0500 -31726304.5212
##    840 17186277199.4070             nan     0.0500 -15589267.7921
##    860 16907319199.6079             nan     0.0500 -10985870.6454
##    880 16672332128.1670             nan     0.0500 -6505638.5355
##    900 16457656522.0702             nan     0.0500 -7356324.2275
##    920 16279225216.6632             nan     0.0500 -22368603.3656
##    940 16081571731.7350             nan     0.0500 -18816832.7860
##    960 15837186902.6464             nan     0.0500 -17036000.7453
##    980 15580102041.7729             nan     0.0500 -3688023.0922
##   1000 15401830628.1735             nan     0.0500 -11692262.9144
##   1020 15226157543.5538             nan     0.0500 -12113881.8976
##   1040 15035362099.2824             nan     0.0500 -15905399.0193
##   1060 14897895348.4325             nan     0.0500 -5597658.6255
##   1080 14747775439.0120             nan     0.0500 -7572100.9126
##   1100 14591734299.1685             nan     0.0500 -9507427.6942
##   1120 14436028273.8097             nan     0.0500 -15456193.6383
##   1140 14289926990.0855             nan     0.0500 -13712147.0794
##   1160 14120661166.5327             nan     0.0500 3149593.7085
##   1180 13966631888.4511             nan     0.0500 -15639754.6911
##   1200 13818633029.8330             nan     0.0500 -15946119.3487
##   1220 13643003716.4458             nan     0.0500 -14910448.1229
##   1240 13503070606.2707             nan     0.0500 -1853288.6071
##   1260 13346681570.6729             nan     0.0500 -8980569.9897
##   1280 13236064155.7072             nan     0.0500 388408.9755
##   1300 13131024585.7955             nan     0.0500 -14156118.7118
##   1320 13010967813.3191             nan     0.0500 -10625531.5399
##   1340 12886333719.7069             nan     0.0500 -3329714.5336
##   1360 12762702250.1396             nan     0.0500 -8490593.3635
##   1380 12647980227.0770             nan     0.0500 -2662356.5318
##   1400 12523280940.4704             nan     0.0500 -23162542.4041
##   1420 12404783029.2308             nan     0.0500 -6473484.6257
##   1440 12303620093.9423             nan     0.0500 831385.2599
##   1460 12188444310.3565             nan     0.0500 -6844546.6747
##   1480 12071849390.1473             nan     0.0500 -9264242.3993
##   1500 11947937783.6791             nan     0.0500 -3355670.1095
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 249359301363.9763             nan     0.0500 17933850108.8230
##      2 234630861034.4167             nan     0.0500 15575752624.0721
##      3 221576843550.0360             nan     0.0500 13170557168.9480
##      4 208726503626.5845             nan     0.0500 12569097960.7845
##      5 196638790493.5054             nan     0.0500 11306574933.3416
##      6 185429412552.1091             nan     0.0500 11598276294.4511
##      7 175528895245.4189             nan     0.0500 7447386283.7618
##      8 166392552196.6895             nan     0.0500 9423512310.2551
##      9 158131037221.6833             nan     0.0500 7901952652.2976
##     10 150430506329.7617             nan     0.0500 7426056144.7728
##     20 98206833699.8239             nan     0.0500 3734989424.6819
##     40 58876138267.9558             nan     0.0500 773103515.2885
##     60 45851732978.9954             nan     0.0500 247345953.6425
##     80 40403446959.1389             nan     0.0500 51007608.7418
##    100 37177002815.3049             nan     0.0500 32890866.4507
##    120 34752801369.4434             nan     0.0500 -64025385.2227
##    140 33052746380.2066             nan     0.0500 -46157064.6437
##    160 31429703916.4592             nan     0.0500 19892231.8005
##    180 30150617358.6633             nan     0.0500 -67591778.8474
##    200 29145061584.6060             nan     0.0500 -57290184.5187
##    220 28037968834.3167             nan     0.0500 32449326.0385
##    240 27060521532.7722             nan     0.0500 -21800576.4128
##    260 26137220779.0587             nan     0.0500 -6211552.9922
##    280 25330000474.9869             nan     0.0500 -51828527.4762
##    300 24603893585.4618             nan     0.0500 -57890534.7837
##    320 23945690348.0757             nan     0.0500 -60586743.7945
##    340 23275651395.0650             nan     0.0500 -63657267.5684
##    360 22622333636.5665             nan     0.0500 -40749521.7934
##    380 22061811096.5735             nan     0.0500 -105875333.9040
##    400 21539415926.4000             nan     0.0500 -76836927.1378
##    420 21081589468.1115             nan     0.0500 -29198170.0019
##    440 20547642090.7975             nan     0.0500 -26268061.8937
##    460 20032996006.6713             nan     0.0500 -32778499.9266
##    480 19573529777.2984             nan     0.0500 -12164103.8106
##    500 19108987368.2954             nan     0.0500 -26175817.4916
##    520 18700584358.4762             nan     0.0500 -16730311.6995
##    540 18355215506.5123             nan     0.0500 -27528116.4555
##    560 17980927682.9892             nan     0.0500 8241521.6692
##    580 17638252696.7367             nan     0.0500 -30081117.2499
##    600 17278774390.7510             nan     0.0500 -18140295.7764
##    620 16929061041.9035             nan     0.0500 -21696472.9517
##    640 16630288897.8685             nan     0.0500 569712.0178
##    660 16305996342.6502             nan     0.0500 -28950039.5009
##    680 16000984109.1567             nan     0.0500 8309518.3918
##    700 15702973139.7974             nan     0.0500 -2844452.4378
##    720 15406592299.7275             nan     0.0500 -20666192.3120
##    740 15157546473.8363             nan     0.0500 -4673965.1635
##    760 14874031992.7597             nan     0.0500 10887629.6987
##    780 14629335098.3802             nan     0.0500 -13215117.6240
##    800 14372025695.1945             nan     0.0500 -7921996.4386
##    820 14176876627.5085             nan     0.0500 -1354647.0440
##    840 13960117691.3998             nan     0.0500 -15619340.9118
##    860 13749913917.7828             nan     0.0500 -12420298.1207
##    880 13583250524.5820             nan     0.0500 -4240998.1222
##    900 13380699580.1217             nan     0.0500 -2854652.5032
##    920 13173039799.8608             nan     0.0500 -19546047.9382
##    940 13001719053.3977             nan     0.0500 -14033222.8052
##    960 12789948927.2717             nan     0.0500 -4442526.4522
##    980 12609820059.8030             nan     0.0500 -1797195.7078
##   1000 12400891064.9105             nan     0.0500 -11812114.1293
##   1020 12240375160.3488             nan     0.0500 -4751657.8719
##   1040 12109561473.5559             nan     0.0500 -14913710.8692
##   1060 11988559294.4753             nan     0.0500 1222029.6098
##   1080 11836089747.9703             nan     0.0500 -5014711.1776
##   1100 11695629916.2662             nan     0.0500 -14182281.4396
##   1120 11541445954.2142             nan     0.0500 -9165880.5025
##   1140 11421328640.0385             nan     0.0500 -13601664.3736
##   1160 11289288935.0156             nan     0.0500 -4768421.6149
##   1180 11153263338.2916             nan     0.0500 -2764106.9671
##   1200 10987664836.3615             nan     0.0500 396607.4554
##   1220 10861371071.5738             nan     0.0500 -7612139.8129
##   1240 10725036266.9664             nan     0.0500 619338.3260
##   1260 10576517105.0796             nan     0.0500 -5519412.8992
##   1280 10444771807.4353             nan     0.0500 -291105.1620
##   1300 10324332512.8487             nan     0.0500 -9954782.2395
##   1320 10189833529.7235             nan     0.0500 3716113.6706
##   1340 10067420955.8649             nan     0.0500 -4017258.6623
##   1360 9953816502.4985             nan     0.0500 -10069122.3749
##   1380 9844047248.9142             nan     0.0500 -7504654.1091
##   1400 9740573045.3642             nan     0.0500 -3934801.4417
##   1420 9621557380.5136             nan     0.0500 -1836344.5427
##   1440 9523641070.6231             nan     0.0500 -7463310.7965
##   1460 9418495533.4454             nan     0.0500 -12742517.5305
##   1480 9323468202.6496             nan     0.0500 -9643444.2866
##   1500 9231564470.6969             nan     0.0500 -1256873.2340
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 264512473084.1277             nan     0.0500 14376557497.2122
##      2 249302306981.8620             nan     0.0500 14461081666.7028
##      3 235549277149.8429             nan     0.0500 14909567013.4649
##      4 223816225782.4591             nan     0.0500 13172785999.3827
##      5 212669367500.6842             nan     0.0500 10382406397.8760
##      6 202490535550.7394             nan     0.0500 9299931565.0145
##      7 191883176145.3174             nan     0.0500 10369461528.0481
##      8 183404055770.4691             nan     0.0500 7913612265.3847
##      9 175496310794.0606             nan     0.0500 7957702969.7206
##     10 168079592906.2544             nan     0.0500 8199669970.8447
##     20 116538559892.6676             nan     0.0500 3659589851.1644
##     40 72794875539.6731             nan     0.0500 1188835530.7272
##     60 55625314488.9418             nan     0.0500 449600317.3161
##     80 48506020779.6335             nan     0.0500 54786904.6545
##    100 44611163214.5119             nan     0.0500 99774702.9154
##    120 42379229152.5798             nan     0.0500 -112692192.3076
##    140 40286558337.0507             nan     0.0500 -68149818.5588
##    160 38717339471.5219             nan     0.0500 -31263423.9497
##    180 37480781270.8069             nan     0.0500 -67533174.9724
##    200 36238238926.5004             nan     0.0500 -26920756.1922
##    220 35221037745.7974             nan     0.0500 43778808.8104
##    240 34433762135.2669             nan     0.0500 -14198376.0681
##    260 33472759882.9216             nan     0.0500 -12254184.1229
##    280 32586672184.7848             nan     0.0500 12779899.2193
##    300 31832427920.3031             nan     0.0500 -1430668.7888
##    320 31247181027.7705             nan     0.0500 -21888150.4465
##    340 30801264199.7037             nan     0.0500 -17834093.0938
##    360 30110732895.0471             nan     0.0500 5046849.2235
##    380 29443761635.3919             nan     0.0500 -71207936.1525
##    400 28908204403.7858             nan     0.0500 -57302119.9229
##    420 28489525158.7569             nan     0.0500 -58553518.2750
##    440 28109961572.9445             nan     0.0500 -32860400.3530
##    460 27734334284.2191             nan     0.0500 -50500131.1317
##    480 27338155383.5536             nan     0.0500 13236271.8832
##    500 27045883908.7043             nan     0.0500 -23771452.9982
##    520 26632208122.0824             nan     0.0500 -32592425.4342
##    540 26266361517.3463             nan     0.0500 -18339080.8323
##    560 25909346655.3993             nan     0.0500 9004428.6638
##    580 25616740352.4580             nan     0.0500 -33304050.8288
##    600 25157443008.2345             nan     0.0500 -52030596.1458
##    620 24785906645.5120             nan     0.0500 -13702689.2174
##    640 24435483135.7852             nan     0.0500 658364.9020
##    660 24176190095.6918             nan     0.0500 13022243.8888
##    680 23875659771.1829             nan     0.0500 3645433.0271
##    700 23646186775.8958             nan     0.0500 -9487861.2778
##    720 23394645118.5558             nan     0.0500 -31019873.0577
##    740 23188534171.2866             nan     0.0500 -52296633.1295
##    760 22921016290.3848             nan     0.0500 -27891914.1760
##    780 22699922836.5226             nan     0.0500 -24671097.8299
##    800 22426267864.2878             nan     0.0500 -8482534.9436
##    820 22186843366.1346             nan     0.0500 -18888418.3041
##    840 21881744229.0595             nan     0.0500 -2696873.4771
##    860 21658781428.5582             nan     0.0500 -37210964.8982
##    880 21405717256.6631             nan     0.0500 -30579935.2906
##    900 21181596098.6431             nan     0.0500 -21390767.7666
##    920 20953579105.7615             nan     0.0500 -27881668.8221
##    940 20719575895.1589             nan     0.0500 -21806639.5299
##    960 20533934763.8000             nan     0.0500 -26786897.2862
##    980 20401906296.7856             nan     0.0500 -15449319.1918
##   1000 20164551377.5891             nan     0.0500 4719485.9459
##   1020 19916486594.7859             nan     0.0500 -4222266.6194
##   1040 19712970823.3902             nan     0.0500 -18630846.5353
##   1060 19545833501.0389             nan     0.0500 -15358869.6818
##   1080 19350956789.6923             nan     0.0500 831092.5664
##   1100 19175767865.8896             nan     0.0500 -20781824.3767
##   1120 18982852890.3528             nan     0.0500 -33790490.0546
##   1140 18816675460.5743             nan     0.0500 -32668703.3388
##   1160 18647795203.0335             nan     0.0500 -1557270.7617
##   1180 18464362238.9880             nan     0.0500 -11105232.9838
##   1200 18302459166.7377             nan     0.0500 -11983557.9611
##   1220 18161081201.1180             nan     0.0500 1900467.5462
##   1240 17972347978.4658             nan     0.0500 -19593166.8899
##   1260 17852952349.4122             nan     0.0500 -32663161.5763
##   1280 17723256630.3632             nan     0.0500 -3402078.9342
##   1300 17567390461.9480             nan     0.0500 -1254713.0834
##   1320 17436461420.0734             nan     0.0500 -13223095.7428
##   1340 17266486606.9626             nan     0.0500 -7511817.7639
##   1360 17146480982.7488             nan     0.0500 -8597398.0645
##   1380 17001014008.9499             nan     0.0500 -5268055.8010
##   1400 16845377187.0853             nan     0.0500 -16552129.2746
##   1420 16713768082.7062             nan     0.0500 -22309070.0058
##   1440 16598016410.4828             nan     0.0500 -9344427.2879
##   1460 16498671629.9815             nan     0.0500 -14119564.7697
##   1480 16365582767.8505             nan     0.0500 -10470671.5768
##   1500 16255349353.4544             nan     0.0500 -4289840.7056
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 261462148656.1093             nan     0.0500 17613173853.2927
##      2 245129119474.6367             nan     0.0500 16804401731.7265
##      3 230201020218.1697             nan     0.0500 11853439930.9497
##      4 217419951005.1906             nan     0.0500 12591669157.7956
##      5 206084466043.2101             nan     0.0500 9331385655.5413
##      6 194092414477.5953             nan     0.0500 11366973865.0955
##      7 184692783175.6577             nan     0.0500 10428625668.6810
##      8 175268705297.7071             nan     0.0500 9027230216.3674
##      9 166209760180.7929             nan     0.0500 7656632069.1700
##     10 158236121349.8042             nan     0.0500 7740350977.0338
##     20 104582287507.7480             nan     0.0500 3612378726.3032
##     40 62940496140.3384             nan     0.0500 838943976.0412
##     60 49197457165.9126             nan     0.0500 556910682.6619
##     80 43503103462.7051             nan     0.0500 -113680666.5931
##    100 39648226756.7766             nan     0.0500 -45020364.2367
##    120 37464617943.7279             nan     0.0500 -92293002.1755
##    140 35580136482.5594             nan     0.0500 -26165978.5357
##    160 34040137180.6127             nan     0.0500 -15533997.4497
##    180 32633782570.0554             nan     0.0500 -36603272.6670
##    200 31432972192.4152             nan     0.0500 -89218345.2989
##    220 30502822679.2292             nan     0.0500 -77271236.0230
##    240 29608521791.6851             nan     0.0500 -34170850.0883
##    260 28716367625.6979             nan     0.0500 -101529506.4166
##    280 27767242618.8925             nan     0.0500 -14340520.2373
##    300 26990784954.1946             nan     0.0500 -16603036.4268
##    320 26236324755.5429             nan     0.0500 -70267637.8269
##    340 25591901234.2244             nan     0.0500 -31048342.1211
##    360 25054623986.1954             nan     0.0500 4211062.7857
##    380 24436482820.8645             nan     0.0500 -44526448.0350
##    400 23879246976.6711             nan     0.0500 -33981290.2878
##    420 23395110822.3692             nan     0.0500 -3295937.4325
##    440 22942236005.9294             nan     0.0500 -44206306.1475
##    460 22451492075.3923             nan     0.0500 -41119822.3647
##    480 21962299512.8227             nan     0.0500 -27241101.0874
##    500 21565883252.0829             nan     0.0500 -64961952.2666
##    520 21244869290.9726             nan     0.0500 -10421597.1621
##    540 20899148930.8468             nan     0.0500 -16696686.7411
##    560 20539209137.0405             nan     0.0500 -33456024.2335
##    580 20158473221.1909             nan     0.0500 -24194644.3165
##    600 19851828270.8549             nan     0.0500 -24288802.7544
##    620 19537304254.6725             nan     0.0500 -23773022.2852
##    640 19220298449.7829             nan     0.0500 -38354241.1344
##    660 18964768411.4549             nan     0.0500 -25927078.4557
##    680 18684552654.9346             nan     0.0500 -8666757.9098
##    700 18378401023.6800             nan     0.0500 -41983881.0977
##    720 18086814669.7959             nan     0.0500 -20767649.2328
##    740 17817005423.9598             nan     0.0500 4287345.0059
##    760 17531400866.9018             nan     0.0500 -2496981.3415
##    780 17270873282.4199             nan     0.0500 -12096839.1453
##    800 17049746090.8402             nan     0.0500 6546717.9293
##    820 16845111885.6934             nan     0.0500 -24474856.9924
##    840 16632912429.6240             nan     0.0500 -24555493.0824
##    860 16380471859.2283             nan     0.0500 -17928906.7474
##    880 16137835381.1756             nan     0.0500 -11443833.0744
##    900 15911288760.0046             nan     0.0500 -19463440.7052
##    920 15720224163.0428             nan     0.0500 -12120936.6476
##    940 15511206460.7722             nan     0.0500 2475406.5896
##    960 15318190971.4078             nan     0.0500 -25579336.1824
##    980 15126808318.3920             nan     0.0500 -5902919.5968
##   1000 14937193552.7219             nan     0.0500 -11687231.3221
##   1020 14759819845.9328             nan     0.0500 -18550417.3817
##   1040 14551219520.3326             nan     0.0500 -11232426.1232
##   1060 14395857951.4783             nan     0.0500 -11840700.9659
##   1080 14253043742.9129             nan     0.0500 -15189949.6285
##   1100 14129030038.2467             nan     0.0500 -11481946.1147
##   1120 13956951563.2114             nan     0.0500 -9931444.0182
##   1140 13817217155.0395             nan     0.0500 -4602709.6727
##   1160 13692517780.0466             nan     0.0500 -4855110.3221
##   1180 13555852065.4119             nan     0.0500 -5165568.4793
##   1200 13410173622.6444             nan     0.0500 -13439864.1242
##   1220 13290215247.8536             nan     0.0500 -4620138.4117
##   1240 13174971421.7899             nan     0.0500 -2463474.4086
##   1260 13053701246.0401             nan     0.0500 -6064656.1411
##   1280 12959972241.8420             nan     0.0500 -1897961.0426
##   1300 12829939049.0286             nan     0.0500 -9245156.2247
##   1320 12688180624.8332             nan     0.0500 -11970911.6940
##   1340 12569153376.2808             nan     0.0500 -7880227.0156
##   1360 12438253967.1158             nan     0.0500 -7415452.2989
##   1380 12317508640.7278             nan     0.0500 -9453091.4594
##   1400 12209715565.4555             nan     0.0500 -9176252.5004
##   1420 12103316612.7784             nan     0.0500 -6161704.1554
##   1440 11995666377.9427             nan     0.0500 -16610753.3534
##   1460 11879273794.1000             nan     0.0500 -8866480.7716
##   1480 11762346820.6386             nan     0.0500 -13063357.5936
##   1500 11663482690.5633             nan     0.0500 2185449.3153
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 261062668669.2361             nan     0.0500 17563771404.8696
##      2 245044611701.5366             nan     0.0500 15110126672.9574
##      3 229342120432.0848             nan     0.0500 16970517399.5225
##      4 215766997975.2973             nan     0.0500 11993374657.6744
##      5 203356662694.6677             nan     0.0500 11776590911.8788
##      6 191420312000.5280             nan     0.0500 10949367992.7444
##      7 180649736194.6107             nan     0.0500 10274454315.6361
##      8 169754105208.8310             nan     0.0500 9380781199.1273
##      9 161029019807.8530             nan     0.0500 9609336424.4144
##     10 152184107319.2722             nan     0.0500 8500630628.0821
##     20 98650005566.1950             nan     0.0500 3500320216.2753
##     40 57885121416.7778             nan     0.0500 858123592.8670
##     60 44389859695.8734             nan     0.0500 104431792.9771
##     80 38988359806.9301             nan     0.0500 11295000.4536
##    100 36256276897.5352             nan     0.0500 -16362591.9311
##    120 34139280838.6534             nan     0.0500 -27929887.8615
##    140 32225089091.7198             nan     0.0500 16055754.8136
##    160 30691144194.2119             nan     0.0500 -13548270.7490
##    180 29230126522.0719             nan     0.0500 38635701.9337
##    200 27942095634.8542             nan     0.0500 -76943723.4862
##    220 27053047705.3692             nan     0.0500 -34778099.7134
##    240 26151247965.1747             nan     0.0500 -103725712.5589
##    260 25378674510.9355             nan     0.0500 -54757288.3060
##    280 24564281868.3360             nan     0.0500 -59083544.2599
##    300 23762409845.1733             nan     0.0500 -64683113.3510
##    320 23097980069.3540             nan     0.0500 -15506309.3979
##    340 22434607965.2737             nan     0.0500 -60495939.0753
##    360 21923173578.7725             nan     0.0500 -34628140.4542
##    380 21384659925.4534             nan     0.0500 -54474629.0775
##    400 20835518573.9232             nan     0.0500 -35290736.0275
##    420 20288479797.3632             nan     0.0500 -63380670.1245
##    440 19862629657.2366             nan     0.0500 -51492601.8230
##    460 19462545258.9549             nan     0.0500 -30503203.3391
##    480 19040323253.3206             nan     0.0500 -14203256.7873
##    500 18610361153.1150             nan     0.0500 -1354362.6974
##    520 18222969346.2931             nan     0.0500 4088189.9978
##    540 17800405398.7420             nan     0.0500 -512481.3236
##    560 17447060886.9690             nan     0.0500 -24789375.2553
##    580 17096253929.9477             nan     0.0500 -20028735.1579
##    600 16824152887.6562             nan     0.0500 -13456601.8492
##    620 16507722101.8801             nan     0.0500 -39348637.5715
##    640 16223835518.9384             nan     0.0500 -4103427.7362
##    660 15951653119.8951             nan     0.0500 -23336257.1200
##    680 15650222272.5386             nan     0.0500 -29815578.3975
##    700 15405658265.4432             nan     0.0500 -1095921.5926
##    720 15116498087.8661             nan     0.0500 -11394600.0172
##    740 14854288124.0346             nan     0.0500 -8269972.5432
##    760 14673821606.4809             nan     0.0500 -16847355.9037
##    780 14419504867.7075             nan     0.0500 1193677.2473
##    800 14195899172.2307             nan     0.0500 -19151419.5929
##    820 13975979228.8563             nan     0.0500 -14665151.3827
##    840 13760339909.0116             nan     0.0500 -24955472.3850
##    860 13530249994.7239             nan     0.0500 -11368635.7890
##    880 13357286715.0653             nan     0.0500 11179035.0570
##    900 13134343741.2385             nan     0.0500 -17327443.6517
##    920 12945586118.1338             nan     0.0500 1098223.6762
##    940 12795629895.9695             nan     0.0500 -16167303.0634
##    960 12614346962.6471             nan     0.0500 -6910974.6935
##    980 12432763170.3729             nan     0.0500 1141739.2498
##   1000 12260285438.6140             nan     0.0500 -5509964.0299
##   1020 12110853187.7381             nan     0.0500 -14590884.2926
##   1040 11946821208.6677             nan     0.0500 -8219193.2759
##   1060 11809232054.9526             nan     0.0500 988549.1805
##   1080 11649283786.0134             nan     0.0500 -8458267.3204
##   1100 11512250091.8247             nan     0.0500 -11701085.2591
##   1120 11359394423.4325             nan     0.0500 -18533229.0160
##   1140 11204855239.3545             nan     0.0500 -7418513.1566
##   1160 11052360933.5943             nan     0.0500 -9104702.1068
##   1180 10893894663.8694             nan     0.0500 -3786027.8450
##   1200 10761993780.8759             nan     0.0500 -3735712.5610
##   1220 10655092210.8256             nan     0.0500 -5984508.7080
##   1240 10523967095.8114             nan     0.0500 -1163328.6165
##   1260 10414099907.0978             nan     0.0500 7633333.7150
##   1280 10296819704.6065             nan     0.0500 393272.6562
##   1300 10153604532.0909             nan     0.0500 -5704553.8624
##   1320 10041007911.2550             nan     0.0500 -936069.9892
##   1340 9933824040.4547             nan     0.0500 -6559229.6511
##   1360 9808823539.5508             nan     0.0500 -528408.9337
##   1380 9719406500.1361             nan     0.0500 -6340354.1102
##   1400 9610941294.3004             nan     0.0500 -6580746.7111
##   1420 9501147795.1071             nan     0.0500 -12727025.3839
##   1440 9399355534.5504             nan     0.0500 293024.0381
##   1460 9293470629.7049             nan     0.0500 -3653397.3476
##   1480 9208230741.8508             nan     0.0500 -4979741.4813
##   1500 9111616722.8734             nan     0.0500 -4766954.9677
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258959030299.4024             nan     0.0500 15218487298.7310
##      2 244602040806.1117             nan     0.0500 14651706158.0669
##      3 232612539653.8523             nan     0.0500 13814769904.3845
##      4 220597947138.8278             nan     0.0500 11945223776.6280
##      5 209475219101.6890             nan     0.0500 10798771619.4467
##      6 199375101324.5631             nan     0.0500 9076166129.6755
##      7 190529842359.0493             nan     0.0500 8346211151.6340
##      8 182034112337.1488             nan     0.0500 8242783921.5524
##      9 174427540322.6750             nan     0.0500 7789611482.7115
##     10 167523374420.2875             nan     0.0500 6300584435.5846
##     20 117041576751.5518             nan     0.0500 3113768436.6556
##     40 73231991111.3422             nan     0.0500 1119103406.0826
##     60 55906646432.2241             nan     0.0500 364765666.4211
##     80 48877508900.1415             nan     0.0500 20030309.9015
##    100 45085466034.9586             nan     0.0500 74954030.4673
##    120 42920917355.0481             nan     0.0500 -35595038.0612
##    140 41005654716.1274             nan     0.0500 -101686258.5136
##    160 39567858949.9043             nan     0.0500 -81472870.9756
##    180 38068504626.8194             nan     0.0500 -5231124.6260
##    200 36984440056.4232             nan     0.0500 -86316110.4818
##    220 36003688473.2511             nan     0.0500 -80572466.0113
##    240 34893206607.8308             nan     0.0500 -21242106.6686
##    260 34086686739.9491             nan     0.0500 -63683056.5693
##    280 33387711842.0079             nan     0.0500 6800636.8087
##    300 32509637381.9342             nan     0.0500 -21814556.6438
##    320 31827715970.4701             nan     0.0500 -10650935.0318
##    340 31262033260.0685             nan     0.0500 -30066992.1681
##    360 30684995930.9023             nan     0.0500 6220208.5520
##    380 30132731631.6810             nan     0.0500 -51247483.9656
##    400 29709648540.6416             nan     0.0500 -96320339.5474
##    420 29196357128.0260             nan     0.0500 -66573418.3657
##    440 28737041878.5620             nan     0.0500 -52036317.7372
##    460 28203590014.4269             nan     0.0500 -27693530.3663
##    480 27726099794.9666             nan     0.0500 -118506704.1736
##    500 27359245640.5880             nan     0.0500 -16989995.0128
##    520 27006130609.6945             nan     0.0500 -13948244.1840
##    540 26608438702.3009             nan     0.0500 -53248480.0791
##    560 26268672016.1704             nan     0.0500 -2421904.9474
##    580 25904919552.8673             nan     0.0500 -46165891.2778
##    600 25565825766.0261             nan     0.0500 -7952942.2112
##    620 25251539012.1957             nan     0.0500 -14525216.4036
##    640 25036792470.3184             nan     0.0500 -22582004.7940
##    660 24717424326.5532             nan     0.0500 -25815118.5135
##    680 24474152371.1464             nan     0.0500 -30888994.1246
##    700 24217144636.0105             nan     0.0500 -23069031.5103
##    720 23942713713.2393             nan     0.0500 -5552147.8032
##    740 23617626377.4004             nan     0.0500 -62015536.5781
##    760 23275890377.8163             nan     0.0500 -36370565.1222
##    780 23012189843.9715             nan     0.0500 -41151155.4029
##    800 22739420898.3654             nan     0.0500 -29283755.6774
##    820 22521257636.6843             nan     0.0500 -4035526.4229
##    840 22317232339.5438             nan     0.0500 -43081441.0291
##    860 22095960827.5284             nan     0.0500 -6001275.2098
##    880 21869754094.8860             nan     0.0500 603606.6939
##    900 21640805195.6286             nan     0.0500 6481433.2659
##    920 21419490207.1092             nan     0.0500 -9147587.8171
##    940 21216587190.2046             nan     0.0500 -36968059.6724
##    960 21087372125.7669             nan     0.0500 -9423051.3940
##    980 20881829919.3550             nan     0.0500 -9896657.7529
##   1000 20652002907.4696             nan     0.0500 -21567180.6269
##   1020 20470775604.7255             nan     0.0500 -2822897.9918
##   1040 20222471652.1521             nan     0.0500 -35514923.0413
##   1060 20036340868.4686             nan     0.0500 -44760186.1531
##   1080 19873996940.1542             nan     0.0500 -13984931.9725
##   1100 19698888180.0595             nan     0.0500 -35852862.9427
##   1120 19533744927.6684             nan     0.0500 -24390520.5620
##   1140 19381328261.6948             nan     0.0500 -1170281.6146
##   1160 19216118043.9049             nan     0.0500 -7673044.9469
##   1180 19059766072.7972             nan     0.0500 -7269933.8317
##   1200 18868362373.6568             nan     0.0500 -10718115.9525
##   1220 18716543824.1759             nan     0.0500 -16768997.6918
##   1240 18534690944.0879             nan     0.0500 -30522853.9191
##   1260 18381612594.1600             nan     0.0500 -10246156.2563
##   1280 18210115086.4929             nan     0.0500 -12335671.5839
##   1300 18064148768.4710             nan     0.0500 -1159852.8983
##   1320 17902261153.9898             nan     0.0500 -16347065.5400
##   1340 17807829731.8919             nan     0.0500 -25259991.9395
##   1360 17653009761.9453             nan     0.0500 -35641545.2759
##   1380 17516445687.4710             nan     0.0500 -27223860.1930
##   1400 17397071505.4483             nan     0.0500 -14353664.5678
##   1420 17272115336.1787             nan     0.0500 -1331620.2918
##   1440 17124547729.5633             nan     0.0500 -37974973.8910
##   1460 17007279735.2132             nan     0.0500 -18529308.8889
##   1480 16847726428.2747             nan     0.0500 -19333056.3330
##   1500 16736005492.9132             nan     0.0500 -13151265.7970
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258553006622.6521             nan     0.0500 15707143875.1516
##      2 242510628738.6475             nan     0.0500 15843356647.8586
##      3 228090931420.9241             nan     0.0500 13554979324.9948
##      4 215596934248.5098             nan     0.0500 13124620930.1990
##      5 204283170373.5099             nan     0.0500 11083404231.4426
##      6 194150187736.4868             nan     0.0500 10513555266.9525
##      7 182573667515.4895             nan     0.0500 9894607717.8823
##      8 173520039455.5111             nan     0.0500 8991121454.9506
##      9 164032993223.1762             nan     0.0500 6758369436.9364
##     10 156060725936.2430             nan     0.0500 7504860430.6405
##     20 105098910095.0005             nan     0.0500 3029589801.8925
##     40 63367283430.9139             nan     0.0500 1069404185.2888
##     60 49380797499.0819             nan     0.0500 366342938.0233
##     80 44116499858.5955             nan     0.0500 224971327.2198
##    100 40903404737.9846             nan     0.0500 20897598.7393
##    120 38799487657.6197             nan     0.0500 -94247653.3717
##    140 36812537281.7791             nan     0.0500 -667195.3006
##    160 35502886171.1979             nan     0.0500 -65855347.3094
##    180 33856151490.0597             nan     0.0500 36444364.9832
##    200 32727332733.7232             nan     0.0500 -75253077.4017
##    220 31276623796.4554             nan     0.0500 -12901605.6281
##    240 30503872986.0411             nan     0.0500 -131879741.3620
##    260 29600381285.9745             nan     0.0500 -3403651.9432
##    280 28757275982.7648             nan     0.0500 -50112878.3064
##    300 28120731172.0057             nan     0.0500 -15230818.4993
##    320 27419028812.6379             nan     0.0500 -72547013.3127
##    340 26719682984.9872             nan     0.0500 -34681261.5555
##    360 26029368289.4613             nan     0.0500 -3487388.8252
##    380 25455380019.4633             nan     0.0500 -40828019.8540
##    400 24971510621.7055             nan     0.0500 -25526580.5694
##    420 24483748809.9024             nan     0.0500 -32768898.2942
##    440 24102845679.7270             nan     0.0500 -42403128.5193
##    460 23689043149.8850             nan     0.0500 -9690613.5351
##    480 23144276433.5403             nan     0.0500 -25875697.2051
##    500 22645216422.9001             nan     0.0500 -33133406.3250
##    520 22227200928.0743             nan     0.0500 3025696.8011
##    540 21872976551.1542             nan     0.0500 -15295964.3389
##    560 21494900977.9147             nan     0.0500 -22186907.3063
##    580 21103348637.5030             nan     0.0500 3425048.4035
##    600 20851214874.7841             nan     0.0500 -19821923.6796
##    620 20526977492.7981             nan     0.0500 -18197643.9950
##    640 20159855308.6429             nan     0.0500 -7122258.0439
##    660 19845109148.6275             nan     0.0500 -16189848.5007
##    680 19563839389.7400             nan     0.0500 -35888848.5949
##    700 19261938203.9729             nan     0.0500 -17808336.5959
##    720 18995224689.4159             nan     0.0500 2026672.5664
##    740 18755477305.1683             nan     0.0500 -8990674.6042
##    760 18505977886.5047             nan     0.0500 -5354328.2011
##    780 18235907718.6398             nan     0.0500 -23819045.2189
##    800 17975282850.7134             nan     0.0500 4736824.0896
##    820 17740449518.9791             nan     0.0500 -16826611.0482
##    840 17513792308.6276             nan     0.0500 -17780376.0759
##    860 17254034698.6067             nan     0.0500 -1993212.8512
##    880 17021786155.7158             nan     0.0500 -14564896.8878
##    900 16761741784.0875             nan     0.0500 -6044505.5941
##    920 16510412300.9746             nan     0.0500 1848043.9079
##    940 16277361854.5789             nan     0.0500 -20191962.6918
##    960 16079081894.8081             nan     0.0500 -37311884.8792
##    980 15832590451.1338             nan     0.0500 -37287455.2496
##   1000 15650577736.5678             nan     0.0500 -11686176.6307
##   1020 15464355974.2895             nan     0.0500 -11681019.9856
##   1040 15296707812.2934             nan     0.0500 -23229745.0655
##   1060 15120072058.7613             nan     0.0500 -19635864.9843
##   1080 14953466031.7064             nan     0.0500 -1324172.5237
##   1100 14779400341.7816             nan     0.0500 -12655663.5727
##   1120 14616007861.2921             nan     0.0500 -13970295.7864
##   1140 14464217754.7840             nan     0.0500 -8158507.0339
##   1160 14312661565.0097             nan     0.0500 -3070434.4573
##   1180 14151580219.1912             nan     0.0500 -11871581.6579
##   1200 13991831469.7477             nan     0.0500 9818357.2351
##   1220 13860816486.7954             nan     0.0500 -11300226.5565
##   1240 13706013295.4755             nan     0.0500 -9091915.9871
##   1260 13573751920.8989             nan     0.0500 -5055725.6124
##   1280 13449349237.7128             nan     0.0500 -11939082.6289
##   1300 13331942605.9093             nan     0.0500 -19975756.5683
##   1320 13201437017.9530             nan     0.0500 -12361825.7128
##   1340 13090253887.0916             nan     0.0500 -13212273.7015
##   1360 12965202985.3208             nan     0.0500 -16529212.5672
##   1380 12829526600.4060             nan     0.0500 -10320169.5148
##   1400 12709258086.3888             nan     0.0500 -2093493.6023
##   1420 12609610816.0579             nan     0.0500 -14219707.0444
##   1440 12504108459.1642             nan     0.0500 -10620489.9024
##   1460 12369769567.0444             nan     0.0500 -8513147.2818
##   1480 12268572998.7536             nan     0.0500 -8146798.3866
##   1500 12154922059.1280             nan     0.0500 -4047985.7845
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 257001398220.3783             nan     0.0500 16416575379.5965
##      2 240853958975.3254             nan     0.0500 18046235718.1197
##      3 224296475739.6973             nan     0.0500 14685999454.6638
##      4 210974705634.5624             nan     0.0500 11328152355.4949
##      5 199358986192.6138             nan     0.0500 10129731041.5656
##      6 188016332258.9004             nan     0.0500 8603951044.3000
##      7 176431246433.1991             nan     0.0500 10708323692.5692
##      8 166998764178.3418             nan     0.0500 9252763225.9532
##      9 157464522795.4120             nan     0.0500 7436938607.7865
##     10 148979208732.6694             nan     0.0500 7796616526.1675
##     20 96353847731.8199             nan     0.0500 3195838693.4693
##     40 58095894631.4568             nan     0.0500 792827766.9997
##     60 45318287820.3790             nan     0.0500 207436496.0402
##     80 39637572440.5029             nan     0.0500 -52595071.6186
##    100 36614478795.9195             nan     0.0500 -98347029.0887
##    120 34418747884.6848             nan     0.0500 -26408163.7162
##    140 32662297760.1974             nan     0.0500 -167459939.8252
##    160 31213803016.2717             nan     0.0500 -81020919.4963
##    180 29764896293.7112             nan     0.0500 -39941367.8720
##    200 28783801316.3819             nan     0.0500 -15579046.3860
##    220 27800225448.8747             nan     0.0500 -110248463.7940
##    240 26752756293.5386             nan     0.0500 14497827.9383
##    260 25943561210.0547             nan     0.0500 -109920143.9975
##    280 25087370432.9398             nan     0.0500 -87327236.4656
##    300 24317662287.7629             nan     0.0500 -3541080.7653
##    320 23598214702.9859             nan     0.0500 -2642070.4531
##    340 23080185045.3898             nan     0.0500 -44146612.9538
##    360 22420870601.1989             nan     0.0500 -43747211.1750
##    380 21919977969.6070             nan     0.0500 -46063192.0528
##    400 21423479242.5217             nan     0.0500 -13710162.2712
##    420 20949964740.3956             nan     0.0500 -6069112.2497
##    440 20444733488.3221             nan     0.0500 -26965828.4310
##    460 19932912578.4355             nan     0.0500 -38673131.7290
##    480 19509391191.0463             nan     0.0500 -9742812.7524
##    500 19113250727.8509             nan     0.0500 -23630451.4661
##    520 18703070335.2485             nan     0.0500 3810155.8689
##    540 18258717255.7210             nan     0.0500 13219857.7307
##    560 17918963760.0234             nan     0.0500 426007.2818
##    580 17519005454.7333             nan     0.0500 -5384402.8337
##    600 17156891861.1237             nan     0.0500 -26027721.8781
##    620 16811139725.5013             nan     0.0500 -33960934.8991
##    640 16499749305.7664             nan     0.0500 -14915577.4640
##    660 16225497535.7619             nan     0.0500 -995071.9015
##    680 15959561938.0099             nan     0.0500 -17900378.5521
##    700 15692166895.0843             nan     0.0500 -8146550.3578
##    720 15481797543.0592             nan     0.0500 -47134736.4762
##    740 15270007026.7653             nan     0.0500 -11716644.2625
##    760 15066833841.0831             nan     0.0500 -19961591.6361
##    780 14827156375.9048             nan     0.0500 -8148925.4082
##    800 14623759460.5515             nan     0.0500 -25201963.0965
##    820 14413033995.4044             nan     0.0500 -18698751.8005
##    840 14186028659.2987             nan     0.0500 -3858618.3675
##    860 13952686032.4822             nan     0.0500 -6866022.4262
##    880 13745070572.5241             nan     0.0500 -25731417.6551
##    900 13532148129.8655             nan     0.0500 -14200687.7746
##    920 13322469475.7557             nan     0.0500 -13447016.9273
##    940 13118495253.2393             nan     0.0500 -11475825.9108
##    960 12921486165.3991             nan     0.0500 -18845216.7964
##    980 12761859758.1887             nan     0.0500 -21111287.0491
##   1000 12590685582.8509             nan     0.0500 -22348347.1318
##   1020 12415227573.6006             nan     0.0500 -10669795.2834
##   1040 12251028918.4925             nan     0.0500 -12065119.4270
##   1060 12087806046.5390             nan     0.0500 -12314369.4845
##   1080 11909783357.7129             nan     0.0500 -6712636.5212
##   1100 11772063243.2542             nan     0.0500 -11742554.7000
##   1120 11646160390.8278             nan     0.0500 581260.3293
##   1140 11513651487.1787             nan     0.0500 -2092895.3275
##   1160 11381616317.5104             nan     0.0500 -5099559.2563
##   1180 11226409765.9567             nan     0.0500 -17050080.2098
##   1200 11073998446.2255             nan     0.0500 -5219132.9620
##   1220 10931693392.9646             nan     0.0500 -6245503.5084
##   1240 10807581654.9962             nan     0.0500 -10522936.3596
##   1260 10684026588.1497             nan     0.0500 -12272102.8043
##   1280 10537990310.3233             nan     0.0500 -13040137.3662
##   1300 10417674565.1459             nan     0.0500 -9042960.0912
##   1320 10295456181.7583             nan     0.0500 1422492.3454
##   1340 10170582304.8068             nan     0.0500 -5586294.8355
##   1360 10039000850.2601             nan     0.0500 -10386895.3894
##   1380 9931924270.7780             nan     0.0500 -8560975.4826
##   1400 9811542728.8459             nan     0.0500 -11933923.9079
##   1420 9699033272.8505             nan     0.0500 -4666212.6136
##   1440 9607166046.1428             nan     0.0500 -9838674.2576
##   1460 9511749524.6625             nan     0.0500 -8354635.3792
##   1480 9395149289.3328             nan     0.0500 -14578116.7091
##   1500 9304959708.6043             nan     0.0500 -3401044.7862
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 254734682898.2973             nan     0.0500 17737597654.4302
##      2 238329795709.5534             nan     0.0500 16882072915.4539
##      3 224123761365.5025             nan     0.0500 14073447199.4208
##      4 210633638897.9256             nan     0.0500 12337092634.8750
##      5 198107607618.3290             nan     0.0500 11843821922.9115
##      6 186693631633.1657             nan     0.0500 10957955327.8815
##      7 175638040428.3156             nan     0.0500 10336325514.0001
##      8 166122515684.0866             nan     0.0500 8151767232.6991
##      9 156619485511.3221             nan     0.0500 8740559091.8604
##     10 148442106840.6277             nan     0.0500 7739343335.6877
##     20 95978348604.5041             nan     0.0500 3549313661.3217
##     40 57577318375.7495             nan     0.0500 721220987.6553
##     60 44688325242.4187             nan     0.0500 171798616.0110
##     80 39019346975.9857             nan     0.0500 115024373.3430
##    100 36081991304.8476             nan     0.0500 -110582719.3001
##    120 33995582450.5782             nan     0.0500 -78159171.9604
##    140 32261161446.8100             nan     0.0500 -49360094.1383
##    160 30846592401.1779             nan     0.0500 17138885.0373
##    180 29629148460.2585             nan     0.0500 -16498434.8706
##    200 28426222728.9948             nan     0.0500 -2764629.3373
##    220 27407327189.0702             nan     0.0500 -44166368.7517
##    240 26478696458.5086             nan     0.0500 -69020578.8231
##    260 25645509988.6465             nan     0.0500 -27579712.9553
##    280 24849593011.0001             nan     0.0500 -31059090.2925
##    300 24191015829.2373             nan     0.0500 -26566439.1585
##    320 23606265764.4047             nan     0.0500 -65374638.3484
##    340 23018766008.4578             nan     0.0500 -7726360.7266
##    360 22479437944.4829             nan     0.0500 -35762729.8342
##    380 21922041839.2671             nan     0.0500 -23981031.7066
##    400 21374557216.2671             nan     0.0500 -4812363.7337
##    420 20901212322.0510             nan     0.0500 -4285790.2389
##    440 20429623028.2288             nan     0.0500 -15484966.3594
##    460 20017985933.0211             nan     0.0500 -8775065.7581
##    480 19604387478.5793             nan     0.0500 -37414909.6728
##    500 19210768718.1519             nan     0.0500 -20214033.7997
##    520 18810604747.5407             nan     0.0500 -17278887.5756
##    540 18445667612.0575             nan     0.0500 -52398081.0259
##    560 18060291862.6748             nan     0.0500 -17660016.1594
##    580 17696693768.1080             nan     0.0500 -16182801.1175
##    600 17393015393.0040             nan     0.0500 -28934038.1821
##    620 17129431194.5485             nan     0.0500 -37800594.9093
##    640 16822434429.0886             nan     0.0500 -7871129.1749
##    660 16522351114.3908             nan     0.0500 -26884881.9095
##    680 16185270422.8340             nan     0.0500 -14061125.2120
##    700 15961347961.1688             nan     0.0500 645078.9429
##    720 15697536502.3528             nan     0.0500 2985554.7364
##    740 15411895580.0741             nan     0.0500 -3183809.4310
##    760 15085228458.1822             nan     0.0500 2403158.1441
##    780 14821929247.5661             nan     0.0500 -27661766.7584
##    800 14637633652.4003             nan     0.0500 -17357970.1914
##    820 14398521124.8441             nan     0.0500 2513939.9060
##    840 14204750865.8329             nan     0.0500 -7758147.4102
##    860 14019658400.3864             nan     0.0500 -7091282.1967
##    880 13798356595.5461             nan     0.0500 -1283765.5585
##    900 13599518334.8556             nan     0.0500 -3816082.9367
##    920 13424064206.9258             nan     0.0500 -14911920.4035
##    940 13273522095.3167             nan     0.0500 -341981.6863
##    960 13111207564.5955             nan     0.0500 -12106304.8085
##    980 12928570487.3943             nan     0.0500 -3764280.6130
##   1000 12749090627.7185             nan     0.0500 -11666288.1590
##   1020 12614840809.7712             nan     0.0500 -14070673.9320
##   1040 12451538014.9309             nan     0.0500 -2869751.1267
##   1060 12282408417.5754             nan     0.0500 132363.4959
##   1080 12135232063.2459             nan     0.0500 -17030056.8137
##   1100 11955230932.1741             nan     0.0500 -21119544.8519
##   1120 11818139817.1547             nan     0.0500 -12806456.1129
##   1140 11685655660.5536             nan     0.0500 -1038339.8498
##   1160 11559107920.1815             nan     0.0500 -10323004.2021
##   1180 11437027348.3033             nan     0.0500 -7000140.7319
##   1200 11314626588.7407             nan     0.0500 -9394526.9823
##   1220 11187291866.3392             nan     0.0500 -12449117.3853
##   1240 11061354467.8955             nan     0.0500 -254499.7940
##   1260 10940218190.6113             nan     0.0500 -5592068.6184
##   1280 10811431707.1982             nan     0.0500 -587521.2996
##   1300 10694481506.3092             nan     0.0500 -13961301.5047
##   1320 10579872799.4367             nan     0.0500 -5247342.1419
##   1340 10471546741.7309             nan     0.0500 -10538964.6497
##   1360 10370284324.7331             nan     0.0500 -10984211.9334
##   1380 10270186080.4176             nan     0.0500 -9103335.9505
##   1400 10158714698.2444             nan     0.0500 -4201472.8616
##   1420 10046841164.1382             nan     0.0500 -8171387.3625
##   1440 9948007813.1247             nan     0.0500 -11210910.5230
##   1460 9839537938.3937             nan     0.0500 -3674455.1423
##   1480 9739244093.9968             nan     0.0500 -6806674.9405
##   1500 9640306275.5177             nan     0.0500 -8126444.5277</code></pre>
<pre class="r"><code>print(gbmFit1)</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 10499 samples
##    13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE    Rsquared  MAE   
##   4                   500     219585  0.825     109574
##   4                  1000     216953  0.830     106428
##   4                  1500     214924  0.833     104503
##   6                   500     218067  0.829     107330
##   6                  1000     214780  0.834     103418
##   6                  1500     213459  0.837     101585
##   8                   500     214467  0.834     105120
##   8                  1000     212246  0.838     101397
##   8                  1500     210764  0.840      99826
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.05
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 1500, interaction.depth =
##  8, shrinkage = 0.05 and n.minobsinnode = 10.</code></pre>
<pre class="r"><code>modelLookup(&quot;gbm&quot;)</code></pre>
<pre><code>##   model         parameter                   label forReg forClass probModel
## 1   gbm           n.trees   # Boosting Iterations   TRUE     TRUE      TRUE
## 2   gbm interaction.depth          Max Tree Depth   TRUE     TRUE      TRUE
## 3   gbm         shrinkage               Shrinkage   TRUE     TRUE      TRUE
## 4   gbm    n.minobsinnode Min. Terminal Node Size   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>#Usual trainControl - take the same

#Expand the search grid (see above for definitions)
grid&lt;-expand.grid(interaction.depth = 8,
                  n.trees = 1500,
                  shrinkage =0.05, 
                  n.minobsinnode = 10)#the minimum number of observations in trees&#39; terminal nodes. Set n.minobsinnode = 10. When working with small training samples it may be vital to lower this setting to five or even three.

set.seed(1)
#Train for gbm
gbmFit1 &lt;- train(price~
    
    distance_to_station 
    +latitude
    +longitude
    

    +freehold_or_leasehold
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company,
  
     train_data,
                 
                 method = &quot;gbm&quot;, 
                 trControl = control,#same as for lm
                 tuneGrid =grid,
                   metric = &quot;RMSE&quot;,
                 verbose = TRUE
                 )</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 262347596363.5839             nan     0.0500 14382245346.9363
##      2 246614721525.0241             nan     0.0500 15185861657.1504
##      3 231905423206.5676             nan     0.0500 14717161142.1852
##      4 217010662199.5157             nan     0.0500 12719143569.3750
##      5 203773144099.5748             nan     0.0500 14143456763.8079
##      6 192783315477.3744             nan     0.0500 10554473399.6575
##      7 181168038825.7074             nan     0.0500 9106442352.5266
##      8 171014607338.3752             nan     0.0500 8515128292.9318
##      9 161837726354.7243             nan     0.0500 8577450291.5377
##     10 154358116318.9413             nan     0.0500 7641761840.0972
##     20 100535182416.2249             nan     0.0500 3611215921.5039
##     40 59904700583.0140             nan     0.0500 802207134.6662
##     60 46321093673.1390             nan     0.0500 236807673.7554
##     80 40451938262.0492             nan     0.0500 123453884.4482
##    100 37247002762.7370             nan     0.0500 -72446542.0637
##    120 34872773800.1324             nan     0.0500 46227892.1206
##    140 33234602873.0408             nan     0.0500 -17808503.2228
##    160 31497260848.8718             nan     0.0500 -97194596.2215
##    180 30159100177.0270             nan     0.0500 -65342762.8384
##    200 28726576531.4834             nan     0.0500 -80254275.4988
##    220 27696132039.5231             nan     0.0500 -32725679.8405
##    240 26831531698.8766             nan     0.0500 -61963244.2203
##    260 25929461470.6465             nan     0.0500 -62171266.9503
##    280 25094417868.4568             nan     0.0500 -42234132.2722
##    300 24386502456.5707             nan     0.0500 -42964380.7879
##    320 23759174522.9171             nan     0.0500 -33521256.7866
##    340 23065207445.6233             nan     0.0500 -3010124.7462
##    360 22341549738.4777             nan     0.0500 35257612.2181
##    380 21662700528.1765             nan     0.0500 24594297.6845
##    400 21100257069.0354             nan     0.0500 25148442.2872
##    420 20583063757.4841             nan     0.0500 -38033003.6910
##    440 20124161650.4190             nan     0.0500 -10130312.8728
##    460 19708431318.5386             nan     0.0500 -17866257.7666
##    480 19221531137.6906             nan     0.0500 -55348318.7028
##    500 18729363886.2986             nan     0.0500 2828708.7548
##    520 18418972192.3429             nan     0.0500 -25146016.3957
##    540 18011656706.8510             nan     0.0500 -16314102.7513
##    560 17608027522.3131             nan     0.0500 -32073221.3519
##    580 17228801173.8338             nan     0.0500 -38926909.7771
##    600 16910682964.8364             nan     0.0500 -32935445.0651
##    620 16598366336.3145             nan     0.0500 -1592318.8908
##    640 16329350638.6897             nan     0.0500 -21655936.4104
##    660 15999126034.0500             nan     0.0500 -14639236.6688
##    680 15702346806.0136             nan     0.0500 -14078268.6964
##    700 15443020436.6287             nan     0.0500 -22239535.0661
##    720 15126033295.2094             nan     0.0500 -30529749.0061
##    740 14840617175.3650             nan     0.0500 -18555045.2787
##    760 14592825766.2101             nan     0.0500 -23107962.1107
##    780 14357616647.6201             nan     0.0500 539865.8668
##    800 14150789134.4171             nan     0.0500 -14102725.3274
##    820 13928770959.4328             nan     0.0500 -26432641.7051
##    840 13710478684.3644             nan     0.0500 29406.6383
##    860 13523113186.7292             nan     0.0500 -11540354.9817
##    880 13288946667.3787             nan     0.0500 -26563047.3513
##    900 13093980994.4768             nan     0.0500 -15788395.7034
##    920 12916438229.7933             nan     0.0500 -4021908.1754
##    940 12719469574.2668             nan     0.0500 303459.2119
##    960 12546101979.3861             nan     0.0500 -8743404.0026
##    980 12396688526.6400             nan     0.0500 -5621251.2413
##   1000 12241225765.2774             nan     0.0500 2103991.5437
##   1020 12076691259.7292             nan     0.0500 3855302.4047
##   1040 11897904603.7746             nan     0.0500 -999378.3232
##   1060 11736241821.5887             nan     0.0500 6068188.3153
##   1080 11594712197.0245             nan     0.0500 -9725358.0435
##   1100 11451937555.7922             nan     0.0500 -5384391.0362
##   1120 11299067731.1017             nan     0.0500 -7124763.9688
##   1140 11163858880.0871             nan     0.0500 -11759937.3388
##   1160 11039880098.5612             nan     0.0500 -11120292.5412
##   1180 10905100392.5950             nan     0.0500 -4255707.4755
##   1200 10783942548.3931             nan     0.0500 -11910226.7833
##   1220 10657191406.7658             nan     0.0500 -13200159.2249
##   1240 10534719205.3029             nan     0.0500 -5601883.9121
##   1260 10417624070.3429             nan     0.0500 -4993429.6416
##   1280 10289588232.3086             nan     0.0500 -6647698.3742
##   1300 10173827558.8727             nan     0.0500 -4782580.1154
##   1320 10047707848.0734             nan     0.0500 -3434441.3790
##   1340 9926152032.0329             nan     0.0500 -3288749.6139
##   1360 9816290202.5436             nan     0.0500 -5846966.6305
##   1380 9709331409.3669             nan     0.0500 -3216073.9386
##   1400 9612070013.0681             nan     0.0500 -6060861.1698
##   1420 9500504159.8758             nan     0.0500 -3741334.3132
##   1440 9402836373.4466             nan     0.0500 -5013655.2343
##   1460 9309239683.6499             nan     0.0500 -2206689.1406
##   1480 9206978773.3292             nan     0.0500 -7473899.1324
##   1500 9108710725.7639             nan     0.0500 -4484757.3616
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258934579543.9947             nan     0.0500 14237476162.2671
##      2 240933767023.7702             nan     0.0500 16575237534.2692
##      3 226306640102.1287             nan     0.0500 15981218977.1003
##      4 213029829409.8011             nan     0.0500 11171849151.0881
##      5 201129415220.9012             nan     0.0500 13562586771.8449
##      6 189802782802.7922             nan     0.0500 11094156853.3848
##      7 179020926911.0676             nan     0.0500 11319883860.8236
##      8 170332396970.3209             nan     0.0500 9691186413.2369
##      9 161955082815.6409             nan     0.0500 8348154990.5642
##     10 154397319726.4233             nan     0.0500 7413416938.0460
##     20 98793644963.3914             nan     0.0500 3269180292.1477
##     40 58272509776.8767             nan     0.0500 923494507.5351
##     60 44818895959.1949             nan     0.0500 180236697.4430
##     80 39094858706.4861             nan     0.0500 2106030.7391
##    100 36312311618.4917             nan     0.0500 -33515137.2962
##    120 33997933051.8143             nan     0.0500 -8859789.8524
##    140 32175096534.2564             nan     0.0500 -9073498.6873
##    160 30819972225.5311             nan     0.0500 -48268809.3849
##    180 29574834713.4712             nan     0.0500 -65702353.7148
##    200 28625753103.5119             nan     0.0500 -48428202.7010
##    220 27753655179.5560             nan     0.0500 -81766678.3598
##    240 26730831676.3307             nan     0.0500 -65244573.4810
##    260 25972372503.2402             nan     0.0500 -73008970.8392
##    280 25154442029.7148             nan     0.0500 -61840825.8312
##    300 24484317728.7191             nan     0.0500 -27306807.6584
##    320 23737272849.8498             nan     0.0500 -44558790.9189
##    340 23204294309.6993             nan     0.0500 -14221840.9176
##    360 22686971125.3850             nan     0.0500 -34159853.9166
##    380 22062281652.7747             nan     0.0500 -38520547.6398
##    400 21573655501.1326             nan     0.0500 -54068994.3169
##    420 21019827775.7742             nan     0.0500 -33336235.4249
##    440 20555938087.8315             nan     0.0500 -26906869.2912
##    460 20062885278.3070             nan     0.0500 5559276.3396
##    480 19632260349.0112             nan     0.0500 -20739585.1274
##    500 19240007120.0073             nan     0.0500 -39622925.3554
##    520 18849524452.4819             nan     0.0500 -25771002.0853
##    540 18472068959.5482             nan     0.0500 -35953472.9918
##    560 18068351000.4883             nan     0.0500 -40664628.5374
##    580 17692739124.6102             nan     0.0500 4825989.4439
##    600 17382468206.7713             nan     0.0500 -25513442.0310
##    620 17097738096.3035             nan     0.0500 -552195.1163
##    640 16782899845.4806             nan     0.0500 -22916908.9074
##    660 16468511337.6971             nan     0.0500 -35423006.9020
##    680 16128878720.0223             nan     0.0500 4455191.0466
##    700 15841648997.9734             nan     0.0500 -16873186.1581
##    720 15560347203.3678             nan     0.0500 -9482669.8190
##    740 15260483689.1468             nan     0.0500 -26235201.7799
##    760 15010724532.7511             nan     0.0500 -22144741.7679
##    780 14782903058.6981             nan     0.0500 381394.0074
##    800 14537447150.7428             nan     0.0500 -6116564.0419
##    820 14300438370.1942             nan     0.0500 -8796689.4180
##    840 14104232854.2105             nan     0.0500 -23994526.0066
##    860 13872748485.2191             nan     0.0500 9824968.2264
##    880 13699792401.5292             nan     0.0500 -12348176.4338
##    900 13497350821.8412             nan     0.0500 2864677.4175
##    920 13277278465.1533             nan     0.0500 -13189458.0490
##    940 13080486098.9773             nan     0.0500 -15903995.6423
##    960 12876203055.2070             nan     0.0500 -3178705.5375
##    980 12664045726.4615             nan     0.0500 -10226292.1814
##   1000 12507894670.4681             nan     0.0500 -11914145.8830
##   1020 12338618277.8486             nan     0.0500 -11590912.4809
##   1040 12177686900.0226             nan     0.0500 -7323016.5922
##   1060 11992628545.8653             nan     0.0500 -8468837.5059
##   1080 11827369493.2815             nan     0.0500 -5999329.4652
##   1100 11680489180.8167             nan     0.0500 -6137686.7665
##   1120 11544943308.3848             nan     0.0500 -7181798.5133
##   1140 11438200653.2138             nan     0.0500 -23655330.3182
##   1160 11287631507.1222             nan     0.0500 -10556567.9782
##   1180 11157629800.0825             nan     0.0500 -15192861.8351
##   1200 11025144418.6088             nan     0.0500 -4761752.3710
##   1220 10886190530.7106             nan     0.0500 -22834351.4207
##   1240 10767219439.3612             nan     0.0500 -10920229.8718
##   1260 10643387233.2931             nan     0.0500 -14577632.4368
##   1280 10534865816.2924             nan     0.0500 -2541396.1470
##   1300 10434379980.0400             nan     0.0500 -20248007.6511
##   1320 10296054358.9943             nan     0.0500 -6703048.8339
##   1340 10190385581.0233             nan     0.0500 -1010243.0515
##   1360 10077256467.6261             nan     0.0500 -970221.8580
##   1380 9964210953.7809             nan     0.0500 143087.3445
##   1400 9855001376.9561             nan     0.0500 -10988073.8072
##   1420 9747587995.9145             nan     0.0500 -5914786.8445
##   1440 9640183729.4192             nan     0.0500 1096614.0954
##   1460 9545021458.2459             nan     0.0500 -10373190.2713
##   1480 9436484233.8647             nan     0.0500 -277812.0446
##   1500 9345105773.8027             nan     0.0500 -6448944.8384
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 256575314690.1495             nan     0.0500 16244631225.8447
##      2 240714287543.3895             nan     0.0500 15167759082.9650
##      3 225339558477.5882             nan     0.0500 15072426950.7023
##      4 211465649178.6497             nan     0.0500 11351305168.1097
##      5 198068036006.4715             nan     0.0500 11122150404.9971
##      6 186760874885.0877             nan     0.0500 9190553009.3746
##      7 175942727248.2926             nan     0.0500 9414479303.7813
##      8 166994383513.1892             nan     0.0500 8581283178.0495
##      9 158466898677.0564             nan     0.0500 7457184000.0009
##     10 150629075251.4391             nan     0.0500 8019686319.2440
##     20 97486036794.3419             nan     0.0500 3213203378.9284
##     40 58701459633.4179             nan     0.0500 856867995.7917
##     60 45704062115.2525             nan     0.0500 267351345.9416
##     80 39811334526.3744             nan     0.0500 161531374.6786
##    100 36604194353.3230             nan     0.0500 -140779166.8133
##    120 34412582944.3449             nan     0.0500 -172479248.0714
##    140 32505301063.9842             nan     0.0500 -38246932.6614
##    160 31208574394.2916             nan     0.0500 -63069223.0032
##    180 29854604022.3709             nan     0.0500 -61526368.0493
##    200 28590743677.5116             nan     0.0500 -59497812.1719
##    220 27567209753.7931             nan     0.0500 16142712.8177
##    240 26531668201.7047             nan     0.0500 -50272119.7337
##    260 25640266126.2039             nan     0.0500 -41315246.1685
##    280 24810499300.9985             nan     0.0500 -71735522.6957
##    300 24023043339.4724             nan     0.0500 -20368084.1013
##    320 23256621690.9287             nan     0.0500 -34997660.7351
##    340 22696319071.4292             nan     0.0500 -65460349.8588
##    360 22059049302.6533             nan     0.0500 -6224039.5368
##    380 21483362057.7676             nan     0.0500 -52345925.3536
##    400 20942592742.5251             nan     0.0500 -7733630.6510
##    420 20414818487.9548             nan     0.0500 -18364242.2119
##    440 19960119213.5106             nan     0.0500 -27657315.5877
##    460 19510513307.8449             nan     0.0500 -26421947.7641
##    480 19082727583.9125             nan     0.0500 1749217.3108
##    500 18669671549.3855             nan     0.0500 -7758499.4744
##    520 18266110469.1421             nan     0.0500 13266302.3024
##    540 17899847646.0134             nan     0.0500 -34988153.4126
##    560 17552816546.1778             nan     0.0500 -16131938.1216
##    580 17248627411.6848             nan     0.0500 -22768310.5029
##    600 16929303248.9091             nan     0.0500 -28034239.7535
##    620 16613761012.0206             nan     0.0500 -19856404.4434
##    640 16315869753.3484             nan     0.0500 -4103583.4611
##    660 16037370291.8895             nan     0.0500 -7589965.3044
##    680 15799429389.3833             nan     0.0500 -17323618.1932
##    700 15529452797.7571             nan     0.0500 -3047632.3231
##    720 15271666053.6237             nan     0.0500 -20548687.4629
##    740 15032109990.7171             nan     0.0500 -17434209.1919
##    760 14765607379.0539             nan     0.0500 -22587114.5724
##    780 14546863993.0572             nan     0.0500 -9414862.7510
##    800 14287710340.9180             nan     0.0500 -10197706.3782
##    820 14085616682.3117             nan     0.0500 -20888380.6467
##    840 13882860680.5960             nan     0.0500 -21360796.8506
##    860 13675347517.1912             nan     0.0500 -14176084.9950
##    880 13461577372.3609             nan     0.0500 -12952156.2829
##    900 13281858918.7162             nan     0.0500 -16107645.8380
##    920 13082400182.2423             nan     0.0500 -8919449.7501
##    940 12857425514.9486             nan     0.0500 -18953400.9135
##    960 12690193517.8093             nan     0.0500 -3980519.2865
##    980 12508419404.8229             nan     0.0500 -9167607.9393
##   1000 12341493985.6557             nan     0.0500 -12666302.3843
##   1020 12192953448.5454             nan     0.0500 -25537864.1412
##   1040 12034953608.7971             nan     0.0500 8911578.6826
##   1060 11850967655.4558             nan     0.0500 -6906910.5347
##   1080 11702901099.8584             nan     0.0500 -6891859.9247
##   1100 11543891729.3056             nan     0.0500 -6062850.8477
##   1120 11416310199.5860             nan     0.0500 -6143817.7279
##   1140 11258375556.3727             nan     0.0500 -886344.3903
##   1160 11132110205.7559             nan     0.0500 -3804181.1158
##   1180 10976388004.0598             nan     0.0500 -11694435.5430
##   1200 10844824518.2620             nan     0.0500 -10442208.6716
##   1220 10717210805.4826             nan     0.0500 -238673.7314
##   1240 10607343635.1456             nan     0.0500 -17863340.4280
##   1260 10474200227.7402             nan     0.0500 -5575062.4740
##   1280 10359291830.1909             nan     0.0500 -4672661.4207
##   1300 10242102503.9871             nan     0.0500 -1918692.2255
##   1320 10141211572.6061             nan     0.0500 -5478251.7348
##   1340 10022916057.4367             nan     0.0500 -16705009.4880
##   1360 9905705771.7060             nan     0.0500 -4805449.6203
##   1380 9783531713.3331             nan     0.0500 -4475493.5101
##   1400 9677219027.9134             nan     0.0500 -4225806.1684
##   1420 9577098098.1061             nan     0.0500 -8663597.7153
##   1440 9479000471.1130             nan     0.0500 -10982000.2927
##   1460 9384299717.6869             nan     0.0500 -4216753.7597
##   1480 9288521333.4792             nan     0.0500 -7518065.9888
##   1500 9200229937.5457             nan     0.0500 -2312352.1501
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 259713250186.4764             nan     0.0500 18916373748.5351
##      2 242645294916.7951             nan     0.0500 16060233434.9988
##      3 227904686354.1818             nan     0.0500 14760286420.5051
##      4 214768963352.1091             nan     0.0500 13326799966.4317
##      5 202787101918.8123             nan     0.0500 12117787504.6699
##      6 190707888298.4553             nan     0.0500 11782815672.6109
##      7 180287869272.8154             nan     0.0500 8963087932.7472
##      8 170126514922.6546             nan     0.0500 9618482585.5681
##      9 162373945017.2156             nan     0.0500 7387410059.9165
##     10 154403481079.7264             nan     0.0500 6304703885.0916
##     20 100892365229.9885             nan     0.0500 3446922951.0517
##     40 61291032286.5811             nan     0.0500 679485670.1946
##     60 47499628844.4942             nan     0.0500 129285739.0114
##     80 41042280304.1604             nan     0.0500 -34790715.7232
##    100 37909128081.5381             nan     0.0500 -2380659.2287
##    120 35772885627.1508             nan     0.0500 -117781851.5312
##    140 34058692782.4624             nan     0.0500 -63738547.7824
##    160 32389711586.6867             nan     0.0500 -40183146.1317
##    180 31013006877.3264             nan     0.0500 -36498934.3300
##    200 29791658251.5737             nan     0.0500 8553849.0868
##    220 28644634472.4789             nan     0.0500 -75384871.7432
##    240 27651364618.1782             nan     0.0500 -124006065.1046
##    260 26797062166.7216             nan     0.0500 -14154158.6827
##    280 26010341222.3934             nan     0.0500 -50272195.1136
##    300 25281967774.8183             nan     0.0500 -45423300.5751
##    320 24626871066.4330             nan     0.0500 -38204496.9297
##    340 23837924235.1658             nan     0.0500 -33250298.2676
##    360 23146166406.0604             nan     0.0500 -21549456.8772
##    380 22463437902.1060             nan     0.0500 10964059.7955
##    400 21831567821.9918             nan     0.0500 -1722411.1485
##    420 21279278784.1337             nan     0.0500 -10163645.0498
##    440 20794820974.7560             nan     0.0500 -1893078.8858
##    460 20336301572.2341             nan     0.0500 -49303226.4162
##    480 19894468740.6599             nan     0.0500 -33257822.2015
##    500 19485499352.2577             nan     0.0500 -30032895.9679
##    520 19061670058.3289             nan     0.0500 -37211601.3410
##    540 18675981785.1329             nan     0.0500 -41409707.5692
##    560 18285577224.5204             nan     0.0500 -41958837.5345
##    580 17956922293.4955             nan     0.0500 -40888681.6876
##    600 17560417989.4106             nan     0.0500 -9002417.8663
##    620 17256138439.9362             nan     0.0500 -34217809.4956
##    640 16913752545.4966             nan     0.0500 -7100024.0419
##    660 16649252461.9957             nan     0.0500 -23058690.6213
##    680 16329188138.6945             nan     0.0500 -39065136.3006
##    700 16056533280.0241             nan     0.0500 -31371899.9771
##    720 15835359753.0895             nan     0.0500 -15170197.8959
##    740 15577301852.1263             nan     0.0500 8175711.5027
##    760 15327354268.7961             nan     0.0500 -8755556.5901
##    780 15065898334.6127             nan     0.0500 -13514662.8419
##    800 14835820707.2240             nan     0.0500 -18417785.6551
##    820 14593537354.1255             nan     0.0500 -25449840.3774
##    840 14378272787.4112             nan     0.0500 -873093.3246
##    860 14164810563.8718             nan     0.0500 -23514887.4994
##    880 13959303946.1004             nan     0.0500 -22282143.2087
##    900 13804324665.3021             nan     0.0500 -26240688.7695
##    920 13628632535.8752             nan     0.0500 8960456.3861
##    940 13445533667.4205             nan     0.0500 -13484442.4791
##    960 13245559042.9270             nan     0.0500 -18128143.5093
##    980 13061516890.0317             nan     0.0500 -14267927.3418
##   1000 12878010972.3810             nan     0.0500 -5687490.1319
##   1020 12675137943.5755             nan     0.0500 -8628304.8618
##   1040 12509764904.7436             nan     0.0500 -10998842.9745
##   1060 12365480551.6777             nan     0.0500 -5772616.2326
##   1080 12188836250.0177             nan     0.0500 -6126891.4251
##   1100 12004984315.2020             nan     0.0500 2112867.3349
##   1120 11867594157.0619             nan     0.0500 -3832272.9223
##   1140 11742778693.4315             nan     0.0500 -9148620.1283
##   1160 11601763388.5370             nan     0.0500 -16664479.9073
##   1180 11448899451.5459             nan     0.0500 -12171535.3645
##   1200 11271945676.8977             nan     0.0500 -1060693.3922
##   1220 11121263942.3734             nan     0.0500 -9284615.2991
##   1240 10995762736.1480             nan     0.0500 -14486879.7827
##   1260 10869425402.2591             nan     0.0500 -12952780.6084
##   1280 10779078275.8334             nan     0.0500 -11176056.4927
##   1300 10661245837.8549             nan     0.0500 -5546547.1185
##   1320 10551212627.0533             nan     0.0500 -8328320.8494
##   1340 10428751945.9096             nan     0.0500 -10035990.1910
##   1360 10316829904.9935             nan     0.0500 -6823098.8167
##   1380 10192657713.1791             nan     0.0500 -14733828.0764
##   1400 10069528075.1755             nan     0.0500 -6987028.7109
##   1420 9957485417.7389             nan     0.0500 -10212853.2007
##   1440 9860756800.5674             nan     0.0500 -7696212.6578
##   1460 9763676673.8184             nan     0.0500 -6568035.9439
##   1480 9668600121.9779             nan     0.0500 -6820813.7752
##   1500 9562609969.1504             nan     0.0500 -7930935.0340
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 243187185231.1353             nan     0.0500 16129206371.9213
##      2 228711957418.4793             nan     0.0500 15030617867.0021
##      3 214826008402.9748             nan     0.0500 12318123021.1741
##      4 202418098562.9252             nan     0.0500 11402391407.8545
##      5 190386901288.4785             nan     0.0500 12675779554.2958
##      6 180492034339.1853             nan     0.0500 9488040594.7388
##      7 170625260111.5352             nan     0.0500 9801360508.4649
##      8 161825413877.1815             nan     0.0500 8317245048.5401
##      9 153708276291.2162             nan     0.0500 6080023007.3792
##     10 146581495893.7227             nan     0.0500 6975637411.5139
##     20 94659061386.3714             nan     0.0500 3097486211.8222
##     40 57895304980.1125             nan     0.0500 348903210.5535
##     60 45736273552.4510             nan     0.0500 298421604.9010
##     80 39966380257.2454             nan     0.0500 67580162.0355
##    100 37083325585.2244             nan     0.0500 -51849910.2425
##    120 34947443193.2500             nan     0.0500 -41897360.6346
##    140 32930343616.2975             nan     0.0500 -56645034.8416
##    160 31469697301.0035             nan     0.0500 -122610355.4524
##    180 30156548340.9028             nan     0.0500 -80939339.6009
##    200 28941453065.6327             nan     0.0500 -48058537.8465
##    220 27914490868.1277             nan     0.0500 -70657790.0271
##    240 26878935372.3127             nan     0.0500 -29851223.3823
##    260 26059360504.7330             nan     0.0500 -66254223.1655
##    280 25348417626.9655             nan     0.0500 -24846278.1722
##    300 24643115195.1666             nan     0.0500 -35716917.4143
##    320 23936908403.5051             nan     0.0500 -40370781.9239
##    340 23362098651.8433             nan     0.0500 -39344.2467
##    360 22682013997.2572             nan     0.0500 -33813522.7364
##    380 22106793815.3879             nan     0.0500 -48922371.1199
##    400 21474509989.6000             nan     0.0500 -13033927.0078
##    420 21049151004.9361             nan     0.0500 -42712707.7421
##    440 20529325975.1639             nan     0.0500 10282197.2613
##    460 20030337407.6464             nan     0.0500 -52823060.5957
##    480 19483591222.1736             nan     0.0500 -20329585.5941
##    500 19022951264.0371             nan     0.0500 -37472666.5809
##    520 18617950578.2438             nan     0.0500 -27471657.2546
##    540 18237370898.4419             nan     0.0500 -34909511.7937
##    560 17901656796.8856             nan     0.0500 -23573980.8633
##    580 17520505296.2404             nan     0.0500 -18100370.1777
##    600 17169709431.2019             nan     0.0500 -13069312.1346
##    620 16870077106.7719             nan     0.0500 -8207951.5889
##    640 16547829481.2617             nan     0.0500 -17755470.6889
##    660 16241391381.3739             nan     0.0500 -1973704.9177
##    680 15969733875.8451             nan     0.0500 -21241653.3614
##    700 15750444248.8881             nan     0.0500 -22602653.4164
##    720 15481802217.9946             nan     0.0500 2860697.6600
##    740 15248657142.7552             nan     0.0500 -6544168.8025
##    760 15042936559.1360             nan     0.0500 -18260460.0028
##    780 14796209902.9408             nan     0.0500 -3463667.9372
##    800 14552703667.1808             nan     0.0500 -19175043.8613
##    820 14333741297.9526             nan     0.0500 -12467760.9592
##    840 14078789340.6881             nan     0.0500 -13512580.4242
##    860 13847419106.7138             nan     0.0500 -16292827.0069
##    880 13631884298.9941             nan     0.0500 -11011991.5521
##    900 13437479042.6727             nan     0.0500 -2944989.8390
##    920 13221561821.5726             nan     0.0500 2570707.0978
##    940 13032131413.5857             nan     0.0500 10518623.8246
##    960 12850237917.8462             nan     0.0500 -11450516.0729
##    980 12687191032.9075             nan     0.0500 -5257949.4156
##   1000 12527334693.9891             nan     0.0500 -10892267.1150
##   1020 12380761843.8854             nan     0.0500 -8790529.8669
##   1040 12197348703.4369             nan     0.0500 -14258581.5155
##   1060 12016029471.1690             nan     0.0500 -11540545.0206
##   1080 11851616447.7543             nan     0.0500 -8943748.8287
##   1100 11691727251.0452             nan     0.0500 -4912274.0691
##   1120 11545094186.9205             nan     0.0500 -18970868.3011
##   1140 11401485133.1011             nan     0.0500 -15998224.7362
##   1160 11257494965.4137             nan     0.0500 -15056736.8053
##   1180 11144975246.4330             nan     0.0500 -18797861.8827
##   1200 11022845306.1885             nan     0.0500 -4155012.1926
##   1220 10901827860.8408             nan     0.0500 -9024635.0317
##   1240 10783353826.0913             nan     0.0500 -14286404.1728
##   1260 10668757111.9792             nan     0.0500 -1062104.7459
##   1280 10549186467.6458             nan     0.0500 -2865469.8599
##   1300 10427945437.4993             nan     0.0500 -10357637.0973
##   1320 10321132582.5366             nan     0.0500 -11655148.5413
##   1340 10193811221.4553             nan     0.0500 -6848024.0918
##   1360 10054785938.5676             nan     0.0500 -3754739.3788
##   1380 9943087485.1230             nan     0.0500 -5033174.5956
##   1400 9827395804.5145             nan     0.0500 -6604843.9380
##   1420 9725623335.6331             nan     0.0500 -10615608.5400
##   1440 9637097724.2771             nan     0.0500 -6793021.2533
##   1460 9531962636.4477             nan     0.0500 -9062802.6480
##   1480 9430082308.6168             nan     0.0500 -15760122.8142
##   1500 9338081009.0831             nan     0.0500 -8950227.0343
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258742833950.3639             nan     0.0500 16759864754.9238
##      2 242452644536.5377             nan     0.0500 15011826684.7267
##      3 228133967160.9022             nan     0.0500 14138367201.4446
##      4 214797299196.6986             nan     0.0500 13927045935.7210
##      5 203034865781.3854             nan     0.0500 12421363221.3702
##      6 191884198466.2985             nan     0.0500 11480355974.1991
##      7 181347624561.8727             nan     0.0500 9056625010.4074
##      8 171499652096.9721             nan     0.0500 8537790038.1054
##      9 163276457037.8472             nan     0.0500 7999745605.6221
##     10 155143531041.3646             nan     0.0500 6963615067.8906
##     20 102156922484.0829             nan     0.0500 3871890545.4141
##     40 60529134833.4183             nan     0.0500 1278709311.5129
##     60 47368715394.8145             nan     0.0500 261890551.8876
##     80 41424382922.7093             nan     0.0500 53813016.1957
##    100 38175611767.4931             nan     0.0500 68567007.5217
##    120 35497967306.7326             nan     0.0500 628191.0548
##    140 33615984788.8163             nan     0.0500 -127240782.9664
##    160 32054424182.4867             nan     0.0500 -7822820.4876
##    180 30477747872.3252             nan     0.0500 -70512633.5081
##    200 29383137924.8566             nan     0.0500 -162776810.2783
##    220 28237439713.0659             nan     0.0500 -57195316.3497
##    240 27287453261.2309             nan     0.0500 -101933069.6512
##    260 26371902380.7392             nan     0.0500 12117782.2190
##    280 25527426521.3213             nan     0.0500 -41106102.6961
##    300 24805582212.0646             nan     0.0500 -145626108.9905
##    320 24054139207.9232             nan     0.0500 -67432623.6315
##    340 23399830620.7388             nan     0.0500 -59520355.4527
##    360 22705868259.1157             nan     0.0500 -24153272.0025
##    380 22180455416.9219             nan     0.0500 -41322149.3425
##    400 21663707915.7492             nan     0.0500 -11988604.8418
##    420 21219235358.6150             nan     0.0500 -50766484.6990
##    440 20781485419.9021             nan     0.0500 -47634799.7097
##    460 20314792290.1386             nan     0.0500 -49551027.8518
##    480 19868242942.0312             nan     0.0500 -38231177.4115
##    500 19469927362.4392             nan     0.0500 -26238482.8175
##    520 19100237373.7857             nan     0.0500 -38587903.2440
##    540 18684719813.5605             nan     0.0500 -34746071.5140
##    560 18322561225.4882             nan     0.0500 -5693277.1019
##    580 17936786251.3797             nan     0.0500 -36791035.1286
##    600 17533068840.7963             nan     0.0500 -32479436.7430
##    620 17188855295.6374             nan     0.0500 -24961934.1628
##    640 16923707510.5254             nan     0.0500 -20757850.8622
##    660 16570236155.3669             nan     0.0500 9073560.5453
##    680 16251732469.0596             nan     0.0500 -33434738.2138
##    700 15960271839.9636             nan     0.0500 -12102828.0859
##    720 15670974940.5105             nan     0.0500 -20860302.3724
##    740 15417185202.1997             nan     0.0500 -24531636.9841
##    760 15166038123.9784             nan     0.0500 -10527652.3131
##    780 14898239186.9682             nan     0.0500 -28357474.6724
##    800 14617127979.8177             nan     0.0500 -13958272.9703
##    820 14400037408.6517             nan     0.0500 -17633059.3647
##    840 14168748209.9200             nan     0.0500 -16862144.2924
##    860 13914615602.6901             nan     0.0500 -20593040.2041
##    880 13712568396.3190             nan     0.0500 -9453965.8745
##    900 13490915353.1742             nan     0.0500 3999099.1435
##    920 13257565126.3746             nan     0.0500 -18055710.2034
##    940 13080843010.1786             nan     0.0500 -8694210.7340
##    960 12893710310.4493             nan     0.0500 -5014229.0826
##    980 12733470137.9460             nan     0.0500 -11595343.6710
##   1000 12586796059.8268             nan     0.0500 -2382294.4580
##   1020 12437137971.5958             nan     0.0500 -11466625.0147
##   1040 12259670170.8707             nan     0.0500 -11274315.3410
##   1060 12089127694.2857             nan     0.0500 -18542748.5314
##   1080 11922217146.3490             nan     0.0500 -11017313.5139
##   1100 11783463270.7614             nan     0.0500 -21116795.6619
##   1120 11644249408.8850             nan     0.0500 -11153932.1556
##   1140 11489223319.8264             nan     0.0500 -2686081.1554
##   1160 11343353086.3522             nan     0.0500 -6723961.6277
##   1180 11211561543.7146             nan     0.0500 -14102999.0153
##   1200 11086737503.9676             nan     0.0500 -7208335.0495
##   1220 10955997977.5031             nan     0.0500 -4385203.1547
##   1240 10837505657.4847             nan     0.0500 605952.2496
##   1260 10709760070.2060             nan     0.0500 -3639625.4985
##   1280 10579121095.0096             nan     0.0500 -3732003.3678
##   1300 10442276914.0743             nan     0.0500 -3525701.1182
##   1320 10329424973.0600             nan     0.0500 -5503314.9453
##   1340 10223218212.7415             nan     0.0500 -6442546.3930
##   1360 10120500022.6566             nan     0.0500 -13657271.2775
##   1380 10000420677.0673             nan     0.0500 -2249891.0675
##   1400 9884864283.8894             nan     0.0500 -4688134.6832
##   1420 9785948428.9338             nan     0.0500 -14826864.4590
##   1440 9661219881.5906             nan     0.0500 -5540889.2144
##   1460 9554551909.1617             nan     0.0500 845167.5965
##   1480 9448480789.9798             nan     0.0500 -6260660.0244
##   1500 9330783401.1039             nan     0.0500 -559315.0543
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 242649791951.7567             nan     0.0500 16983706767.5695
##      2 226899256983.6523             nan     0.0500 15026029479.2680
##      3 213226325677.6133             nan     0.0500 14521747157.2713
##      4 200250654514.3906             nan     0.0500 13094599179.7760
##      5 187638958745.4034             nan     0.0500 11433963563.6074
##      6 177519569421.1631             nan     0.0500 10941234458.0073
##      7 167206066584.8113             nan     0.0500 10026213696.3536
##      8 158549949146.1157             nan     0.0500 6527886501.4918
##      9 149968611879.0331             nan     0.0500 7712177103.3566
##     10 142680182367.6884             nan     0.0500 7184755146.8896
##     20 91169632023.4790             nan     0.0500 3245791566.1835
##     40 53897570577.7340             nan     0.0500 843852861.4636
##     60 41458642737.7700             nan     0.0500 288338640.5952
##     80 36271368056.5096             nan     0.0500 64580174.0370
##    100 33794943115.7794             nan     0.0500 38655206.2278
##    120 31828887597.6988             nan     0.0500 -15456699.7254
##    140 30073205203.7635             nan     0.0500 -55866918.7899
##    160 28875422973.2454             nan     0.0500 -75470279.3854
##    180 27615517035.8404             nan     0.0500 -47529149.4288
##    200 26680991753.4261             nan     0.0500 -746096.4479
##    220 25517521528.5585             nan     0.0500 -1631407.5214
##    240 24622364024.6456             nan     0.0500 11609351.2090
##    260 23824746093.6051             nan     0.0500 -33552222.6368
##    280 23066801328.0429             nan     0.0500 -65638555.0309
##    300 22460102705.2514             nan     0.0500 -28186160.6690
##    320 21843620874.1590             nan     0.0500 -17534476.0817
##    340 21311041631.8160             nan     0.0500 -18111846.7083
##    360 20791837518.9841             nan     0.0500 -51999690.8423
##    380 20267154864.3514             nan     0.0500 -33252693.4670
##    400 19771770684.7683             nan     0.0500 -44414843.7601
##    420 19336322802.7429             nan     0.0500 -13817269.0757
##    440 18887855828.3470             nan     0.0500 -9338933.3557
##    460 18513848150.8026             nan     0.0500 -27599674.6137
##    480 18162261095.8200             nan     0.0500 -3731714.7469
##    500 17831386335.0100             nan     0.0500 2068265.5011
##    520 17421087821.5427             nan     0.0500 -17199415.3592
##    540 17062236124.3499             nan     0.0500 -22216742.0628
##    560 16733497627.1632             nan     0.0500 -7656296.9194
##    580 16401541533.7033             nan     0.0500 -21079165.4139
##    600 16141138050.5743             nan     0.0500 -23170629.5389
##    620 15791066935.7902             nan     0.0500 7650453.1239
##    640 15510494962.5572             nan     0.0500 -24217707.0143
##    660 15261522368.7625             nan     0.0500 -22869580.6837
##    680 15008288356.9923             nan     0.0500 -13065932.5142
##    700 14766520077.9751             nan     0.0500 -8163148.0764
##    720 14542710625.9038             nan     0.0500 -12269956.5528
##    740 14352189933.2497             nan     0.0500 -7353802.5127
##    760 14083911070.4984             nan     0.0500 -12786713.1933
##    780 13876005342.4605             nan     0.0500 8947978.5370
##    800 13668227207.8030             nan     0.0500 3960920.3520
##    820 13447193279.6456             nan     0.0500 -19383750.8741
##    840 13237281415.3513             nan     0.0500 -6573590.1201
##    860 13011244671.7442             nan     0.0500 254482.6373
##    880 12830314020.1302             nan     0.0500 -10140797.6317
##    900 12671834846.0258             nan     0.0500 -9104514.7888
##    920 12452143603.1106             nan     0.0500 -13302319.0451
##    940 12253614396.3100             nan     0.0500 -3329634.7026
##    960 12075332159.5742             nan     0.0500 -11715550.6576
##    980 11926895486.3842             nan     0.0500 -16596680.5373
##   1000 11740952242.8241             nan     0.0500 -12429524.8977
##   1020 11579470697.8975             nan     0.0500 -858942.0569
##   1040 11434129052.5559             nan     0.0500 -10028951.2298
##   1060 11314173030.3438             nan     0.0500 -9533848.6098
##   1080 11161768909.1161             nan     0.0500 -8695156.7183
##   1100 11027318670.8928             nan     0.0500 -10460093.6426
##   1120 10899683968.5380             nan     0.0500 -7711338.3771
##   1140 10768220699.6991             nan     0.0500 -7949233.7589
##   1160 10649474800.7277             nan     0.0500 -12207420.5203
##   1180 10540663394.3777             nan     0.0500 -14104524.6598
##   1200 10406814305.1475             nan     0.0500 -2622247.9774
##   1220 10284710289.6902             nan     0.0500 -12634267.9793
##   1240 10157965133.0620             nan     0.0500 -12743356.8576
##   1260 10049976998.5291             nan     0.0500 -3459703.6568
##   1280 9947651720.3491             nan     0.0500 -10878345.9839
##   1300 9833587874.0937             nan     0.0500 -9536596.6407
##   1320 9725188485.9391             nan     0.0500 -11929108.9410
##   1340 9622486269.7147             nan     0.0500 -7772216.5459
##   1360 9529372648.5437             nan     0.0500 1384393.4903
##   1380 9434297401.5934             nan     0.0500 -12459802.1597
##   1400 9332237848.3992             nan     0.0500 -5848147.4012
##   1420 9235863831.6028             nan     0.0500 -8656609.1792
##   1440 9134784158.1711             nan     0.0500 -2294019.4827
##   1460 9035265157.1491             nan     0.0500 -7208087.7665
##   1480 8949685451.8688             nan     0.0500 963808.8065
##   1500 8855094548.9893             nan     0.0500 -2555951.7967
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 248833159947.2840             nan     0.0500 16057858620.7577
##      2 232619360144.8608             nan     0.0500 16263070388.7636
##      3 220298703295.5231             nan     0.0500 13567914361.1876
##      4 206385945434.2388             nan     0.0500 13652958807.6211
##      5 194672370331.1234             nan     0.0500 11369929202.5687
##      6 184520512347.3973             nan     0.0500 10722657826.8694
##      7 175237383198.0252             nan     0.0500 9090670691.2852
##      8 165979343343.7433             nan     0.0500 8320492193.4147
##      9 157841676373.5061             nan     0.0500 6046552990.2481
##     10 149772589124.2349             nan     0.0500 6730772635.5868
##     20 97636511277.4490             nan     0.0500 3337698937.3309
##     40 57649557928.0169             nan     0.0500 649726708.6880
##     60 45180681012.5950             nan     0.0500 250627821.1683
##     80 39009182992.5192             nan     0.0500 51947110.3272
##    100 36052848951.2696             nan     0.0500 -53595799.6151
##    120 33987422589.6317             nan     0.0500 -16170915.3665
##    140 32220029390.5629             nan     0.0500 -100813445.4555
##    160 30774648370.7739             nan     0.0500 -99296938.0866
##    180 29635720049.8813             nan     0.0500 -45643258.2717
##    200 28474591208.0246             nan     0.0500 -47138840.3955
##    220 27435280893.9789             nan     0.0500 -73354400.2893
##    240 26433544820.5561             nan     0.0500 -38909486.2129
##    260 25456499260.7952             nan     0.0500 -110918425.6963
##    280 24866604837.5381             nan     0.0500 -35268882.9235
##    300 24057771067.1045             nan     0.0500 14527216.9412
##    320 23239411562.0904             nan     0.0500 -78007432.1588
##    340 22610916977.8772             nan     0.0500 -39344839.1279
##    360 22043011523.9201             nan     0.0500 -43766786.6722
##    380 21447444301.8052             nan     0.0500 -35721578.8333
##    400 21039873449.8224             nan     0.0500 -44697822.7607
##    420 20531924646.0936             nan     0.0500 -46744918.5340
##    440 20031742154.7612             nan     0.0500 19832009.4939
##    460 19617763217.7395             nan     0.0500 -35549701.0044
##    480 19134432034.8226             nan     0.0500 -35667989.2174
##    500 18701235377.0034             nan     0.0500 -27955964.3153
##    520 18357595361.5324             nan     0.0500 -6140425.6101
##    540 17988927051.7501             nan     0.0500 -25061611.0461
##    560 17632632174.4071             nan     0.0500 353688.5625
##    580 17254106317.3244             nan     0.0500 15719651.3660
##    600 16910641546.0446             nan     0.0500 -30436429.9358
##    620 16594470735.4064             nan     0.0500 1760126.5859
##    640 16324613565.2663             nan     0.0500 -21939800.0444
##    660 16012162946.5632             nan     0.0500 -26044325.7318
##    680 15743180855.5707             nan     0.0500 -28396130.4016
##    700 15492945320.6243             nan     0.0500 -31198181.1055
##    720 15252447227.8296             nan     0.0500 -22485394.5122
##    740 14992852276.0945             nan     0.0500 12195505.2273
##    760 14771471571.1885             nan     0.0500 -13867496.3644
##    780 14523083924.6481             nan     0.0500 -27167917.6835
##    800 14364264256.0811             nan     0.0500 -19994438.8080
##    820 14162725742.3948             nan     0.0500 -18854828.4067
##    840 13971159334.1022             nan     0.0500 -10008647.0812
##    860 13741234721.7846             nan     0.0500 -18593055.4440
##    880 13523783918.5312             nan     0.0500 -21969339.2216
##    900 13331702473.6918             nan     0.0500 -4093809.1060
##    920 13112720188.1189             nan     0.0500 3852395.3150
##    940 12912821096.3408             nan     0.0500 -13449518.8685
##    960 12734708914.5556             nan     0.0500 -12506684.2518
##    980 12549171897.8836             nan     0.0500 -10077656.3448
##   1000 12394169265.6020             nan     0.0500 2512332.2822
##   1020 12225490121.9393             nan     0.0500 -7346233.2622
##   1040 12061379085.9847             nan     0.0500 -4477973.6398
##   1060 11895202288.7772             nan     0.0500 -26914741.8767
##   1080 11741227161.0222             nan     0.0500 -2723824.1436
##   1100 11597348678.3465             nan     0.0500 -11108234.0628
##   1120 11460108363.4075             nan     0.0500 -7813514.4862
##   1140 11309619996.8024             nan     0.0500 -736989.5933
##   1160 11175238745.2420             nan     0.0500 -5931351.7085
##   1180 11037490567.5329             nan     0.0500 -6311229.1797
##   1200 10918736729.3804             nan     0.0500 -4640638.6717
##   1220 10796198946.7346             nan     0.0500 -2088593.0882
##   1240 10653738071.8442             nan     0.0500 -12804449.8296
##   1260 10559811530.1339             nan     0.0500 -7943609.7162
##   1280 10416541984.8042             nan     0.0500 -5470056.6309
##   1300 10290152653.5679             nan     0.0500 -2342649.3261
##   1320 10153398322.8143             nan     0.0500 -582898.1423
##   1340 10033870722.5354             nan     0.0500 -1886630.8477
##   1360 9925001292.7960             nan     0.0500 -7347472.5212
##   1380 9817739144.9454             nan     0.0500 -180765.3187
##   1400 9724898890.2799             nan     0.0500 -2771589.6569
##   1420 9617986186.7312             nan     0.0500 -6243976.7087
##   1440 9518955440.8911             nan     0.0500 -6986625.5845
##   1460 9426981160.8435             nan     0.0500 -4240043.5397
##   1480 9328629266.0048             nan     0.0500 -5243089.0344
##   1500 9239765275.5080             nan     0.0500 -8397765.8881
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 261077204091.5774             nan     0.0500 16806133242.7596
##      2 244330249080.4302             nan     0.0500 16956080769.3180
##      3 228722341723.8415             nan     0.0500 14409075342.7326
##      4 215327081499.5758             nan     0.0500 14100177363.7748
##      5 203828197818.2587             nan     0.0500 11745773133.4069
##      6 191967778446.1989             nan     0.0500 11764262741.2997
##      7 182607931704.8990             nan     0.0500 9565912248.1802
##      8 171121857534.9655             nan     0.0500 10785533504.3119
##      9 162400211890.5793             nan     0.0500 9653796342.5522
##     10 154485468976.7570             nan     0.0500 8448259137.9684
##     20 98818950582.3676             nan     0.0500 3193159486.9382
##     40 58629238861.7265             nan     0.0500 646308856.3876
##     60 45284264461.4765             nan     0.0500 137480633.0107
##     80 40038061262.0787             nan     0.0500 29287859.5241
##    100 36403718320.4851             nan     0.0500 -21018170.3283
##    120 34069055390.4958             nan     0.0500 62451838.4312
##    140 32300773535.3140             nan     0.0500 -142744065.2277
##    160 30532353926.7915             nan     0.0500 -33077416.2770
##    180 29423400534.3304             nan     0.0500 -92190914.2583
##    200 28348499063.4229             nan     0.0500 -24802912.2552
##    220 27345586656.5984             nan     0.0500 -76567199.8085
##    240 26282507274.1979             nan     0.0500 -16082041.6243
##    260 25485021465.0483             nan     0.0500 -23086329.3971
##    280 24768773318.5949             nan     0.0500 -90231856.0652
##    300 24031011750.5534             nan     0.0500 -65636502.4585
##    320 23427742302.3361             nan     0.0500 -59569827.5214
##    340 22678780022.4294             nan     0.0500 -17474527.4837
##    360 22007303591.0790             nan     0.0500 -18694317.1358
##    380 21568427515.2661             nan     0.0500 -30265765.3559
##    400 21056911979.8007             nan     0.0500 -39108193.2960
##    420 20533014950.5934             nan     0.0500 -27756174.0543
##    440 20003958260.9335             nan     0.0500 -45623871.4456
##    460 19569806477.3293             nan     0.0500 -32425909.8731
##    480 19140732818.8711             nan     0.0500 -57714242.5686
##    500 18702563499.4578             nan     0.0500 -46581067.2627
##    520 18264474489.8358             nan     0.0500 -12831916.3091
##    540 17905387121.2503             nan     0.0500 11368837.9054
##    560 17546964874.5429             nan     0.0500 -2896064.9839
##    580 17204859267.4713             nan     0.0500 -12615248.6052
##    600 16908303215.4431             nan     0.0500 -38812901.2064
##    620 16518376569.6275             nan     0.0500 -11047658.2470
##    640 16235393874.6609             nan     0.0500 -28344423.1590
##    660 15978331143.2675             nan     0.0500 -14551411.3764
##    680 15658805934.5003             nan     0.0500 -18867716.7337
##    700 15387328063.6293             nan     0.0500 -23978919.3870
##    720 15146239768.2422             nan     0.0500 -25073237.0977
##    740 14899148452.5827             nan     0.0500 -12083330.1951
##    760 14696150523.9043             nan     0.0500 -5723170.6788
##    780 14416947993.7098             nan     0.0500 -6842044.0232
##    800 14180911653.6609             nan     0.0500 -3670395.3423
##    820 13949197644.4995             nan     0.0500 -16531942.6923
##    840 13724753772.7260             nan     0.0500 123352.8937
##    860 13550495500.3279             nan     0.0500 -15090853.8547
##    880 13353148452.4185             nan     0.0500 -4054470.5902
##    900 13139222972.6544             nan     0.0500 -16754447.0190
##    920 12978933866.7019             nan     0.0500 -19229366.9039
##    940 12824228558.5677             nan     0.0500 -13009040.9159
##    960 12645632527.4091             nan     0.0500 -12596057.4968
##    980 12487711988.6536             nan     0.0500 -17015635.9491
##   1000 12344926405.0192             nan     0.0500 -17563456.0110
##   1020 12164781928.2263             nan     0.0500 -15781056.4934
##   1040 11994220632.4536             nan     0.0500 -8383800.3755
##   1060 11840427702.9643             nan     0.0500 -6692534.1448
##   1080 11703372864.4749             nan     0.0500 -2994846.3616
##   1100 11561285503.3205             nan     0.0500 -7808024.6509
##   1120 11417520815.6514             nan     0.0500 611648.9030
##   1140 11306624241.5151             nan     0.0500 -11737442.6166
##   1160 11171801771.2895             nan     0.0500 -4948248.0979
##   1180 11010278670.5498             nan     0.0500 -9030616.4140
##   1200 10871434423.5037             nan     0.0500 -5262774.0571
##   1220 10752304757.4559             nan     0.0500 -7618889.6534
##   1240 10630271890.4356             nan     0.0500 -3183600.6658
##   1260 10502082668.8358             nan     0.0500 -5953141.4337
##   1280 10377948673.6559             nan     0.0500 -10557656.7863
##   1300 10246013966.0555             nan     0.0500 -4659066.1008
##   1320 10138113780.9637             nan     0.0500 -5473895.2136
##   1340 10017270823.5736             nan     0.0500 -2800484.9044
##   1360 9918685498.7592             nan     0.0500 -7137270.9046
##   1380 9789226685.1399             nan     0.0500 8225713.6175
##   1400 9688444734.6165             nan     0.0500 -8191426.4413
##   1420 9572154173.1695             nan     0.0500 -7111108.6452
##   1440 9469933821.1635             nan     0.0500 -11254726.7268
##   1460 9369619651.5303             nan     0.0500 -7346580.0357
##   1480 9266376417.5061             nan     0.0500 -5336763.0339
##   1500 9188765198.3835             nan     0.0500 -5382015.2187
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 256961028552.3868             nan     0.0500 13596315509.3445
##      2 242146740565.5752             nan     0.0500 16336372439.7014
##      3 227709060109.8990             nan     0.0500 13644655049.3976
##      4 214055499587.5862             nan     0.0500 13090602391.5037
##      5 201346627485.7445             nan     0.0500 12307528211.7569
##      6 190221147476.5506             nan     0.0500 11621879303.9520
##      7 180232286168.9012             nan     0.0500 9131752464.6458
##      8 169260312490.7976             nan     0.0500 8703402659.8409
##      9 160528851504.3266             nan     0.0500 9118202016.5918
##     10 153211698172.8436             nan     0.0500 6870080662.2512
##     20 98290736239.3418             nan     0.0500 3210893604.8377
##     40 58016466422.2620             nan     0.0500 632800180.0425
##     60 45098683624.3209             nan     0.0500 146903328.2896
##     80 39532729204.8481             nan     0.0500 100723943.9826
##    100 36459418099.1744             nan     0.0500 -51391789.1663
##    120 34229566558.2467             nan     0.0500 -134278792.3482
##    140 32518526566.8096             nan     0.0500 -59882878.7069
##    160 31102796050.5344             nan     0.0500 -62823660.9841
##    180 29951200732.9341             nan     0.0500 -68468926.5057
##    200 28800113310.9201             nan     0.0500 -2156269.3018
##    220 27853986364.2722             nan     0.0500 -53820668.4438
##    240 26938041750.4250             nan     0.0500 -38153491.6082
##    260 26045812573.7098             nan     0.0500 -21908168.1229
##    280 25177141670.6617             nan     0.0500 -49244398.7714
##    300 24457133894.2398             nan     0.0500 -72069190.0715
##    320 23802472083.3671             nan     0.0500 -57321951.5706
##    340 23148502555.4734             nan     0.0500 6508426.9148
##    360 22557044559.6212             nan     0.0500 -35903377.7200
##    380 21995980960.5757             nan     0.0500 -46361976.7515
##    400 21445749194.7578             nan     0.0500 -5954793.9083
##    420 20869669481.0330             nan     0.0500 -22689147.3483
##    440 20339903662.9383             nan     0.0500 -51463948.3910
##    460 19893782249.2852             nan     0.0500 -37098485.0279
##    480 19455314474.1958             nan     0.0500 -24864095.1708
##    500 19038567356.1932             nan     0.0500 -57005649.0130
##    520 18664158627.1321             nan     0.0500 -21894686.5828
##    540 18188747780.1245             nan     0.0500 -27691238.9925
##    560 17824332881.0343             nan     0.0500 -39152035.6873
##    580 17532993068.5588             nan     0.0500 -27146497.6014
##    600 17265270043.7083             nan     0.0500 -38980961.4920
##    620 16920592388.0907             nan     0.0500 -37137931.3007
##    640 16595896625.5806             nan     0.0500 -29218850.6083
##    660 16308643837.5684             nan     0.0500 -16291458.1193
##    680 16007916236.5441             nan     0.0500 -20336120.0757
##    700 15744063141.1721             nan     0.0500 -12046017.3234
##    720 15476107004.4255             nan     0.0500 -7596703.9764
##    740 15209222491.6077             nan     0.0500 -19875027.8745
##    760 14994813967.0010             nan     0.0500 -5291467.3949
##    780 14778526365.2925             nan     0.0500 -5615030.9089
##    800 14565901805.9698             nan     0.0500 -10377744.5734
##    820 14392727998.0688             nan     0.0500 2606440.9411
##    840 14166311436.4503             nan     0.0500 -16047755.2501
##    860 13903377056.3113             nan     0.0500 4375602.4282
##    880 13677124825.8941             nan     0.0500 -8897434.2833
##    900 13466383395.7153             nan     0.0500 -6252236.1763
##    920 13242011516.3404             nan     0.0500 -14519953.2942
##    940 13076256378.8012             nan     0.0500 -8531283.8778
##    960 12910012840.4628             nan     0.0500 -10899351.6371
##    980 12715329320.5089             nan     0.0500 -17836744.5377
##   1000 12571992960.1607             nan     0.0500 -10309378.5694
##   1020 12379021068.7641             nan     0.0500 -2009980.8462
##   1040 12233715331.7915             nan     0.0500 -9418733.2602
##   1060 12049029955.6078             nan     0.0500 -12289607.7055
##   1080 11876319509.5442             nan     0.0500 -7148485.4369
##   1100 11725409965.9565             nan     0.0500 -10905979.9926
##   1120 11587163627.5358             nan     0.0500 -10660475.9545
##   1140 11425035150.4955             nan     0.0500 763526.2310
##   1160 11264721128.3077             nan     0.0500 -1883134.8012
##   1180 11124187575.5818             nan     0.0500 -9537011.4258
##   1200 10966922198.5193             nan     0.0500 -9484901.1301
##   1220 10836082505.8130             nan     0.0500 -6919043.8489
##   1240 10708959700.2013             nan     0.0500 -743022.2542
##   1260 10567200974.6532             nan     0.0500 -7838450.0046
##   1280 10432916989.9528             nan     0.0500 -12642749.4292
##   1300 10310700740.1489             nan     0.0500 -6657609.9878
##   1320 10192349453.8540             nan     0.0500 -12658955.2008
##   1340 10071880122.8658             nan     0.0500 -13731830.9572
##   1360 9965913219.5583             nan     0.0500 3825181.7878
##   1380 9856685452.7405             nan     0.0500 603409.6377
##   1400 9746182794.3446             nan     0.0500 -5668004.8149
##   1420 9636813200.3789             nan     0.0500 -4012583.3083
##   1440 9545394402.4610             nan     0.0500 -6976281.7784
##   1460 9446452228.0202             nan     0.0500 -8573858.1662
##   1480 9341795997.7662             nan     0.0500 -7270132.3751
##   1500 9252761718.1349             nan     0.0500 -4157779.6242
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 256273172922.1127             nan     0.0500 16475993940.5618
##      2 240305076581.4894             nan     0.0500 14179391921.7267
##      3 225508286190.2109             nan     0.0500 13825070054.2698
##      4 212260687495.8755             nan     0.0500 11631125610.8081
##      5 199204591087.0238             nan     0.0500 10773922169.9477
##      6 187558171109.1367             nan     0.0500 10107129753.4585
##      7 177274191407.0065             nan     0.0500 10557791311.4995
##      8 166866406249.2773             nan     0.0500 10756396012.9423
##      9 158602927514.1418             nan     0.0500 7718907688.3376
##     10 150521710442.0020             nan     0.0500 8003752032.9885
##     20 97534507168.3902             nan     0.0500 3284238527.0179
##     40 58342597234.1578             nan     0.0500 920288147.0516
##     60 44816781472.4510             nan     0.0500 168496814.5089
##     80 39232782570.4869             nan     0.0500 -36574976.1233
##    100 36358126577.8185             nan     0.0500 65080894.1299
##    120 34488305582.7475             nan     0.0500 -39993817.8369
##    140 32823764105.5015             nan     0.0500 -79572543.4698
##    160 31380557614.1650             nan     0.0500 -39505101.6803
##    180 29903024364.6493             nan     0.0500 -14617622.8508
##    200 28756423883.1286             nan     0.0500 -26691370.9429
##    220 27624092407.2248             nan     0.0500 -74754370.1664
##    240 26648764229.0802             nan     0.0500 -39642775.0494
##    260 25885724708.5284             nan     0.0500 -33487504.0349
##    280 25182825060.7734             nan     0.0500 -23772745.3403
##    300 24563193694.0631             nan     0.0500 -50259830.8138
##    320 23951361552.1786             nan     0.0500 -72028102.7714
##    340 23332667919.7964             nan     0.0500 -48122244.4774
##    360 22760178699.1839             nan     0.0500 -15456707.6986
##    380 22168435675.6530             nan     0.0500 -26520089.7398
##    400 21564025550.7548             nan     0.0500 25571670.8474
##    420 21069527601.4791             nan     0.0500 -12776476.3768
##    440 20605350792.4676             nan     0.0500 -16192257.5518
##    460 20144818046.6543             nan     0.0500 -20844513.6268
##    480 19687271692.9390             nan     0.0500 -72295216.6777
##    500 19307707118.9132             nan     0.0500 -46861216.2410
##    520 18891817919.2596             nan     0.0500 1714567.9597
##    540 18524376263.6984             nan     0.0500 -41087083.7318
##    560 18109758295.9956             nan     0.0500 -10184732.6989
##    580 17785013062.5296             nan     0.0500 -25460090.9326
##    600 17482902518.3414             nan     0.0500 -30366128.4707
##    620 17157643259.6789             nan     0.0500 -26371112.9977
##    640 16872842494.7559             nan     0.0500 -18408341.9112
##    660 16538831936.5227             nan     0.0500 -20967998.9223
##    680 16250649090.4657             nan     0.0500 -6373194.3272
##    700 15965547957.3812             nan     0.0500 -12766871.0418
##    720 15695754583.7372             nan     0.0500 -19215794.0135
##    740 15432219380.3812             nan     0.0500 -16632824.1014
##    760 15169715708.1510             nan     0.0500 -19145496.8969
##    780 14944547840.7392             nan     0.0500 4892100.8099
##    800 14722578032.3923             nan     0.0500 -10474598.8448
##    820 14500095843.4936             nan     0.0500 -26633249.9670
##    840 14333919064.2247             nan     0.0500 -5854535.2540
##    860 14120945838.3005             nan     0.0500 -27309558.6069
##    880 13857549229.5940             nan     0.0500 6348403.2779
##    900 13663246309.8473             nan     0.0500 -8401382.9371
##    920 13469369170.9343             nan     0.0500 -12068111.2114
##    940 13246960563.4971             nan     0.0500 -9407034.2429
##    960 13093016917.3819             nan     0.0500 -8843450.0626
##    980 12920276770.8224             nan     0.0500 -1848802.6936
##   1000 12742442760.5994             nan     0.0500 -2383721.6992
##   1020 12581892757.3096             nan     0.0500 -6554784.3777
##   1040 12431445179.2181             nan     0.0500 -4840458.7708
##   1060 12259890396.9444             nan     0.0500 4398427.9296
##   1080 12116565749.5842             nan     0.0500 -4734322.7069
##   1100 11979595280.6954             nan     0.0500 -12220622.9264
##   1120 11860090642.8968             nan     0.0500 -6698014.0730
##   1140 11726185117.1190             nan     0.0500 -9888075.4965
##   1160 11576930973.1215             nan     0.0500 -10993185.4440
##   1180 11460232887.5132             nan     0.0500 -4340808.7436
##   1200 11345043143.8726             nan     0.0500 -1952055.3181
##   1220 11214904746.9705             nan     0.0500 1068088.9584
##   1240 11083897458.9971             nan     0.0500 706620.2969
##   1260 10962677739.8483             nan     0.0500 -7382916.3404
##   1280 10849606011.0306             nan     0.0500 -176935.7341
##   1300 10745377082.6016             nan     0.0500 1999158.8720
##   1320 10637541650.2774             nan     0.0500 -9323111.8382
##   1340 10535860768.1162             nan     0.0500 -4203902.1689
##   1360 10404903008.3344             nan     0.0500 1445044.8743
##   1380 10307696451.1562             nan     0.0500 -3496346.2977
##   1400 10204337420.8437             nan     0.0500 -13853587.3194
##   1420 10096866369.5880             nan     0.0500 5290040.0087
##   1440 9990284020.6638             nan     0.0500 -3732865.8372
##   1460 9901004852.9039             nan     0.0500 -9755343.6530
##   1480 9777775633.1540             nan     0.0500 -5688719.7052
##   1500 9663781438.7971             nan     0.0500 -4057078.3835</code></pre>
<pre class="r"><code>print(gbmFit1)</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 10499 samples
##    13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 9450, 9450, 9449, 9448, 9450, 9449, ... 
## Resampling results:
## 
##   RMSE    Rsquared  MAE  
##   210923  0.84      99060
## 
## Tuning parameter &#39;n.trees&#39; was held constant at a value of 1500
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.05
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10</code></pre>
<p>RMSE was used to select the optimal model using the smallest value.
The final values used for the model were n.trees = 1500, interaction.depth = 8, shrinkage = 0.05 and n.minobsinnode = 10.</p>
<pre class="r"><code>gbm_prediction &lt;- predict(gbmFit1, newdata = test_data)

gbm_results&lt;-data.frame(RMSE = RMSE(gbm_prediction, test_data$price), Rsquare = R2(gbm_prediction, test_data$price))

gbm_results</code></pre>
<p>Perfomance of the model (in R²):
- Training 0.8403008
- Testing 0.8472716 201039.8</p>
</div>
<div id="stacking" class="section level2">
<h2>Stacking</h2>
<p>Finally, I combine all the models that I trained and make a final prediction based on the predictions of the individual models. This method is an ensembled learning method called stacking and usually outperforms all the individual models.</p>
<pre class="r"><code>#number of folds in cross validation
CVfolds &lt;- 5

#Define folds
set.seed(1)
  #create five folds with no repeats
indexPreds &lt;- createMultiFolds(train_data$price, CVfolds,times = 1) 
#Define traincontrol using folds
ctrl &lt;- trainControl(method = &quot;cv&quot;,  number = CVfolds, returnResamp = &quot;final&quot;, savePredictions = &quot;final&quot;, index = indexPreds,sampling = NULL)

#LINEAR REGRESSION
model_lm&lt;-train(
    price ~ 
   num_tube_lines 
   +distance_to_station
   
    +district:property_type
    +london_zone*poly(total_floor_area,2)*number_habitable_rooms 
   
   +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
    
    ,
    train_data,
   method = &quot;lm&quot;,
    trControl = ctrl
   )

# LASSO
lasso_fit &lt;- train(price ~

   num_tube_lines 
   +distance_to_station
   
    +district:property_type
    +london_zone*poly(total_floor_area,2)*number_habitable_rooms 

   +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company,
    
        data=train_data,
        method=&quot;glmnet&quot;,
        preProc = c(&quot;center&quot;, &quot;scale&quot;), #This option standardizes the data before running the LASSO regression if alpha = 0 -&gt;RIDGE REG
  
   trControl = ctrl,
  tuneGrid = expand.grid(alpha = 1, lambda = 40.40404) #insert the optimized
)

# TREE
model_tree_2 &lt;- train(
  price ~ 
    
   num_tube_lines 
    
    +latitude
    +longitude
    
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,
 
  method = &quot;rpart&quot;,
  metric=&quot;RMSE&quot;,
  trControl = ctrl,  
  tuneGrid= expand.grid(cp=0.00002)
    )

#KNN

knn_fit_2 &lt;- train(  
  price ~ 
    
   num_tube_lines 
    
    +latitude
    +longitude

    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    +average_income
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company
  ,
  train_data,

    method = &quot;knn&quot;, 
     trControl = ctrl,
     tuneGrid = expand.grid(k=6), #looking for numbers around 
     preProcess = c(&quot;center&quot;, &quot;scale&quot;), #center and scale the data in k-nn this is pretty important
     metric=&quot;RMSE&quot;) #default metric is accuracy is binary, otherwise RMSE, I change it to R²


# Random Forest
rf_fit_2 &lt;- train(price~
  
   distance_to_station
   +latitude
   +longitude
    
 
   +freehold_or_leasehold
  
   +district
   +property_type
   +london_zone
   +total_floor_area
   +number_habitable_rooms 
   
   +energy_consumption_potential 
   +windows_energy_eff
   +co2_emissions_potential
   +water_company,
  
    train_data, 
                                  
    method = &quot;ranger&quot;,
    metric=&quot;RMSE&quot;, 
    trControl = ctrl, 
    tuneGrid = data.frame(.mtry = 27, .splitrule=&quot;variance&quot;, .min.node.size = 5),
    importance = &#39;permutation&#39;)


# Gradient
grid&lt;-expand.grid(interaction.depth = 8, #seq(6, 10, by = 2), #2. interaction.depth (Maximum nodes per tree) - number of splits it has to perform on a tree (starting from a single node).
                  n.trees = 1500,##Number of trees (the number of gradient boosting iteration) i.e. N. Increasing N reduces the error on training set, but setting it too high may lead to over-fitting.
                  shrinkage =0.05, #It is considered as a learning rate, use a small shrinkage (slow learn rate) when growing many trees. 
                  n.minobsinnode = 10)#the minimum number of observations in trees&#39; terminal nodes. 

gbmFit1 &lt;- train(price~
    
    distance_to_station 
    +latitude
    +longitude
    
    +freehold_or_leasehold
  
    +district
    +property_type
    +london_zone
    +total_floor_area
    +number_habitable_rooms 
    
    +energy_consumption_potential 
    +windows_energy_eff
    +co2_emissions_potential
    +water_company,
  
     train_data,
                 
                 method = &quot;gbm&quot;, 
                 trControl = ctrl,
                 tuneGrid =grid,
                   metric = &quot;RMSE&quot;
                 )</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 247437688705.4287             nan     0.0500 16801252301.2286
##      2 232000278268.7830             nan     0.0500 15690971801.8620
##      3 218828715591.3823             nan     0.0500 14106227202.8752
##      4 205149091076.5482             nan     0.0500 12788910307.6939
##      5 193468845035.5358             nan     0.0500 9757749739.6899
##      6 183062089130.4374             nan     0.0500 10848202067.8948
##      7 172291539975.4364             nan     0.0500 9470000832.9087
##      8 163214068742.9066             nan     0.0500 7615975344.3065
##      9 154737960754.7700             nan     0.0500 7875555203.9193
##     10 147833823108.9143             nan     0.0500 7109522111.4091
##     20 95624937375.2434             nan     0.0500 2488688721.7182
##     40 58092570913.3721             nan     0.0500 950912601.8645
##     60 45720667173.3667             nan     0.0500 216688799.9767
##     80 40422896772.1081             nan     0.0500 137066553.2981
##    100 37088400609.1000             nan     0.0500 -80460469.0406
##    120 34632966244.9075             nan     0.0500 -120556986.8314
##    140 32705038931.6038             nan     0.0500 -82286260.6530
##    160 31108822663.6984             nan     0.0500 -50359260.6044
##    180 29804648110.2538             nan     0.0500 -45773553.0638
##    200 28475772744.5148             nan     0.0500 -61852314.9401
##    220 27377462100.7449             nan     0.0500 -47809341.3956
##    240 26490908447.8670             nan     0.0500 -128925155.8264
##    260 25556126149.4352             nan     0.0500 -19549531.7794
##    280 24635458756.1371             nan     0.0500 -78076118.9399
##    300 23948105351.6986             nan     0.0500 -38316972.5993
##    320 23272549122.9257             nan     0.0500 -33706969.5887
##    340 22490097524.4572             nan     0.0500 -59175625.4364
##    360 21913320289.2327             nan     0.0500 -81212438.8221
##    380 21274755158.0386             nan     0.0500 -36026982.3494
##    400 20599748547.6230             nan     0.0500 -14355642.3414
##    420 20068631707.7723             nan     0.0500 -12469755.2147
##    440 19542858228.6832             nan     0.0500 -11172592.0571
##    460 18957357908.1856             nan     0.0500 -30209488.4526
##    480 18520113900.8436             nan     0.0500 -44097434.8410
##    500 18106351966.9998             nan     0.0500 -2689730.3581
##    520 17729385466.6864             nan     0.0500 -23576089.0579
##    540 17364459474.5803             nan     0.0500 -23042515.0439
##    560 16993376893.4093             nan     0.0500 -26829867.2448
##    580 16637945433.6468             nan     0.0500 -5031381.5125
##    600 16241509125.1088             nan     0.0500 -28517106.0280
##    620 15949782148.7863             nan     0.0500 -19627916.7605
##    640 15644076619.6955             nan     0.0500 -19562244.3131
##    660 15367835705.5778             nan     0.0500 -32529324.8970
##    680 15121015306.8522             nan     0.0500 -6995581.9433
##    700 14829581815.4196             nan     0.0500 12299534.4644
##    720 14584374758.2405             nan     0.0500 -18207259.6416
##    740 14361383025.5789             nan     0.0500 -10153063.1291
##    760 14113383270.6949             nan     0.0500 -2342932.3574
##    780 13859412434.8414             nan     0.0500 -21503185.5878
##    800 13608157151.5257             nan     0.0500 -17122922.7747
##    820 13405498629.3242             nan     0.0500 -11937472.9078
##    840 13194032278.9143             nan     0.0500 -29046910.0443
##    860 12991025036.5170             nan     0.0500 -12257807.3376
##    880 12772064407.5574             nan     0.0500 -4436759.1798
##    900 12605245762.4946             nan     0.0500 -2316528.2865
##    920 12436950735.2306             nan     0.0500 -5876477.6883
##    940 12248571760.3645             nan     0.0500 -4719345.9821
##    960 12071145325.9307             nan     0.0500 -8056584.7381
##    980 11872934646.7866             nan     0.0500 -12635342.6009
##   1000 11691570997.7380             nan     0.0500 -12517932.8066
##   1020 11533281478.7139             nan     0.0500 -11155896.7995
##   1040 11358480874.8904             nan     0.0500 -7089073.4319
##   1060 11233333550.3298             nan     0.0500 -9573067.8657
##   1080 11087773656.8590             nan     0.0500 -11676314.5897
##   1100 10939282478.3953             nan     0.0500 -10325639.8591
##   1120 10806951942.8404             nan     0.0500 -10566758.2213
##   1140 10673602322.8670             nan     0.0500 -8394480.4835
##   1160 10532386780.4276             nan     0.0500 -12659095.1066
##   1180 10388414557.8044             nan     0.0500 5537969.6325
##   1200 10267046954.5759             nan     0.0500 -5298494.5268
##   1220 10138555309.0737             nan     0.0500 -1417217.0564
##   1240 10007393587.1272             nan     0.0500 -7221218.4085
##   1260 9884409148.0953             nan     0.0500 -3893119.3180
##   1280 9766316088.5224             nan     0.0500 -6982833.8691
##   1300 9641018051.4913             nan     0.0500 -6058292.3689
##   1320 9525771025.4948             nan     0.0500 -13425171.2655
##   1340 9428161845.2522             nan     0.0500 -12974105.7873
##   1360 9310307904.4361             nan     0.0500 -4800012.5692
##   1380 9197895335.2128             nan     0.0500 -5212347.4768
##   1400 9095293289.4673             nan     0.0500 -11650171.7175
##   1420 8985995031.2347             nan     0.0500 2916449.3046
##   1440 8885559645.2912             nan     0.0500 -7129216.5155
##   1460 8790457619.8345             nan     0.0500 -9212977.3824
##   1480 8696663815.7667             nan     0.0500 -6896679.9748
##   1500 8597522170.1863             nan     0.0500 -6298537.6785
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 251203392392.6218             nan     0.0500 19344882605.9957
##      2 234529263549.3858             nan     0.0500 17483443616.1385
##      3 220173872432.6830             nan     0.0500 14467723251.8060
##      4 206328159598.5661             nan     0.0500 11265029035.4564
##      5 194161485143.1612             nan     0.0500 10743208848.0867
##      6 183708627434.2637             nan     0.0500 10668275198.3186
##      7 173237403545.4839             nan     0.0500 10336632424.6296
##      8 164298076597.5103             nan     0.0500 7780511081.7556
##      9 155792614724.3971             nan     0.0500 7173932923.2228
##     10 148457780399.1842             nan     0.0500 6910057664.0994
##     20 97763732035.2382             nan     0.0500 2875515430.3423
##     40 58900773855.1187             nan     0.0500 918231443.3753
##     60 46183142670.6044             nan     0.0500 253414611.3341
##     80 40201278078.0805             nan     0.0500 69071359.8496
##    100 36699451908.0091             nan     0.0500 -4516673.3067
##    120 34302018774.7417             nan     0.0500 -9793333.4514
##    140 32239454530.4458             nan     0.0500 -35196531.9144
##    160 30903961176.0136             nan     0.0500 -107953654.9803
##    180 29609868801.4378             nan     0.0500 11564621.6200
##    200 28272624249.7456             nan     0.0500 42234699.3563
##    220 27215128104.3425             nan     0.0500 -38628780.3761
##    240 26227552075.7280             nan     0.0500 -36024153.9477
##    260 25382314915.9630             nan     0.0500 5581784.5762
##    280 24558449616.3890             nan     0.0500 -17399545.5599
##    300 23800143557.5414             nan     0.0500 -28672447.0224
##    320 23228259880.5985             nan     0.0500 -17536645.3697
##    340 22611033158.6527             nan     0.0500 -39774918.4282
##    360 22140754789.0262             nan     0.0500 -29909985.4045
##    380 21539089965.2597             nan     0.0500 -56837071.4607
##    400 21006010445.1879             nan     0.0500 -19866737.5342
##    420 20570501692.2485             nan     0.0500 -29590002.3431
##    440 20127696884.5072             nan     0.0500 -45831246.8909
##    460 19655207296.3137             nan     0.0500 -20441181.9312
##    480 19241343967.6648             nan     0.0500 -26365636.8724
##    500 18832311092.0197             nan     0.0500 -45451824.1377
##    520 18316443033.3673             nan     0.0500 -60991947.8298
##    540 17919126655.5172             nan     0.0500 -14575932.5523
##    560 17578663913.5246             nan     0.0500 -22899199.9812
##    580 17232961523.5101             nan     0.0500 -30097122.0064
##    600 16889764649.2289             nan     0.0500 -12629884.3628
##    620 16578600806.3272             nan     0.0500 -13320013.4055
##    640 16304986461.5123             nan     0.0500 -6501267.9757
##    660 16005890114.1592             nan     0.0500 -18230020.6700
##    680 15686469037.5680             nan     0.0500 -46999612.9232
##    700 15403856111.9631             nan     0.0500 -27166298.6348
##    720 15127514481.1521             nan     0.0500 -24820471.2971
##    740 14852155115.9459             nan     0.0500 -16084368.7082
##    760 14568011376.2146             nan     0.0500 -19219897.0704
##    780 14294724529.1704             nan     0.0500 9065125.2962
##    800 14023171519.7364             nan     0.0500 -26434488.8656
##    820 13819591704.6066             nan     0.0500 -18162991.4190
##    840 13591781834.2017             nan     0.0500 -20190265.1968
##    860 13382386123.3599             nan     0.0500 -4419774.3000
##    880 13175049039.0262             nan     0.0500 -18230969.3747
##    900 12981550883.2149             nan     0.0500 -16212708.1816
##    920 12774177215.8483             nan     0.0500 -12548070.3101
##    940 12584930645.3376             nan     0.0500 -8206728.6178
##    960 12406856216.8821             nan     0.0500 -17873884.2780
##    980 12208764478.9520             nan     0.0500 4002501.3718
##   1000 12041402422.3606             nan     0.0500 -15007376.5228
##   1020 11888619859.1288             nan     0.0500 -10304794.2639
##   1040 11729419641.1294             nan     0.0500 -7997410.8868
##   1060 11552969034.2644             nan     0.0500 -1060328.2748
##   1080 11398003761.4592             nan     0.0500 -16261175.9755
##   1100 11243669602.3688             nan     0.0500 -654272.8387
##   1120 11107895547.1591             nan     0.0500 -14972216.5820
##   1140 10992705728.9962             nan     0.0500 -3329225.7788
##   1160 10850873737.8402             nan     0.0500 -17387176.9088
##   1180 10719762185.4472             nan     0.0500 -18864670.8849
##   1200 10581010520.8986             nan     0.0500 -3139779.3311
##   1220 10436798609.9160             nan     0.0500 -18672376.0004
##   1240 10322270295.5927             nan     0.0500 -14248382.3870
##   1260 10188391548.8068             nan     0.0500 4382505.7696
##   1280 10052155777.3462             nan     0.0500 -1733655.9220
##   1300 9938786238.2663             nan     0.0500 3050129.0254
##   1320 9822575226.6972             nan     0.0500 -11962581.4963
##   1340 9711724050.8268             nan     0.0500 -11770566.6723
##   1360 9587038187.6770             nan     0.0500 -822333.6319
##   1380 9488740978.3182             nan     0.0500 -6620612.3834
##   1400 9383516481.3260             nan     0.0500 -9789046.0878
##   1420 9267603771.8339             nan     0.0500 -340856.8886
##   1440 9166119635.1323             nan     0.0500 -11159009.6714
##   1460 9067276906.2260             nan     0.0500 -79573.5737
##   1480 8969042475.5866             nan     0.0500 -4810129.8591
##   1500 8876747816.7409             nan     0.0500 1258214.5088
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 257832453782.5124             nan     0.0500 19602069228.8723
##      2 241082847214.0711             nan     0.0500 18014915801.4955
##      3 226147129184.6718             nan     0.0500 15610551148.6476
##      4 212483943930.3416             nan     0.0500 14120372400.8190
##      5 200290053366.6906             nan     0.0500 12807336022.7842
##      6 188683691101.6127             nan     0.0500 9697859385.7568
##      7 177055708949.3166             nan     0.0500 11286524552.0228
##      8 167361969167.4400             nan     0.0500 9084676439.0758
##      9 158245404946.2050             nan     0.0500 8411053317.3486
##     10 149852517903.2663             nan     0.0500 7286703276.9721
##     20 95932971388.8225             nan     0.0500 3872198582.6725
##     40 57469358375.5171             nan     0.0500 859251216.6947
##     60 44132083337.5622             nan     0.0500 -45260808.1626
##     80 38734596859.0976             nan     0.0500 42685945.9327
##    100 35783232325.8149             nan     0.0500 -59407880.7167
##    120 33534472681.1316             nan     0.0500 -90182502.5801
##    140 31670865299.9807             nan     0.0500 30693393.0432
##    160 30399762830.5174             nan     0.0500 -75498694.2365
##    180 29053507112.1285             nan     0.0500 -32876814.1289
##    200 27660526988.9776             nan     0.0500 -59604574.9750
##    220 26661881812.8947             nan     0.0500 -44880190.4880
##    240 25805513127.7589             nan     0.0500 -34775555.9173
##    260 24951058150.6592             nan     0.0500 -38280813.8107
##    280 24265190184.7988             nan     0.0500 -89865069.2265
##    300 23514899191.8895             nan     0.0500 -55939094.2960
##    320 22846529489.5833             nan     0.0500 -21678901.5008
##    340 22241722931.6147             nan     0.0500 -72639543.4436
##    360 21669254450.4368             nan     0.0500 -50194359.9988
##    380 21071626810.0067             nan     0.0500 -68234595.7483
##    400 20669073172.2180             nan     0.0500 742271.2956
##    420 20198969016.0675             nan     0.0500 -30482270.8289
##    440 19701711111.2000             nan     0.0500 -13790515.0276
##    460 19277684929.6747             nan     0.0500 -17597674.2445
##    480 18851986432.5235             nan     0.0500 -30658769.2931
##    500 18419872309.0325             nan     0.0500 -12709707.5661
##    520 18034503236.8089             nan     0.0500 -2652920.0498
##    540 17669477555.0583             nan     0.0500 -18499678.1658
##    560 17323280148.1029             nan     0.0500 -6389876.5418
##    580 17002830888.6033             nan     0.0500 -11224128.3790
##    600 16687777520.3583             nan     0.0500 -27055275.9887
##    620 16385256636.7353             nan     0.0500 -4810463.7090
##    640 16071995743.3280             nan     0.0500 -17698091.0570
##    660 15807069050.6145             nan     0.0500 -14777260.5033
##    680 15507406014.9158             nan     0.0500 -31272771.7744
##    700 15218299674.2426             nan     0.0500 -20817229.4336
##    720 14972368172.4079             nan     0.0500 -36049140.5975
##    740 14734570617.9544             nan     0.0500 -20105028.3027
##    760 14460319326.3111             nan     0.0500 -6387907.1781
##    780 14211407588.8203             nan     0.0500 3711776.9274
##    800 13961047159.7350             nan     0.0500 -24287686.6757
##    820 13744819908.1639             nan     0.0500 3170680.0159
##    840 13477364031.8947             nan     0.0500 -28227326.6305
##    860 13263240331.5939             nan     0.0500 -15065353.7046
##    880 13082541088.3425             nan     0.0500 -16028019.4990
##    900 12902809225.5303             nan     0.0500 -23779974.8605
##    920 12724318288.2856             nan     0.0500 -3147657.2575
##    940 12539307152.1351             nan     0.0500 -3654384.6394
##    960 12335050319.1319             nan     0.0500 -14443040.5316
##    980 12168639840.8320             nan     0.0500 -14977260.9678
##   1000 11996209100.4582             nan     0.0500 -18693892.2972
##   1020 11855901659.7468             nan     0.0500 -8798645.8295
##   1040 11699581425.6238             nan     0.0500 -15970362.9078
##   1060 11539082468.2978             nan     0.0500 2981656.5609
##   1080 11394951775.2452             nan     0.0500 -13174392.2152
##   1100 11235164367.1390             nan     0.0500 -5736375.9502
##   1120 11106895481.5597             nan     0.0500 -10727736.8546
##   1140 10942314463.4981             nan     0.0500 -12364184.2845
##   1160 10803770740.9620             nan     0.0500 -4580430.6311
##   1180 10679405648.8745             nan     0.0500 3395139.3460
##   1200 10570311415.0426             nan     0.0500 -19403432.6361
##   1220 10442359059.4609             nan     0.0500 -4806954.1705
##   1240 10291586634.7517             nan     0.0500 -3595122.0516
##   1260 10160402194.9309             nan     0.0500 806074.6402
##   1280 10035462951.9658             nan     0.0500 -3462910.6448
##   1300 9902785388.8658             nan     0.0500 8891951.5147
##   1320 9783589863.5066             nan     0.0500 -8452873.1774
##   1340 9657263218.3910             nan     0.0500 -6885831.0535
##   1360 9547039887.5819             nan     0.0500 -9991172.5045
##   1380 9431280498.4185             nan     0.0500 -6288002.1895
##   1400 9322022219.2580             nan     0.0500 -9258141.5213
##   1420 9223275930.6152             nan     0.0500 -8740198.1921
##   1440 9120383844.6298             nan     0.0500 -11226898.1740
##   1460 9009490297.2610             nan     0.0500 -1332762.9914
##   1480 8915281768.0753             nan     0.0500 2071345.6554
##   1500 8822700901.2461             nan     0.0500 -8519650.6575
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258768875615.4841             nan     0.0500 20788264223.2576
##      2 242298274267.3581             nan     0.0500 16189472667.0661
##      3 227263309703.9819             nan     0.0500 15607427543.3734
##      4 213562699686.1152             nan     0.0500 12810910203.6035
##      5 200583642217.8555             nan     0.0500 12715454695.3170
##      6 188612312716.7159             nan     0.0500 9291512107.7753
##      7 177815681232.6924             nan     0.0500 8854729872.0179
##      8 168707280715.0586             nan     0.0500 9448714372.1164
##      9 160327643564.3338             nan     0.0500 9304522755.6371
##     10 152052729079.2238             nan     0.0500 7285335039.3477
##     20 99277880132.5523             nan     0.0500 3525041391.9227
##     40 59075420404.3493             nan     0.0500 758098076.2381
##     60 45905132944.3801             nan     0.0500 150864832.3737
##     80 40277765243.4037             nan     0.0500 27085350.5500
##    100 37252416978.5639             nan     0.0500 -29250723.9635
##    120 34915631799.6153             nan     0.0500 -80017300.3011
##    140 32887470759.3464             nan     0.0500 -74906855.3093
##    160 31401257065.3274             nan     0.0500 -27781236.9718
##    180 30008414301.3661             nan     0.0500 -54407669.8603
##    200 28995391616.5640             nan     0.0500 -38983037.9838
##    220 27992351945.6012             nan     0.0500 -54059565.1321
##    240 27094069813.1610             nan     0.0500 -25595973.8679
##    260 26056645515.6979             nan     0.0500 -39778018.3336
##    280 25106734311.1263             nan     0.0500 -8148969.1881
##    300 24401721846.3725             nan     0.0500 -31716119.1427
##    320 23592250736.3010             nan     0.0500 -24536548.2942
##    340 22819019757.0565             nan     0.0500 21452978.2207
##    360 22235140028.0625             nan     0.0500 -42580206.8320
##    380 21650235391.2817             nan     0.0500 -23121481.4526
##    400 21147917667.8512             nan     0.0500 -40850834.1961
##    420 20649394224.4801             nan     0.0500 -55632730.6568
##    440 20164827285.9685             nan     0.0500 -34340111.6986
##    460 19708008366.1965             nan     0.0500 -26904900.6645
##    480 19163493100.6559             nan     0.0500 11462885.8101
##    500 18762139710.6187             nan     0.0500 -27961580.6964
##    520 18248676146.9786             nan     0.0500 -36589403.1521
##    540 17865487362.6215             nan     0.0500 -5754457.7977
##    560 17442198203.4223             nan     0.0500 -17487433.4555
##    580 17092016004.5553             nan     0.0500 -31181480.5679
##    600 16778577401.1917             nan     0.0500 -26402570.4252
##    620 16418756018.0820             nan     0.0500 -2622766.7861
##    640 16155299955.4977             nan     0.0500 -28190448.2910
##    660 15852122475.1059             nan     0.0500 -16868453.1137
##    680 15575640034.9584             nan     0.0500 -15345975.5106
##    700 15324115238.3178             nan     0.0500 -12851562.0436
##    720 15110786147.6783             nan     0.0500 -17310284.7596
##    740 14853194945.5165             nan     0.0500 -7848858.8144
##    760 14614309703.2426             nan     0.0500 -17807954.1999
##    780 14369559183.0986             nan     0.0500 -12510305.6648
##    800 14092528357.5526             nan     0.0500 -6374997.2305
##    820 13873968825.9696             nan     0.0500 -11252037.1803
##    840 13682949620.5290             nan     0.0500 345197.7131
##    860 13463736144.5008             nan     0.0500 -11103568.2348
##    880 13277150862.4057             nan     0.0500 -20943408.6402
##    900 13041187565.4077             nan     0.0500 3852015.0117
##    920 12839575609.2895             nan     0.0500 -11925749.6978
##    940 12629135530.9884             nan     0.0500 -12482762.9303
##    960 12445795992.2094             nan     0.0500 -9646217.7820
##    980 12260808708.5173             nan     0.0500 -15758908.5782
##   1000 12083464020.0268             nan     0.0500 -9510428.8467
##   1020 11895993728.2972             nan     0.0500 -3224239.8537
##   1040 11736551883.0273             nan     0.0500 -8985759.7424
##   1060 11560260419.9724             nan     0.0500 -17368129.0168
##   1080 11395890559.5762             nan     0.0500 -11636344.5716
##   1100 11231462960.8721             nan     0.0500 -9201865.8273
##   1120 11095110727.1141             nan     0.0500 4321402.4205
##   1140 10956612229.8037             nan     0.0500 -16920348.8914
##   1160 10817810555.9859             nan     0.0500 -8250178.0734
##   1180 10686306953.7374             nan     0.0500 -16032329.7398
##   1200 10548078737.6017             nan     0.0500 -1641263.5025
##   1220 10416379858.2776             nan     0.0500 -10226178.8852
##   1240 10296831939.4207             nan     0.0500 -7050287.6795
##   1260 10182730595.6681             nan     0.0500 -5787638.6946
##   1280 10055694115.5930             nan     0.0500 -5402335.5294
##   1300 9930160381.4398             nan     0.0500 -11579779.3864
##   1320 9807854130.5481             nan     0.0500 -8008083.5546
##   1340 9717342106.8317             nan     0.0500 -14565342.7346
##   1360 9611239891.0548             nan     0.0500 1316366.7541
##   1380 9500817498.2141             nan     0.0500 -1069072.8462
##   1400 9415000376.5840             nan     0.0500 -1209869.0486
##   1420 9314737734.9074             nan     0.0500 -5298688.6195
##   1440 9220758829.8052             nan     0.0500 -11794477.6778
##   1460 9123231821.6435             nan     0.0500 -8354817.5872
##   1480 9024711307.9251             nan     0.0500 -19240373.8671
##   1500 8920470232.8748             nan     0.0500 -6467160.5776
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 258909339918.8690             nan     0.0500 18844999337.4506
##      2 243891483172.0254             nan     0.0500 15078073696.5793
##      3 229591388437.0222             nan     0.0500 12956388217.6491
##      4 215024474771.6006             nan     0.0500 15502393800.4451
##      5 202976870668.8875             nan     0.0500 13618598007.9925
##      6 192131546117.8822             nan     0.0500 10726006952.1989
##      7 181814208454.6968             nan     0.0500 10066577822.1216
##      8 172262606644.6008             nan     0.0500 9347443783.6331
##      9 163401508866.7413             nan     0.0500 9269358684.6585
##     10 154624664126.8134             nan     0.0500 8049065044.0284
##     20 100380384229.5783             nan     0.0500 3535429361.4723
##     40 58787923181.1791             nan     0.0500 633834165.9540
##     60 45226458906.7937             nan     0.0500 293888167.3495
##     80 39951415652.9891             nan     0.0500 -22940656.4192
##    100 36855600725.6866             nan     0.0500 -196595541.1954
##    120 34258667364.7127             nan     0.0500 -92221266.9923
##    140 32210515254.2621             nan     0.0500 -16944888.6598
##    160 30568807494.8040             nan     0.0500 -82288389.1737
##    180 29064076672.0278             nan     0.0500 -96274393.4498
##    200 27792900937.6425             nan     0.0500 -49455106.5358
##    220 26588756829.0611             nan     0.0500 -57142617.5414
##    240 25519894899.6631             nan     0.0500 -95028649.7053
##    260 24494794405.7692             nan     0.0500 -56032097.4869
##    280 23732351364.7546             nan     0.0500 -59850140.7348
##    300 23042201593.4881             nan     0.0500 -28454664.9745
##    320 22328019599.3422             nan     0.0500 -55136947.5459
##    340 21581907236.1899             nan     0.0500 -25208196.8429
##    360 20939722023.3211             nan     0.0500 -22806351.2030
##    380 20348132864.2421             nan     0.0500 -25897418.2975
##    400 19867626719.8213             nan     0.0500 -51518384.1216
##    420 19339397599.9123             nan     0.0500 1981498.5579
##    440 18893382630.2561             nan     0.0500 -30185496.9763
##    460 18454067362.9378             nan     0.0500 1701148.0979
##    480 18052457201.8958             nan     0.0500 -18003665.3678
##    500 17618309814.1054             nan     0.0500 -32596938.6268
##    520 17225763925.7692             nan     0.0500 -12783373.4203
##    540 16872406732.2674             nan     0.0500 -34156346.3204
##    560 16567314977.6310             nan     0.0500 -13774437.4431
##    580 16234993611.0253             nan     0.0500 -5251047.4825
##    600 15895991653.8401             nan     0.0500 -28171362.0151
##    620 15576906468.9031             nan     0.0500 -6249888.8830
##    640 15284718113.8470             nan     0.0500 -19379694.2935
##    660 14972057047.7235             nan     0.0500 -1297524.0640
##    680 14717157974.3155             nan     0.0500 -12022341.8302
##    700 14442294239.9017             nan     0.0500 -16836561.6537
##    720 14200901942.8578             nan     0.0500 -15692619.5557
##    740 13931803657.5258             nan     0.0500 -8677562.6867
##    760 13677331957.0521             nan     0.0500 -2594177.5133
##    780 13462495016.4761             nan     0.0500 -9975521.7596
##    800 13247003867.6707             nan     0.0500 -5867438.0628
##    820 13025909794.3190             nan     0.0500 3209899.8004
##    840 12830231174.3768             nan     0.0500 -2641002.0109
##    860 12633627472.2446             nan     0.0500 -4280496.4233
##    880 12471302227.5607             nan     0.0500 -7976938.1678
##    900 12275922232.6236             nan     0.0500 -115036.5489
##    920 12093343104.6787             nan     0.0500 -15011981.1700
##    940 11936987780.9866             nan     0.0500 -6111448.2191
##    960 11787014782.8474             nan     0.0500 -11467468.5610
##    980 11638467041.1413             nan     0.0500 -6987665.9372
##   1000 11475426528.5388             nan     0.0500 -17822682.1647
##   1020 11325521744.5253             nan     0.0500 -13978043.4160
##   1040 11162272668.8892             nan     0.0500 -2627996.8707
##   1060 10978886950.4393             nan     0.0500 -14897115.6624
##   1080 10820635107.8792             nan     0.0500 -4220121.8955
##   1100 10688247211.5504             nan     0.0500 -10470243.2729
##   1120 10555227235.7617             nan     0.0500 -3808133.0762
##   1140 10433006669.8847             nan     0.0500 -8005977.1351
##   1160 10321301887.8452             nan     0.0500 -13349388.6427
##   1180 10183031244.9192             nan     0.0500 -7734792.7876
##   1200 10071892216.8314             nan     0.0500 -9085863.0799
##   1220 9941231028.1395             nan     0.0500 -2587628.1854
##   1240 9829051266.5810             nan     0.0500 -6591424.2098
##   1260 9701752922.7926             nan     0.0500 -1366447.6359
##   1280 9590841384.2869             nan     0.0500 -2543759.8275
##   1300 9479209751.0747             nan     0.0500 -15792012.2073
##   1320 9359235283.2509             nan     0.0500 -33807.9187
##   1340 9246705188.1748             nan     0.0500 -3802791.4265
##   1360 9143149175.8891             nan     0.0500 -7896967.3225
##   1380 9037994879.4216             nan     0.0500 -3053550.2541
##   1400 8947764588.8148             nan     0.0500 -7862819.1870
##   1420 8849245916.7855             nan     0.0500 -2314903.7042
##   1440 8767298474.2565             nan     0.0500 -9934904.6934
##   1460 8658106336.2579             nan     0.0500 -3818158.6872
##   1480 8559464725.5251             nan     0.0500 -10247861.3962
##   1500 8462116142.4200             nan     0.0500 -177752.6975
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1 254061589297.6797             nan     0.0500 16707467520.3205
##      2 237727876492.4179             nan     0.0500 16341916930.8013
##      3 223250792049.8754             nan     0.0500 13949844036.1071
##      4 210597930293.1893             nan     0.0500 12996577532.9726
##      5 198652192665.2593             nan     0.0500 11806650447.0869
##      6 186625546581.9215             nan     0.0500 10778725861.8742
##      7 176893152834.0851             nan     0.0500 8918958067.7665
##      8 166297679018.5577             nan     0.0500 9835802406.7236
##      9 157571619326.7144             nan     0.0500 8218010207.1319
##     10 149997070285.4969             nan     0.0500 7561139285.5028
##     20 96711863945.0235             nan     0.0500 3336591495.7178
##     40 57134800820.1563             nan     0.0500 921554483.9302
##     60 44518284490.6246             nan     0.0500 232751469.6994
##     80 38984317768.0901             nan     0.0500 64681869.7492
##    100 36037628840.8775             nan     0.0500 -15603862.1741
##    120 33893332248.7045             nan     0.0500 36574013.0376
##    140 32322552413.1837             nan     0.0500 14276389.9365
##    160 30939286279.4923             nan     0.0500 -33730113.9104
##    180 29775392412.7720             nan     0.0500 -97194805.1931
##    200 28663486991.3102             nan     0.0500 -3540365.6663
##    220 27700360966.8449             nan     0.0500 8748848.2965
##    240 26736155783.5938             nan     0.0500 -41201853.5041
##    260 25989916027.8502             nan     0.0500 -57744328.4367
##    280 25287119178.2563             nan     0.0500 -44412715.6066
##    300 24470943385.5846             nan     0.0500 -49963342.7560
##    320 23799857488.8041             nan     0.0500 -19067004.7585
##    340 23183169638.7120             nan     0.0500 -20477871.5461
##    360 22683072900.0236             nan     0.0500 -42506709.1344
##    380 22125128108.6084             nan     0.0500 -51340005.9311
##    400 21623948384.1186             nan     0.0500 -35473910.2428
##    420 21157446857.0273             nan     0.0500 -22753420.2709
##    440 20583118511.9698             nan     0.0500 -26880528.0392
##    460 20176683737.8660             nan     0.0500 -39577606.3761
##    480 19781244585.3747             nan     0.0500 -25837473.8527
##    500 19408666881.4744             nan     0.0500 -13570609.1997
##    520 19053558919.2727             nan     0.0500 -23920631.0353
##    540 18702947212.8924             nan     0.0500 -29762458.1933
##    560 18361135336.6851             nan     0.0500 -10106440.8142
##    580 18057533510.3451             nan     0.0500 -11185155.3344
##    600 17697920464.6967             nan     0.0500 -23962152.0447
##    620 17384044560.3564             nan     0.0500 -1980860.3223
##    640 17092813323.3172             nan     0.0500 3451863.4620
##    660 16826451520.8222             nan     0.0500 -12484111.8287
##    680 16526345530.6201             nan     0.0500 -12800386.9243
##    700 16273595849.4316             nan     0.0500 -15184608.6109
##    720 15999756545.5648             nan     0.0500 -2329555.7880
##    740 15700752700.1574             nan     0.0500 -13109842.7084
##    760 15442364264.2017             nan     0.0500 -21702209.2440
##    780 15152009205.9528             nan     0.0500 6648059.8984
##    800 14935381902.6730             nan     0.0500 -15800294.5268
##    820 14724355671.9934             nan     0.0500 -25300481.7705
##    840 14497642202.0234             nan     0.0500 -7246855.3086
##    860 14301229878.1407             nan     0.0500 -17235959.9812
##    880 14118342559.7032             nan     0.0500 -24505958.8202
##    900 13867825949.3564             nan     0.0500 -2146673.6135
##    920 13675825370.8646             nan     0.0500 -11339556.8270
##    940 13496316501.2680             nan     0.0500 -3193636.2969
##    960 13326734670.8289             nan     0.0500 -1182916.8065
##    980 13150610118.5390             nan     0.0500 -9339504.2453
##   1000 12980442027.6338             nan     0.0500 -7968451.5679
##   1020 12805816292.9469             nan     0.0500 -13006352.9698
##   1040 12642013291.1660             nan     0.0500 -1777712.7314
##   1060 12468608971.9994             nan     0.0500 -8613299.5845
##   1080 12311180917.6355             nan     0.0500 -14600521.8862
##   1100 12160230572.6988             nan     0.0500 -9682642.6602
##   1120 11987462775.5350             nan     0.0500 -12374557.2553
##   1140 11842061976.5453             nan     0.0500 -7026835.8001
##   1160 11710632738.8370             nan     0.0500 3810345.3085
##   1180 11568116271.3770             nan     0.0500 -8856220.3612
##   1200 11439690894.8156             nan     0.0500 -7870074.7704
##   1220 11289178575.9091             nan     0.0500 -6932127.5612
##   1240 11170197237.6925             nan     0.0500 -8821673.1030
##   1260 11036398698.8110             nan     0.0500 -13423092.0605
##   1280 10898335689.2964             nan     0.0500 -5092489.6338
##   1300 10774694486.7303             nan     0.0500 -3030104.0653
##   1320 10668773961.5829             nan     0.0500 -9842026.1921
##   1340 10549785829.0096             nan     0.0500 -7735773.5874
##   1360 10431741671.0151             nan     0.0500 -11927802.4062
##   1380 10328873683.4323             nan     0.0500 -780244.1208
##   1400 10230866002.6588             nan     0.0500 -9649780.4170
##   1420 10132219931.3737             nan     0.0500 -6574881.4469
##   1440 10033889257.0840             nan     0.0500 -2939305.4942
##   1460 9935996593.9181             nan     0.0500 679091.0797
##   1480 9849385202.6572             nan     0.0500 -10371527.3147
##   1500 9756616797.8631             nan     0.0500 -7318059.3543</code></pre>
<pre class="r"><code>#combine the results 
#make sure to use the method names  from above
multimodel &lt;- list(
  lm = model_lm, 
  gbm = gbmFit1,
  knn=knn_fit_2,
  glmnet=lasso_fit,
  rpart = model_tree_2,
 ramger =rf_fit_2
  )
class(multimodel) &lt;- &quot;caretList&quot;</code></pre>
<p>The figures below compare the 6 models used for stacking visually in terms of RMSE and R².</p>
<pre class="r"><code>#we can visualize the differences in performance of each algorithm for each fold 
  dotplot(resamples(multimodel), metric = &quot;Rsquared&quot;) #you can set metric=MAE, RMSE, or Rsquared </code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize%20results-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>    splom(resamples(multimodel), metric = &quot;Rsquared&quot;)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize%20results-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>  dotplot(resamples(multimodel), metric = &quot;RMSE&quot;) #you can set metric=MAE, RMSE, or Rsquared </code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize%20results-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>    splom(resamples(multimodel), metric = &quot;RMSE&quot;)</code></pre>
<p><img src="/blogs/blog10_files/figure-html/visualize%20results-4.png" width="768" style="display: block; margin: auto;" /></p>
<p>The figure below shows the correlation between the models that I stacked together. The linear regression correlated strongly with the LASSO regression, but also with gradient boost and random forest. The selection of very similar variables throughout the whole process could be a reason for this.</p>
<pre class="r"><code>modelCor(resamples(multimodel))</code></pre>
<pre><code>##           lm   gbm   knn glmnet rpart ramger
## lm     1.000 0.926 0.752  0.963 0.726  0.893
## gbm    0.926 1.000 0.738  0.792 0.577  0.907
## knn    0.752 0.738 1.000  0.706 0.905  0.951
## glmnet 0.963 0.792 0.706  1.000 0.766  0.807
## rpart  0.726 0.577 0.905  0.766 1.000  0.840
## ramger 0.893 0.907 0.951  0.807 0.840  1.000</code></pre>
<p>Now, I run the model:</p>
<pre class="r"><code>#we can now use stacking with the list of models
library(caretEnsemble)  
model_list &lt;- caretStack(multimodel,
    trControl=ctrl,
    method=&quot;lm&quot;,
    metric = &quot;RMSE&quot;)

  summary(model_list)</code></pre>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ ., data = dat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3263032   -51716     1810    50039  4408661 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.36e+04   3.47e+03   -9.67  &lt; 2e-16 ***
## lm           1.28e+00   1.16e-01   11.06  &lt; 2e-16 ***
## gbm          3.80e-01   2.01e-02   18.95  &lt; 2e-16 ***
## knn          1.36e-01   1.28e-02   10.59  &lt; 2e-16 ***
## glmnet      -1.13e+00   1.17e-01   -9.68  &lt; 2e-16 ***
## rpart        6.63e-02   1.32e-02    5.01  5.4e-07 ***
## ramger       3.28e-01   2.71e-02   12.11  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2e+05 on 10492 degrees of freedom
## Multiple R-squared:  0.854,  Adjusted R-squared:  0.854 
## F-statistic: 1.02e+04 on 6 and 10492 DF,  p-value: &lt;2e-16</code></pre>
<pre class="r"><code>#predict the price of each house in the test data set
#recall that the output of &quot;train&quot; function (knn_fit) automatically keeps the best model 
all_prediction &lt;- predict(model_list, newdata = test_data)

all_results&lt;-data.frame(RMSE = RMSE(all_prediction, test_data$price), Rsquare = R2(all_prediction, test_data$price))

all_results</code></pre>
<pre><code>##     RMSE Rsquare
## 1 187360   0.866</code></pre>
</div>
</div>
<div id="selection-of-the-model" class="section level1">
<h1>Selection of the model</h1>
<p>To compare the performance of the different models I look at RMSE and R², the same parameters I used to optimize them. The best model is the model with the highest R² and the lowest RMSE. A high R² indicated that a high portion of overall variability in the dataset is explained by this model, while RMSE shows the error of the prediction.</p>
<pre class="r"><code>data.frame(name=c(&quot;Linear Regression&quot;, &quot;LASSO&quot;, &quot;KNN&quot;, &quot;Regression Tree&quot;, &quot;Random Forest&quot;, &quot;Gradient Boosting&quot;, &quot;Stacked Model&quot;),RMSE_Training= c(227300, 234251, 268281, 252842, 207808, 210764, 199600), RSquared_Training= c(0.8133, 0.8026, 0.7472, 0.7694, 0.8432
, 0.8403, 0.8541))</code></pre>
<pre><code>##                name RMSE_Training RSquared_Training
## 1 Linear Regression        227300             0.813
## 2             LASSO        234251             0.803
## 3               KNN        268281             0.747
## 4   Regression Tree        252842             0.769
## 5     Random Forest        207808             0.843
## 6 Gradient Boosting        210764             0.840
## 7     Stacked Model        199600             0.854</code></pre>
<p>Stacking is clearly the best method, explaining 85.41% of overall variability and having the lowest error. The table shows a difference in R² and RMSE between training and testing data. While the difference is not huge, it is surprising that most models perform better in the testing data than in the training data. This is unexpected but might be caused by the seed I used when splitting the total data into training and testing. I would expect, to have a slightly different result when using another seed.</p>
<div id="pick-investments" class="section level2">
<h2>Pick investments</h2>
<p>To select the 200 houses out of the 2,000 on the market for sale at the moment I applied my best model, the stacking model. I added the by the model predicted price to the dataset and calculated the profit margin comparing the predicted price to the asking price ((predicted price – asking price) /asking prices).
Finally, I ranked the properties by the calculated profit margin and selected the top 200. These 200 properties give an average return of 69.63%. My model calculates an average return of 3.78% over the whole dataset.</p>
<pre class="r"><code>numchoose=200
oos&lt;-london_house_prices_2019_out_of_sample

#predict the value of houses
oos$predict &lt;- predict(model_list,oos)

#Choose the ones you want to invest here

#Let&#39;s find the profit margin given our predicted price and asking price
oos_data&lt;- oos%&gt;%
  mutate(profitMargin=(predict-asking_price)/asking_price)%&gt;%
  arrange(-profitMargin)

#Make sure you choose exactly 200 of them
oos_data$buy=0
oos_data[1:numchoose,]$buy=1

#let&#39;s find the actual profit

oos_data&lt;-oos_data%&gt;%
  mutate(actualProfit=buy*profitMargin)

#if we invest in everything
mean(oos_data$profitMargin)</code></pre>
<pre><code>## [1] 0.0378</code></pre>
<pre class="r"><code>#just invest in those we chose
sum(oos_data$actualProfit)/numchoose</code></pre>
<pre><code>## [1] 0.696</code></pre>
<p>To control, I calculate how much profit I would make on the training dataset:</p>
<pre class="r"><code>##try for testing data
numchoose=200

#predict the value of houses
train_data$predict &lt;- predict(model_list,train_data)

#Choose the ones you want to invest here
#Let&#39;s find the profit margin given our predicted price and asking price
train_data_pred&lt;- train_data%&gt;%
  mutate(profitMargin=(predict-price)/price)%&gt;%
  arrange(-profitMargin)

#Make sure you choose exactly 200 of them
train_data_pred$buy=0
train_data_pred[1:numchoose,]$buy=1


#let&#39;s find the actual profit
train_data_pred&lt;-train_data_pred%&gt;%
  mutate(actualProfit=buy*profitMargin)

#if we invest in everything
mean(train_data_pred$actualProfit)</code></pre>
<pre><code>## [1] 0.0182</code></pre>
<pre class="r"><code>#just invest in those we chose
sum(train_data_pred$actualProfit)/numchoose</code></pre>
<pre><code>## [1] 0.955</code></pre>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>To sum up, I used available features of houses and historic data of all transactions done in London in 2019 to calculate seven different estimation engines. I used the methods linear regression, k-NN, and trees as well as the ensembled methods random forest, gradient boosting and stacking. While all of them are able to explain the difference in house prices in London at least to 75%, the best performing model, namely the stacking model, manages to explain 85.4%.
This estimation engine has subsequently been used to select the 200 most promising houses to invest in, with a predicted return of 69.63%.
Limitations of this project are the available information on the specific houses as well as the assumption that the asking price will not change. In addition, if I would have sufficient computing power, I would tune additional parameters of the models that I have used.
Other reasonable information that could be useful is commuting time to the center especially for properties that are located far from the center, as well as distance to supermarket and other facilities. Also, the architectural style, brightness of the rooms and interior design could be significant.</p>
</div>
